[{"content":"哈希表 快乐数 编写一个算法来判断一个数 n 是不是快乐数。\n「快乐数」 定义为：\n对于一个正整数，每一次将该数替换为它每个位置上的数字的平方和。 然后重复这个过程直到这个数变为 1，也可能是 无限循环 但始终变不到 1。 如果这个过程 结果为 1，那么这个数就是快乐数。 如果 n 是 快乐数 就返回 true ；不是，则返回 false 。\n思路：\n递归+哈希表\n使用哈希表存储已经出现过的数，通过递归计算下一个数。当数变为1时返回true，当数出现重复（即在哈希表中已经存在），则为false。\n快慢指针\n类比于链表成环的思路。这个题最终必有环，只是说这个环节点是1还是其他值。为1代表true，其他则是false。但是不同于链表成环2的是，这个如果是1的话，环内元素只有1，因此slow和fast相遇必是1；但如果节点不是1，则有可能是其他任意值。因此只需要判断成环那一刻，slow是不是1即可。\nclass Solution { HashSet\u0026lt;Integer\u0026gt; set=new HashSet\u0026lt;\u0026gt;(); public boolean isHappy(int n) { if(n==1){ return true; } if(set.contains(n)){ return false; }else{ set.add(n); } int sum=0; while(n!=0){ sum=sum+(n%10)*(n%10); n=n/10; } return isHappy(sum); } } class Solution { public boolean isHappy(int n) { int slow=n,fast=n; do{ slow=step(slow); fast=step(fast); fast=step(fast); }while(slow!=fast); return slow==1; } private int step(int n){ int sum=0; while(n!=0){ sum=sum+(n%10)*(n%10); n=n/10; } return sum; } } 字符串 右旋字符串 右旋字符串 | 代码随想录\n对于输入字符串 \u0026ldquo;abcdefg\u0026rdquo; 和整数 2，函数应该将其转换为 \u0026ldquo;fgabcde\u0026rdquo;。\n思路：\n旋转整个字符串，旋转前n个字符，旋转len-n个字符。\nimport java.util.*; public class Main{ public static void main(String[] args){ Scanner scanner=new Scanner(System.in); Integer index=scanner.nextInt(); String str=scanner.next(); index=index%str.length(); char[] arr=str.toCharArray(); rotate(arr,0,str.length()-1); rotate(arr,0,index-1); rotate(arr,index,str.length()-1); System.out.println(new String(arr)); } public static void rotate(char[] arr,int left,int right){ while(left\u0026lt;right){ char temp=arr[left]; arr[left]=arr[right]; arr[right]=temp; left++;right--; } } } 旋转字符串 旋转字符串\n思路：\n找到两个字符串的第一个字符，指针1指向s字符串的首位字符，指针2指向goal字符串“找到的第一个字符” 让两个指针同时朝一个方向移动，指针2移动到最右侧后回到最左侧。 在移动的过程中判断两个指针指向的内容是否相等，如果不等，表明字符串goal“找到的第一个字符”不对；然后寻找goal字符串下一个可能的第一个字符，当goal尝试完所有的情况都不对之后，返回结果则为false。 但如果指向字符串s的指针能从头走到尾，那表明两个字符串是相等的。\nclass Solution { public boolean rotateString(String s, String goal) { if(s.equals(goal)){ return true; }else if(s.length()!=goal.length()){ return false; } int start=0; //找到第二个字符串中可能的最开始的位置 for(int second=0;second\u0026lt;goal.length();second++){ start=0; if(goal.charAt(second)!=s.charAt(start)){ continue; } //让第一个指针和第二个指针同时往右走，假设第一个指针能走到头，那证明可以 int temp=second; while(start\u0026lt;s.length()){ //一旦同一时刻，两个指针的内容不同，表明当前找到的second指针是不对的 if(s.charAt(start)!=goal.charAt(temp)){ break; } start++;temp++; //走到最右侧之后再走回来 if(temp\u0026gt;=goal.length()){ temp=0; } } if(start==s.length()){ return true; } } //所有的second指针都是不对的 return false; } } 思路2：\n大佬的思路\n由于每次旋转操作都是将最左侧字符移动到最右侧，因此如果 goal 可由 s 经过多步旋转而来，那么 goal 必然会出现在 s + s 中，即满足 (s + s).contains(goal)，同时为了 s 本身过长导致的结果成立，我们需要先确保两字符串长度相等。\n作者：宫水三叶 链接：https://leetcode.cn/problems/rotate-string/solutions/1400369/by-ac_oier-bnkx/ 来源：力扣（LeetCode） 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\nreturn s.length()==goal.length()\u0026amp;\u0026amp;(s+s).contains(goal); strStr|indexOf indexOf\n给你两个字符串 haystack 和 needle ，请你在 haystack 字符串中找出 needle 字符串的第一个匹配项的下标（下标从 0 开始）。如果 needle 不是 haystack 的一部分，则返回 -1 。\n暴力解法 class Solution { public int strStr(String haystack, String needle) { for(int i=0;i\u0026lt;=haystack.length()-needle.length();i++){ int k=0; for(int j=i;j\u0026lt;i+needle.length();j++,k++){ if(haystack.charAt(j)!=needle.charAt(k)){ break; } } if(k==needle.length()){ return i; } } return -1; } } KMP class Solution { public int strStr(String haystack, String needle) { int[] next=buildNext(needle); for(int i=0,j=0;i\u0026lt;haystack.length();i++){ while(j\u0026gt;0\u0026amp;\u0026amp;haystack.charAt(i)!=needle.charAt(j)){ //冲突的时候，会去找next数组前一位的值 j=next[j-1]; } if(haystack.charAt(i)==needle.charAt(j)){ j++; } if(j==needle.length()){ return i-j+1; } } return -1; } private int[] buildNext(String needle){ //最长公共前后缀的下一位（或者说最大公共前后缀的位数），初始值为0 int prefixNext=0; int[] next=new int[needle.length()]; //因为第一个字符串是首尾相继，因此最大公共前后缀的位数就是0. next[0]=prefixNext; //cur表明是后缀最后一位，即要比较的数 //比较的逻辑也是先比较next[cur-1]和cur是否相等，相等的话公共前后缀的长度+1，cur的next数组值就是next[cur-1]+1 //假如不等，就要找到前一位next数组的位置 //比如aabaaf，假设cur为f的话，比较的就是b和f这两位 for(int cur=1;cur\u0026lt;needle.length();cur++){ while(prefixNext\u0026gt;0\u0026amp;\u0026amp;needle.charAt(cur)!=needle.charAt(prefixNext)){ //这里作何分析？ //虽然是在构建next数组，但本质上也是一个字符串匹配的过程,比如aabaaf,当b和f比较时，可以视作匹配串是aab，待比较串是aabaaf，b和f冲突了，我们会看aab的next数字的前一位的next数组值，视作不变量 prefixNext=next[prefixNext-1]; } if(needle.charAt(cur)==needle.charAt(prefixNext)){ prefixNext++; } next[cur]=prefixNext; } return next; } } 重复的子字符串 重复的子字符串\n给定一个非空的字符串 s ，检查是否可以通过由它的一个子串重复多次构成，如abababab\n暴力算法 暴力算法也有不同的暴力处理\n比如我首先想到的是，找到个首字符相等的字符位置j，假设前j个字符为重复子串，循环判断[j,2j][2j,3j]是否和[0,j]相等。如果一旦有不等的，那就找一下可能的子串，当j的位置大于s.length/2时，一定为false。而假设比较完所有区间全部相等，此时j==s.length，返回结果则为false。这种方案我内循环比较的时候使用的是substring，但下面的方案可以算作优化。\n假设重复字符串为[x1,x2,x3]，那么在[x1\u0026hellip;xn]中，[x7..x9]=[x4..x6]=[x1..x3]，因此假如从j开始，前j个字符串为重复子串,长度为l，那么一旦str[j]!=str[j-l]，那么就为false。就可以找寻下一个j了，当j大于s.length/2时,为false;\npublic boolean repeatedSubstringPattern(String s) { int j=1; while(true){ while(j\u0026lt;s.length()\u0026amp;\u0026amp;s.charAt(0)!=s.charAt(j)){ j++; } if(j\u0026gt;s.length()/2){ return false; } int k=0; boolean match=true; for(k=j;k\u0026lt;s.length();k++){ //这里需要判断s.length()%j的原因是存在abcabcab的情况 if(s.length()%j!=0||s.charAt(k)!=s.charAt(k-j)){ match=false; break; } } if(match){ return true; } j++; } } 其他神仙方案:\n参考力扣题解和代码随想录\n字符串为s，假设s+s去掉首位和末位字符后依然包含s，那么就证明是由重复子串构成\n可以使用KMP，判断kmp(s+s,s)，但是内循环比较的时候要注意从1到n-2；\nKMP 最长公共前缀和最长公共后缀的差即是重复子串：求取结果为： len-next(n-1)\n","date":"2024-09-12T20:07:49+08:00","permalink":"https://qisiii.github.io/post/algorithm/other/","title":"其他算法"},{"content":"排序 快排 核心思想是选定一个阈值temp\n通过左右指针，将比temp小的放左边，比temp大的放右边。\n对两个子序列重复排序。\npublic static void quickSort(int[] nums){ doQuickSort(nums,0,nums.length-1); } public static void doQuickSort(int[] nums, int left, int right){ if (left\u0026gt;=right){ return; } int temp=nums[left]; int min=left; int max=right; while (min\u0026lt;max){ //右指针左移 while (min\u0026lt;max\u0026amp;\u0026amp;nums[max]\u0026gt;=temp){ max--; } //将找到的小于标志数的放在左指针上，同时左指针右移 if (min\u0026lt;max){ nums[min]=nums[max]; min++; } //左指针右移 while (min\u0026lt;max\u0026amp;\u0026amp;nums[min]\u0026lt;=temp){ min++; } //将找到的大于标志数的放在右指针上，同时右指针左移 if (min\u0026lt;max){ nums[max]=nums[min]; max--; } } nums[min]=temp; doQuickSort(nums,left,min-1); doQuickSort(nums,min+1,right); } 二分查找 二分的前提是有序，通过规定两个边界，每次比较中间的值是否是目标值来决定下次边界的范围。\n在代码随想录中对边界的总结挺有特点的，在我个人的感知中左开右闭这种处理，既不美观，也不好懂，因此只需要记住left\u0026lt;=right的这种处理就好。\n力扣-35搜索插入位置 给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。\npublic int searchInsert(int[] nums, int target) { int left=0,right=nums.length-1; while(left\u0026lt;=right){ int mid=left+(right-left)/2; if(nums[mid]==target){ return mid; }else if(nums[mid]\u0026gt;target){ right=mid-1; }else{ left=mid+1; } } //这里需要思考一下 //当进入到最后一次循环的时候，由于left=right，那么mid=left=right； //所以对于if的三种情况，第一种相等就直接返回下标. //后两种，从left角度分析，如果nums[left]\u0026gt;target,那么left正好是要被插入的位置；如果nums[left]\u0026lt;target，那么要插入的位置就是下一个，即left+1，刚好在else中的逻辑就是这样，因此，最后虽然只是return left，但是会根据不同的情况落到不同的位置 // return left //那如果以right角度分析呢，如果nums[right]\u0026gt;target,那就应该返回right，但是由于在elseif中right-1，因此right还得再加回来即right+1,如果nums[right]\u0026lt;target,那就应该返回right+1； return right+1; } 力扣-69x的平方根 力扣-69x的平方根\n给你一个非负整数 x ，计算并返回 x 的 算术平方根 。\n由于返回类型是整数，结果只保留 整数部分 ，小数部分将被 舍去 。\n思路:\n其实和上面的题一样，换个说法就是在1,x中，寻找sqrt(x)。但是需要额外注意的有两点，\n1是返回值，由于返回的是取整的结构，从上面的分析可以知道return left表示的是返回结果将要占得位置，2.x之类的结果会得到3，所以需要返回left-1或者right。\npublic int mySqrt(int x) { int left=1,right=x; while(left\u0026lt;=right){ int mid=left+(right-left)/2; long sum=(long)mid*mid; if(sum==x){ return mid; }else if(sum\u0026gt;x){ right=mid-1; }else{ left=mid+1; } } return right; } 双指针 移除元素 力扣27移除元素\n给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素。元素的顺序可能发生改变。然后返回 nums 中与 val 不同的元素的数量。\n使用双指针，start指针用于记录最终的返回结果，当nums[start]和val不等，表示要保留 因此指针要++，反之则表示当前位置的这个值可以被替换，因此需要另一个指针遍历所有值来进行比较\npublic int removeElement(int[] nums, int val) { int start=0,cur=0; while(cur\u0026lt;nums.length){ if(nums[cur]!=val){ nums[start++]=nums[cur]; } cur++; } return start; } 比较含退格的字符串 力扣844. 比较含退格的字符串\n给定 s 和 t 两个字符串，当它们分别被输入到空白的文本编辑器后，如果两者相等，返回 true 。# 代表退格字符。\n思路一：\n使用双指针覆写的思想，当遇到#代表start指针可以被覆写，和移除元素的思想很像。这种方法也可以使用栈的思想，当不等于#号就入栈，等于#号就弹出顶部的元素。最后比较栈内的结果。\nclass Solution { public boolean backspaceCompare(String s, String t) { return doSolution(s).equals(doSolution(t)); } public String doSolution(String s){ int start=0,cur=0; char[] arr=s.toCharArray(); while(cur\u0026lt;s.length()){ if(arr[cur]==\u0026#39;#\u0026#39;){ if(start\u0026gt;0){ start--; } cur++; continue; } arr[start++]=arr[cur]; cur++; } StringBuilder build=new StringBuilder(); for(int i=0;i\u0026lt;start;i++){ build.append(arr[i]); } return build.toString(); } } 思路二：\n上面其实已经用到了双指针，但是会发现必须遍历完整个字符串，才能确定最终是什么，那有没有可能在遍历的过程中直接比较呢？\n正着遍历肯定不行，因为比较的时候不清楚后面是不是会删除当前字符，但如果反着遍历呢？\n假如反着遍历，当前字符是#，那么表明遇到的下一个不是#的字符要被删除，跳过就好了。\n假如字符不是#，那就要看当前字符是否要被删除（即遍历到当前字符的过程中有几个#），要么被删除，要么#号不足保留，同时比较两个字符串每一轮保留的字符，既可以确定是否是相同的字符串了。\n另外，两个字符串长度不等也不相同。\npublic boolean backspaceCompare(String s, String t) { int i = s.length() - 1, j = t.length() - 1; int delI = 0, delJ = 0; while (i \u0026gt;= 0 || j \u0026gt;= 0) { //跳出条件为当前不是#，且没有删除标记 while (i \u0026gt;= 0) { //如果是#号，那么增加删除标记 if (s.charAt(i) == \u0026#39;#\u0026#39;) { delI++; //如果不是#号，且存在删除标记,那么就减少删除标记,即当前元素被删除 } else if (delI \u0026gt; 0) { delI--; //直到不能删除，那就表示这一位一定在了 } else { break; } i--; } while (j \u0026gt;= 0) { if (t.charAt(j) == \u0026#39;#\u0026#39;) { delJ++; } else if (delJ \u0026gt; 0) { delJ--; } else { break; } j--; } //如果都没走到头，且当前字符不相等，那表明两个字符串不相等 if (i \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026gt;= 0) { if (s.charAt(i) != t.charAt(j)) { return false; } //如果只有任意一方走到头，那也表明不相等 } else { if (i \u0026gt;= 0 || j \u0026gt;= 0) { return false; } } i--; j--; } return true; } 有序数组的平方 977. 有序数组的平方\n给你一个按 非递减顺序 排序的整数数组 nums，返回 每个数字的平方 组成的新数组，要求也按 非递减顺序 排序。\n示例 1：\n输入：nums = [-4,-1,0,3,10] 输出：[0,1,9,16,100] 解释：平方后，数组变为 [16,1,0,9,100]，排序后，数组变为 [0,1,9,16,100] 示例 2：\n输入：nums = [-7,-3,2,3,11] 输出：[4,9,9,49,121] 思路：\n首先可以想到通过双指针来比较最左和最右两个位置的平方值，可以得出一个较大值并将指针移动。但是不能在原数组原地移动，因为单纯的交换值并不能做到其他位置一起移动。因此需要额外借助另一个数组，即每次将较大值放入result[n\u0026ndash;]中去。\nclass Solution { public int[] sortedSquares(int[] nums) { int n = nums.length; int[] resultArray = new int[n]; int left = 0, right = n - 1; while (left \u0026lt;= right) { int leftValue = nums[left] * nums[left]; int rightValue = nums[right] * nums[right]; int value = leftValue; if (leftValue \u0026gt; rightValue) { left++; } else { value = rightValue; right--; } resultArray[--n] = value; } return resultArray; } } 滑动窗口 长度最小的子数组 长度最小的子数组\n看到题之后首先想到的肯定就是滑动窗口了，而滑动窗口基本上也都是双指针实现，通过控制两个指针来表示窗口。因此这个题我们首先要不断右移指针来判断是否满足条件，当满足条件之后再不断缩小窗口（即移动左指针）。\n注意看题，题目中说的是总和大于等于 target，而不是等于，如果是等于len那里要额外判断的。\npublic int minSubArrayLen(int target, int[] nums) { int start = 0, end = 0; int sum = 0, len = nums.length; boolean flag = false; while (end \u0026lt; nums.length) { sum = sum + nums[end]; while (sum \u0026gt;= target) { len = Math.min(len, end - start + 1); flag = true; sum -= nums[start]; start++; } end++; } return flag ? len : 0; } 水果成篮 水果成篮\n依然是滑动窗口算法，但是窗口里记录什么决定了代码怎么写，下面这种方式好理解且简单，窗口中记录的是每个种类出现的次数，这样子，就是简单的移入，移除就可以了。\n而如果是记录的每个种类出现的位置，需要额外关心两个点：\n第一个是11223和112213这两种情况不同处理，当size大于2的时候，不能简单的移除left，由于不好决定移除哪个，所以就只能clear重新添加了\n第二个112213，map获取上次出现的地址，应该获取最新的位置，而不是最开始的位置\n这里我取巧了：当两个相邻的元素不同时表明元素位置需要刷新了。\npublic int totalFruit(int[] fruits) { int left = 0, right = 0,len=0; HashMap\u0026lt;Integer, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); while (right \u0026lt; fruits.length) { map.put(fruits[right], map.getOrDefault(fruits[right], 0) + 1); while (map.size() \u0026gt; 2) { map.put(fruits[left], map.getOrDefault(fruits[left], 0) - 1); if (map.get(fruits[left]) == 0) { map.remove(fruits[left]); } left++; } len=Math.max(len,right-left+1); right++; } return len; } public int totalFruit(int[] fruits) { if(fruits.length\u0026lt;=2){ return fruits.length; } int len=0; int start=0,end=0,n=fruits.length-1; HashMap\u0026lt;Integer,Integer\u0026gt; kindMap=new HashMap\u0026lt;\u0026gt;(); while(end\u0026lt;=n){ if(!kindMap.containsKey(fruits[end])|| (kindMap.size()==2\u0026amp;\u0026amp;fruits[end]!=fruits[end-1]) ){ kindMap.put(fruits[end],end); } //当篮子满了的时候 if(kindMap.size()\u0026gt;2){ len=Math.max(len,end-start); start=kindMap.get(fruits[end-1]); kindMap.clear(); kindMap.put(fruits[end],end); kindMap.put(fruits[end-1],start); } len=Math.max(len,end-start+1); end++; } return len; } 螺旋矩阵2 给定一个正整数 n，生成一个包含 1 到 n^2 所有元素，且元素按顺时针顺序螺旋排列的正方形矩阵。\n主要是边界情况的处理，我习惯的做法是完整写完一个方向后就移动边界。对于这种处理方案，第一次是处理的最上方，因此第一行写完后top要进行++，然后处理最右边这列，right\u0026ndash;，以此类推。\npublic static int[][] generateMatrix(int n) { int[][] result = new int[n][n]; int count = 1, target = n * n; int left = 0, right = n - 1, top = 0, bottom = n - 1; int i , j ; while (count \u0026lt;= target) { for ( i = left; count \u0026lt;= target\u0026amp;\u0026amp;i \u0026lt;= right; i++) { result[top][i] = count++; } top++; for ( j = top; count \u0026lt;= target\u0026amp;\u0026amp;j \u0026lt;= bottom; j++) { result[j][right] = count++; } right--; for ( i = right;count \u0026lt;= target\u0026amp;\u0026amp; i \u0026gt;= left; i--) { result[bottom][i] = count++; } bottom--; for ( j = bottom; count \u0026lt;= target\u0026amp;\u0026amp;j \u0026gt;= top; j--) { result[j][left] = count++; } left++; } return result; } ","date":"2024-09-06T16:32:12+08:00","permalink":"https://qisiii.github.io/post/algorithm/array/","title":"数组相关算法"},{"content":"链表结构 /** * 算法链表结构 */ public class ListNode { public int val; public ListNode next; ListNode() {} public ListNode(int val) { this.val = val; } ListNode(int val, ListNode next) { this.val = val; this.next = next; } public static ListNode build(Integer... obj){ return build(Arrays.asList(obj)); } public static ListNode build(List\u0026lt;Integer\u0026gt; arr){ if(arr.isEmpty()){ return null; } ListNode listNode = new ListNode(arr.get(0)); ListNode cur=listNode; for (int i = 1; i \u0026lt; arr.size(); i++) { cur.next=new ListNode(arr.get(i)); cur=cur.next; } return listNode; } /** * 构造成环的链表 * @param index 成环的位置 * @param obj 链表节点内容 * @return */ public static ListNode buildCycle(Integer index,Integer... obj){ List\u0026lt;Integer\u0026gt; arr = Arrays.asList(obj); ListNode listNode = new ListNode(arr.get(0)); ListNode cur=listNode; ListNode pos=null; for (int i = 1; i \u0026lt; arr.size(); i++) { if(index==i){ pos=cur; } cur.next=new ListNode(arr.get(i)); cur=cur.next; } cur.next=pos; return listNode; } public void print(){ ListNode node=this; while(node!=null){ System.out.print(node.val+\u0026#34;,\u0026#34;); node=node.next; } System.out.println(); } } 反转链表 题目 给定链表头结点，要求原地反转该链表，返回链表新的头结点。 例：1-\u003e2-\u003e3，反转后链表应为3-\u003e2-\u003e1，返回节点3； 思路 /** * 这种思路的核心在于不需要动head，真正原地移动，但需要构建一个假节点方便返回 * pre-1-2-3 * 拿掉2，所以要先获取到2； * 1和3建立连接；变为pre-1-3 2-3 * 2指向pre后面的节点 pre-1-3 2-1-3 * pre指向2 pre-2-1-3 * 全程不需要动head，当head或者head.next为空时，表明最后一个节点也移动到了pre后面 * 因此返回pre.next */ static ListNode reverse(ListNode head) { ListNode pre=new ListNode(-1); pre.next=head; ListNode next; //pre-1-2-3 while(head!=null\u0026\u0026head.next!=null){ //next=2 next=head.next; //1-3 head.next=next.next; //2-1 next.next=pre.next; //pre-2 pre.next=next; } return pre.next; } /** * 这个解法的思路我称之为接头霸王：核心构建一个新链表，节点为null。即同时存在null 1-2-3，然后一个一个让右边这个链表的头摘下来指向左边的头 * null 1-2-3 * 1-null 2-3 * 2-1-null 3 * 3-2-1-null null * 右边链表头没了之后，要让next作为头，所以还要先获取next * 左边链表有了新头之后，要作为pre，给下个头做准备，因此pre=head */ static ListNode reverse2(ListNode head) { ListNode pre=null,next=null; while(head!=null){ next=head.next; //接头 head.next=pre; //左边链表更新 pre=head; //右边链表更新 head=next; } return pre; } 链表环节点 判断是否成环 题目 给你一个链表的头节点 `head` ，判断链表中是否有环。 思路 类比于龟兔赛跑，只要存在环，那么两个不一样速度的指针终会相遇，因此，采用快慢指针来做实现 static Boolean hasCycle(ListNode head) { ListNode slow = head,fast = head; while(slow!=null\u0026\u0026fast!=null){ slow=slow.next; fast=fast.next; if(fast!=null){ fast=fast.next; if(slow==fast){ return true; } } } return false; } 找到成环的首节点 题目 给定一个链表的头节点 head ，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。 思路 当快慢指针相遇时，快指针走过的路是慢指针走过的路的2倍； 假设相遇是在b点， fast=a+b+c; slow=a+b; fast=2slow=2(a+b)=a+b+c; c=a+b或者说a=c-b; 既然当前slow处于b，那么slow再走c-b就到了相遇的节点，而c-b正好是a，所以让fast从链表的头节点开始一步一步走，当和slow相遇时，即表明走了a步，那就是环节点。 static ListNode detectCycle(ListNode head) { ListNode slow = head,fast = head; while(slow!=null\u0026\u0026fast!=null){ slow=slow.next; fast=fast.next; if(fast!=null){ fast=fast.next; if(slow==fast){ fast=head; while(slow!=fast){ fast=fast.next; slow=slow.next; } return fast; } } } return null; } 删除链表的倒数第N个节点 思路：\n典型的双指针应用，通过先让fast指针走n步，然后slow和fast一起走，当fast走到头的时候，slow走到的就是倒数第n个节点。由于要断开，因此还要记录old节点。\npublic ListNode removeNthFromEnd(ListNode head, int n) { ListNode old=new ListNode(-1,head),result=old; ListNode slow=head,fast=head; while(n\u0026gt;0){ fast=fast.next; n--; } while(fast!=null){ old=slow; slow=slow.next; fast=fast.next; } old.next=slow!=null?slow.next:null; return result.next; } ","date":"2024-08-14T15:43:27+08:00","permalink":"https://qisiii.github.io/post/algorithm/linkedlist/","title":"链表相关算法"},{"content":"基本概念 建议读一下20 共识算法：一次性说清楚 Paxos、Raft 等算法的区别，里面讲的还算易懂。\nZAB是zookeeper专门为了保持分布式共识而实现的算法，算法的基石还是Paxos的原理，或者说Mluti Paxos的原理。和Raft算法很像，都具有leader的概念，消息都是通过leader去统一管理，其他节点只需要从leader同步消息即可，并且都是超过半数提交事务就认为成功了。\n如果对分布式算法完全陌生，建议了解一下Paxos，MlutiPaxos，Raft的基本概念。\n在ZAB协议中，其设计主要包括两部分：原子广播和崩溃恢复。\n广播的意思是指当节点收到消息后，要将消息广播给其他的节点。那什么叫做原子呢？原子的意思是在这次广播中，要么所有的节点都收到消息并进行广播；要么所有的节点都放弃该条消息不做广播。\n但仅是广播并不能保证所有节点的数据完全一致，还需要保证消息必须有序的处理，每个节点必须处理完上一个消息，才能处理下一条消息。\n这是原子广播的两个基本要求：原子和有序。\n当leader挂掉的时候，新的leader必须尽快了解并统一整个集群当前的进度。因此，在zk选举流程 中，可以理解为什么必须选择最大事务ID作为leader，因为只有这样，才能在当前节点拥有最全的事务日志。当拥有了最全的事务后，从节点去进行同步到最新的进度。假如原来的leader又恢复了，那么就需要原来的leader丢弃超出现有leader的事务。这就是ZAB的另一部分\u0026ndash;崩溃恢复。\n整体设计 所有的节点分为了Leader、Follower、Observer三种，其中Leader和Follower是有投票权的。Observer是一个只处理只读请求的节点，属于作为提交吞吐量的横向扩展机制。\n之前的选举机制中也提到过，当选举结束之后，每个节点会更新自己的状态，当进入下一次循环的时候，会走到各自的case下执行各自的逻辑。\n虽然每个节点只有两行方法，但背后的逻辑还是蛮复杂的，make***方法是构建Zookeeper，可以理解为原子广播部分的逻辑。\n而lead、followLeader和observeLeader则是启动部分，主要是崩溃恢复的逻辑。下面我们以leader和follower串一下这个流程。\nswitch (state) { case OBSERVING: LOG.info(\u0026#34;OBSERVING\u0026#34;); setObserver(makeObserver(logFactory)); observer.observeLeader(); break; case FOLLOWING: LOG.info(\u0026#34;FOLLOWING\u0026#34;); setFollower(makeFollower(logFactory)); follower.followLeader(); break; case LEADING: LOG.info(\u0026#34;LEADING\u0026#34;); setLeader(makeLeader(logFactory)); leader.lead(); 崩溃恢复 执行到leader.lead()时，leader首先要保证集群尽快统一集群的进度。为了更好的理解这部分，需要了解ZabState类。\npublic enum ZabState { ELECTION,//选举状态，处于选举时的状态，到调用leader.lead为止 DISCOVERY,//发现状态，本质上是leader和其他节点建立连接，统一当前的周期epoch和事务ID，并得到大多数节点的认可 SYNCHRONIZATION,//同步状态，follow节点根据leader确定的事务ID，多退少补 BROADCAST//大多数节点的事务已经统一，可以接受来自客户端或者从节点的消息并广播了 } ELECTION 整个选举过程都是属于ELECTION状态，具体分析可以看选举机制\nDISCOVERY 在这个过程中，leader和其他的节点需要建立通信；注意，这个和之前选举时建立的连接不同，选举时所建立的连接仅是为了选举工作。而这个连接，才是负责真正的通信。\n建立连接之后，每个节点（不论是leader还是follower）要根据自己的事务id计算新的周期，zxid本身是64位的数值，低32位用来自增，高32位用来表示周期，因此需要将自己的高32+1来作为新的周期。\n当leader获取到最新的周期后，要通知所有节点，当大多数节点都成功应答之后，当前集群的周期就算定下来了。\nPS：有点像是皇帝的年号，在当上皇帝后，要告知天下当前是洪武、嘉靖还是崇祯之类的。\n建立连接是由LearnerCnxAcceptor类为每个地址都创建了一个LearnerCnxAcceptorHandler来接受连接，并用LearnerHandler来处理socket请求\nLearnerHandler是非常重要的一个类，其维护者leader和普通节点的通信和数据同步，几个步骤的流转也都是Learner回应了ACK，LearnerHandler收到之后才能往下推进的。\nSYNCHRONIZATION 当所有节点就epoch和zxId协商一致之后，Learner节点就可以开始根据Leader的事务情况进行同步了。\n关于数据的同步分为三种类型：\nDIFF:差距很小，在这种情况下，leader以request的形式发给Learner就可以了 SNAP:差距过大，需要将日志文件直接发给learner\nTRUNC: Learner的事务id比leader的还要大，因此Learner要截断事务\n当超过半数节点表示数据已经跟上最新进度之后，leader就会启动服务器，并表示ack的这些节点可以接受客户端工作了，自此进入BROADCAST状态。\nBROADCAST 在这个状态下，更核心的其实应该是那些不同类型节点的zkServer处理逻辑，或者说那些RequestProcessor的处理逻辑。而处于Leader、LearnerHandler、Follower者三个类中的逻辑，就只有维护好通信，做好心跳之类的框架工作。\n几个阻塞态 在Leader.lead和LearnerHandler中，在zabState流转过程中会调用几个阻塞的方法来等待大部分节点的ACK\ngetEpochToPropose 获取不同节点的周期提案\nwaitForEpochAck Leader计算完最大的周期，通知其他节点，等待节点对于周期提案的答复\nwaitForNewLeaderAck 在已经确定周期的情况下，等待其他节点同步完数据之后，给Leader答复\n这三个方法的逻辑是大似相同的，都是由Leader或者LearnerHandler来进行调用，下面以getEpochToPropose为例讲一下逻辑\n当Leader调用时，传进来的lastAcceptedEpoch是Leader记录的最后的周期或者半数Learner已经商量好的周期。\n当LearnerHandler调用时，是在Leader收到FollowInfo之后，这个时候已经获取到各个Follower的周期信息，因此每个LearnerHandler负责将自己Follower的周期传进来，以计算最大的周期，每个节点投票后，通过connectingFollowers.wait进行阻塞\n当半数之上的节点参与投票之后，就定下来当前周期，唤醒所有wait的线程，并将waitingForNewEpoch设置为false，那些还没参与投票的就不用投票了\npublic long getEpochToPropose(long sid, long lastAcceptedEpoch) throws InterruptedException, IOException { synchronized (connectingFollowers) { if (!waitingForNewEpoch) { return epoch; } //每个节点都会调用getEpochToPropose反法，leader是直接调用，其他节点是在learnerHandler中调用 //因此，假如从节点的周期大于主节点，主节点也要以大的为主 if (lastAcceptedEpoch \u0026gt;= epoch) { epoch = lastAcceptedEpoch + 1; } //判断是否有投票权 if (isParticipant(sid)) { connectingFollowers.add(sid); } QuorumVerifier verifier = self.getQuorumVerifier(); //超过半数就通知所有线程继续执行，否则阻塞在这里 //这里需要注意一下，仅是校验是否有半数参与投票了，而不是校验投票的最大周期超过半数 //比如存在7票，顺序分别为3,3,3,4,3,3,5，那么当投票到第二个4的时候，就会确定下来当前周期为4，那些大于4的节点在收到epoch判断自己的周期比提案的周期大之后会断开连接 //当然了，实际情况不会这么极端，毕竟Leader本身就是最大事务Id才能当选，所以大批量的Follower大于Leader是不可能的，只有老领导才会有可能大于新领导 if (connectingFollowers.contains(self.getMyId()) \u0026amp;\u0026amp; verifier.containsQuorum(connectingFollowers)) { waitingForNewEpoch = false; self.setAcceptedEpoch(epoch); connectingFollowers.notifyAll(); } else { long start = Time.currentElapsedTime(); if (sid == self.getMyId()) { timeStartWaitForEpoch = start; } long cur = start; long end = start + self.getInitLimit() * self.getTickTime(); //在等待时间内一直阻塞 while (waitingForNewEpoch \u0026amp;\u0026amp; cur \u0026lt; end \u0026amp;\u0026amp; !quitWaitForEpoch) { connectingFollowers.wait(end - cur); cur = Time.currentElapsedTime(); } if (waitingForNewEpoch) { throw new InterruptedException(\u0026#34;Timeout while waiting for epoch from quorum\u0026#34;); } } return epoch; } } 启动流程 参考上图走一下代码\nLeader.lead() void lead() throws IOException, InterruptedException { //zab状态是服务发现 self.setZabState(QuorumPeer.ZabState.DISCOVERY); self.tick.set(0); zk.loadData(); leaderStateSummary = new StateSummary(self.getCurrentEpoch(), zk.getLastProcessedZxid()); //用来和从节点同步数据的连接 cnxAcceptor = new LearnerCnxAcceptor(); cnxAcceptor.start(); //等待所有节点计算出来最大的周期 long epoch = getEpochToPropose(self.getMyId(), self.getAcceptedEpoch()); //该周期的事务id从0开始计算 zk.setZxid(ZxidUtils.makeZxid(epoch, 0)); synchronized(this) { lastProposed = zk.getZxid(); } //newLeaderProposal会在waitForEpochAck用到 newLeaderProposal.packet = new QuorumPacket(NEWLEADER, zk.getZxid(), null, null); if ((newLeaderProposal.packet.getZxid() \u0026amp; 0xffffffff L) != 0) { LOG.info(\u0026#34;NEWLEADER proposal has Zxid of {}\u0026#34;, Long.toHexString(newLeaderProposal.packet.getZxid())); } //Q\u0026amp;A 2024/8/18 // Q: 由于一直没有理解getLastSeenQuorumVerifier是什么场景下的，所以这里也不是很理解 // A: QuorumVerifier lastSeenQV = self.getLastSeenQuorumVerifier(); QuorumVerifier curQV = self.getQuorumVerifier(); //区分第一次和其他情况，第一次的时候只有curQV，其他情况可能会有lastSeenQV if (curQV.getVersion() == 0 \u0026amp;\u0026amp; curQV.getVersion() == lastSeenQV.getVersion()) { try { LOG.debug(String.format(\u0026#34;set lastSeenQuorumVerifier to currentQuorumVerifier (%s)\u0026#34;, curQV.toString())); QuorumVerifier newQV = self.configFromString(curQV.toString()); newQV.setVersion(zk.getZxid()); self.setLastSeenQuorumVerifier(newQV, true); } catch (Exception e) { throw new IOException(e); } } newLeaderProposal.addQuorumVerifier(self.getQuorumVerifier()); //上一个配置的版本大于当前的版本，就也要添加进去 if (self.getLastSeenQuorumVerifier().getVersion() \u0026gt; self.getQuorumVerifier().getVersion()) { newLeaderProposal.addQuorumVerifier(self.getLastSeenQuorumVerifier()); } // 大部分节点就周期和zxid协商一致 waitForEpochAck(self.getMyId(), leaderStateSummary); self.setCurrentEpoch(epoch); self.setLeaderAddressAndId(self.getQuorumAddress(), self.getMyId()); //zab状态到达同步状态 self.setZabState(QuorumPeer.ZabState.SYNCHRONIZATION); try { //数据已经同步完成 waitForNewLeaderAck(self.getMyId(), zk.getZxid()); } catch (InterruptedException e) { shutdown(\u0026#34;Waiting for a quorum of followers, only synced with sids: [ \u0026#34; + newLeaderProposal.ackSetsToString() + \u0026#34; ]\u0026#34;); HashSet \u0026lt; Long \u0026gt; followerSet = new HashSet \u0026lt; \u0026gt; (); for (LearnerHandler f: getLearners()) { if (self.getQuorumVerifier().getVotingMembers().containsKey(f.getSid())) { followerSet.add(f.getSid()); } } boolean initTicksShouldBeIncreased = true; for (Proposal.QuorumVerifierAcksetPair qvAckset: newLeaderProposal.qvAcksetPairs) { if (!qvAckset.getQuorumVerifier().containsQuorum(followerSet)) { initTicksShouldBeIncreased = false; break; } } if (initTicksShouldBeIncreased) { LOG.warn(\u0026#34;Enough followers present. Perhaps the initTicks need to be increased.\u0026#34;); } return; } //启动Leader端的Server，启动流程和单机版类似，只是会设置周期和最新事务ID startZkServer(); String initialZxid = System.getProperty(\u0026#34;zookeeper.testingonly.initialZxid\u0026#34;); if (initialZxid != null) { long zxid = Long.parseLong(initialZxid); zk.setZxid((zk.getZxid() \u0026amp; 0xffffffff00000000 L) | zxid); } if (!System.getProperty(\u0026#34;zookeeper.leaderServes\u0026#34;, \u0026#34;yes\u0026#34;).equals(\u0026#34;no\u0026#34;)) { self.setZooKeeperServer(zk); } //到达广播状态 self.setZabState(QuorumPeer.ZabState.BROADCAST); self.adminServer.setZooKeeperServer(zk); boolean tickSkip = true; // If not null then shutdown this leader String shutdownMessage = null; //保持法定人数的统计和ping while (true) { synchronized(this) { long start = Time.currentElapsedTime(); long cur = start; long end = start + self.tickTime / 2; while (cur \u0026lt; end) { wait(end - cur); cur = Time.currentElapsedTime(); } if (!tickSkip) { self.tick.incrementAndGet(); } SyncedLearnerTracker syncedAckSet = new SyncedLearnerTracker(); syncedAckSet.addQuorumVerifier(self.getQuorumVerifier()); if (self.getLastSeenQuorumVerifier() != null \u0026amp;\u0026amp; self.getLastSeenQuorumVerifier().getVersion() \u0026gt; self.getQuorumVerifier().getVersion()) { syncedAckSet.addQuorumVerifier(self.getLastSeenQuorumVerifier()); } syncedAckSet.addAck(self.getMyId()); for (LearnerHandler f: getLearners()) { if (f.synced()) { syncedAckSet.addAck(f.getSid()); } } // check leader running status if (!this.isRunning()) { // set shutdown flag shutdownMessage = \u0026#34;Unexpected internal error\u0026#34;; break; } //状态不健康时 if (!tickSkip \u0026amp;\u0026amp; !syncedAckSet.hasAllQuorums() \u0026amp;\u0026amp; !(self.getQuorumVerifier().overrideQuorumDecision(getForwardingFollowers()) \u0026amp;\u0026amp; self.getQuorumVerifier().revalidateOutstandingProp(this, new ArrayList \u0026lt; \u0026gt; (outstandingProposals.values()), lastCommitted))) { // Lost quorum of last committed and/or last proposed // config, set shutdown flag shutdownMessage = \u0026#34;Not sufficient followers synced, only synced with sids: [ \u0026#34; + syncedAckSet.ackSetsToString() + \u0026#34; ]\u0026#34;; break; } tickSkip = !tickSkip; } for (LearnerHandler f: getLearners()) { f.ping(); } } if (shutdownMessage != null) { shutdown(shutdownMessage); // leader goes in looking state } } LearnHandler.run() try { //ia是socket的输入，oa是socket的输出 ia = BinaryInputArchive.getArchive(bufferedInput); bufferedOutput = new BufferedOutputStream(sock.getOutputStream()); oa = BinaryOutputArchive.getArchive(bufferedOutput); //等于是从输入流中读取QuorumPacket序列化对象，这个对应的是follower的registerWithLeader方法 QuorumPacket qp = new QuorumPacket(); ia.readRecord(qp, \u0026#34;packet\u0026#34;); //判断消息类型是不是FOLLOWERINFO和OBSERVERINFO，即上报节点信息 messageTracker.trackReceived(qp.getType()); if (qp.getType() != Leader.FOLLOWERINFO \u0026amp;\u0026amp; qp.getType() != Leader.OBSERVERINFO) { LOG.error(\u0026#34;First packet {} is not FOLLOWERINFO or OBSERVERINFO!\u0026#34;, qp.toString()); return; } ... //获取从节点的周期（高32位） long lastAcceptedEpoch = ZxidUtils.getEpochFromZxid(qp.getZxid()); long peerLastZxid; StateSummary ss = null; long zxid = qp.getZxid(); long newEpoch = learnerMaster.getEpochToPropose(this.getSid(), lastAcceptedEpoch); long newLeaderZxid = ZxidUtils.makeZxid(newEpoch, 0); //Q\u0026amp;A 2024/8/18 // Q: 小于一万的意义？ // A: if (this.getVersion() \u0026lt; 0x10000) { // we are going to have to extrapolate the epoch information long epoch = ZxidUtils.getEpochFromZxid(zxid); ss = new StateSummary(epoch, zxid); // fake the message learnerMaster.waitForEpochAck(this.getSid(), ss); } else { byte[] ver = new byte[4]; ByteBuffer.wrap(ver).putInt(0x10000); QuorumPacket newEpochPacket = new QuorumPacket(Leader.LEADERINFO, newLeaderZxid, ver, null); oa.writeRecord(newEpochPacket, \u0026#34;packet\u0026#34;); //将商议出来的周期和zxid发给客户端 messageTracker.trackSent(Leader.LEADERINFO); bufferedOutput.flush(); QuorumPacket ackEpochPacket = new QuorumPacket(); ia.readRecord(ackEpochPacket, \u0026#34;packet\u0026#34;); //客户端响应成功 messageTracker.trackReceived(ackEpochPacket.getType()); if (ackEpochPacket.getType() != Leader.ACKEPOCH) { LOG.error(\u0026#34;{} is not ACKEPOCH\u0026#34;, ackEpochPacket.toString()); return; } ByteBuffer bbepoch = ByteBuffer.wrap(ackEpochPacket.getData()); ss = new StateSummary(bbepoch.getInt(), ackEpochPacket.getZxid()); learnerMaster.waitForEpochAck(this.getSid(), ss); } peerLastZxid = ss.getLastZxid(); //计算节点和leader相差是否很多 //三种类型： //DIFF:差距很小 //SNAP:差距过大，需要将日志文件直接发给learner //TRUNC: Learner的事务id比leader的还要大，因此Learner要截断事务 boolean needSnap = syncFollower(peerLastZxid, learnerMaster); boolean exemptFromThrottle = getLearnerType() != LearnerType.OBSERVER; /* if we are not truncating or sending a diff just send a snapshot */ if (needSnap) { syncThrottler = learnerMaster.getLearnerSnapSyncThrottler(); syncThrottler.beginSync(exemptFromThrottle); ServerMetrics.getMetrics().INFLIGHT_SNAP_COUNT.add(syncThrottler.getSyncInProgress()); try { //对于需要同步日志文件的，先发一个通知 long zxidToSend = learnerMaster.getZKDatabase().getDataTreeLastProcessedZxid(); oa.writeRecord(new QuorumPacket(Leader.SNAP, zxidToSend, null, null), \u0026#34;packet\u0026#34;); messageTracker.trackSent(Leader.SNAP); bufferedOutput.flush(); // Dump data to peer //直接将日志dump发给follow learnerMaster.getZKDatabase().serializeSnapshot(oa); oa.writeString(\u0026#34;BenWasHere\u0026#34;, \u0026#34;signature\u0026#34;); bufferedOutput.flush(); } finally { ServerMetrics.getMetrics().SNAP_COUNT.add(1); } } else { syncThrottler = learnerMaster.getLearnerDiffSyncThrottler(); syncThrottler.beginSync(exemptFromThrottle); ServerMetrics.getMetrics().INFLIGHT_DIFF_COUNT.add(syncThrottler.getSyncInProgress()); ServerMetrics.getMetrics().DIFF_COUNT.add(1); } ... // Start thread that blast packets in the queue to learner //单独一个线程专门同步 startSendingPackets(); qp = new QuorumPacket(); ia.readRecord(qp, \u0026#34;packet\u0026#34;); //收到Learner的ACK messageTracker.trackReceived(qp.getType()); if (qp.getType() != Leader.ACK) { LOG.error(\u0026#34;Next packet was supposed to be an ACK, but received packet: {}\u0026#34;, packetToString(qp)); return; } LOG.debug(\u0026#34;Received NEWLEADER-ACK message from {}\u0026#34;, sid); //同步完了 learnerMaster.waitForNewLeaderAck(getSid(), qp.getZxid()); ... /* * Wait until learnerMaster starts up */ learnerMaster.waitForStartup(); //leader向follower发送UPTODATE，表明follower可以开始响应客户端了 queuedPackets.add(new QuorumPacket(Leader.UPTODATE, -1, null, null)); //接受follower消息，主要是两类吧，一类是request，一类是ack while (true) { 自己看吧， 没啥特殊的 } } Follower.followLeader() self.setZabState(QuorumPeer.ZabState.DISCOVERY); QuorumServer leaderServer = findLeader(); try { //建立连接 connectToLeader(leaderServer.addr, leaderServer.hostname); connectionTime = System.currentTimeMillis(); //告诉leader自己的信息,并等待协商好的最新事务Id返回 long newEpochZxid = registerWithLeader(Leader.FOLLOWERINFO); if (self.isReconfigStateChange()) { throw new Exception(\u0026#34;learned about role change\u0026#34;); } long newEpoch = ZxidUtils.getEpochFromZxid(newEpochZxid); if (newEpoch \u0026lt; self.getAcceptedEpoch()) { LOG.error(\u0026#34;Proposed leader epoch \u0026#34; + ZxidUtils.zxidToString(newEpochZxid) + \u0026#34; is less than our accepted epoch \u0026#34; + ZxidUtils.zxidToString(self.getAcceptedEpoch())); throw new IOException(\u0026#34;Error: Epoch of leader is lower\u0026#34;); } long startTime = Time.currentElapsedTime(); self.setLeaderAddressAndId(leaderServer.addr, leaderServer.getId()); self.setZabState(QuorumPeer.ZabState.SYNCHRONIZATION); //同步数据 syncWithLeader(newEpochZxid); self.setZabState(QuorumPeer.ZabState.BROADCAST); completedSync = true; long syncTime = Time.currentElapsedTime() - startTime; ServerMetrics.getMetrics().FOLLOWER_SYNC_TIME.add(syncTime); if (self.getObserverMasterPort() \u0026gt; 0) { LOG.info(\u0026#34;Starting ObserverMaster\u0026#34;); om = new ObserverMaster(self, fzk, self.getObserverMasterPort()); om.start(); } else { om = null; } // create a reusable packet to reduce gc impact QuorumPacket qp = new QuorumPacket(); while (this.isRunning()) { readPacket(qp); processPacket(qp); } 消息处理流程 RequestProcessor 相比于单机版来说，集群的Processor显得有些多，但是像是PrepRequestProcessor、SyncRequestProcessor和FinnalProcessor都是复用，逻辑和zookeeper源码-单机版一样，这里就不赘述了。\nLeaderRequestProcessor只是做了一个checkUpgradeSession，处理本地会话创建临时节点的情况。\nPropsoalRequestProcessor 的工作就是将请求以提案的方法发给各个节点，并且本地落库\nCommitProcessor 用于处理本地事务和总事务的匹配处理，这个类的代码是我觉得最难理解的\nToBeAppliedRequestProcessor 好像只是一个队列排序，没感知到实际作用\nAckRequestProcessor 用于判断提案是否通过，通过的话给其他节点发送commit消息，并修改leader的LastZxid\nFollowerRequestProcessor 的作用是 判断是否需要是只读请求，只读的话自己交给下一个Processor处理，如果是写事务的话则需要像Leader发request\nSendAckRequestProcessor 是在收到leader的提案执行了SyncRequestProcessor（本地落库）之后调用的，用于回复Leader提案ACK\n流程图 CommitProcessor 通信流程中其他部分的代码都比较好理解，只有CommitProcessor的run方法，我个人看了好几遍才懂，所以这里贴一下代码分析。\nCommitProcessor持有四个队列：\nqueuedRequests 存储所有请求，无论读写，这个队列的作用主要是规定了顺序。\npendingRequests 表示正在等待处理的请求，是queuedRequests以sessionId分组后的结果，实际存储的请求可能比queuedRequests少，因为queuedRequests中有部分读请求是可以立即处理的。\nqueuedWriteRequests 只存储事务请求\ncommittedRequests 表示已经提交的事务请求，在调用Commit之后才会添加进来。\n这个类的执行逻辑是：\n在processRequest中将所有请求添加到queuedRequests，事务请求添加到queuedRequests中\n当queuedRequests或者committedRequests任意不为空的时候，执行run里的循环逻辑\n如果是queuedRequests不为空，顺序出队；\n如果出队的是事务请求，添加到pendingRequests中\n如果出队的是只读请求，且正在处理的请求中不包含这个只读请求的SessionId，立即交由下一个Processor处理\n如果出队的是只读请求，但是这个session之前有写请求，那么这个只读请求也得添加到pendingRequests中，强制串行化\n等待commitIsWaiting为真，即存在已经提交的事务请求不为空\n这里要理解一下，目前还为返回结果的请求只有两种，一种是未提交的事务请求，一种是阻塞在事务请求后的同session只读请求，因此想要处理这两种中的任意一个，都需要等待队首的事务提交\n当commitIsWaiting为真之后，下面其实有两段逻辑：while循环是处理事务请求的，for循环是处理阻塞的只读请求的\n从committedRequests取出已提交的请求，并从queuedWriteRequests中匹配，组装完整的request交给下一个Processor处理；并将当前请求的SessionId添加到queuesToDrain，表示里面阻塞的只读请求可以开始处理了\n遍历可以处理的session，从pendingRequests中取出只读请求并进行处理，当遇到事务请求时停止\npublic void run() { int requestsToProcess = 0; boolean commitIsWaiting = false; do { //queuedRequests表示还没有commit的事务，主要用于排队 //committedRequests表示已经commit的事务 synchronized(this) { commitIsWaiting = !committedRequests.isEmpty(); requestsToProcess = queuedRequests.size(); //两个队列都没有表示现在没有请求需要处理 if (requestsToProcess == 0 \u0026amp;\u0026amp; !commitIsWaiting) { // Waiting for requests to process while (!stopped \u0026amp;\u0026amp; requestsToProcess == 0 \u0026amp;\u0026amp; !commitIsWaiting) { wait(); commitIsWaiting = !committedRequests.isEmpty(); requestsToProcess = queuedRequests.size(); } } } Request request; int readsProcessed = 0; while (!stopped \u0026amp;\u0026amp; requestsToProcess \u0026gt; 0 \u0026amp;\u0026amp; (maxReadBatchSize \u0026lt; 0 || readsProcessed \u0026lt;= maxReadBatchSize) \u0026amp;\u0026amp; (request = queuedRequests.poll()) != null) { requestsToProcess--; //如果是写事务，或者虽然是读事务，但是该sessionId存在正在处理的请求都要放到队列里 if (needCommit(request) || pendingRequests.containsKey(request.sessionId)) { // Add request to pending Deque \u0026lt; Request \u0026gt; requests = pendingRequests.computeIfAbsent(request.sessionId, sid -\u0026gt; new ArrayDeque \u0026lt; \u0026gt; ()); requests.addLast(request); ServerMetrics.getMetrics().REQUESTS_IN_SESSION_QUEUE.add(requests.size()); } else { readsProcessed++; numReadQueuedRequests.decrementAndGet(); //是读事务，直接交给Final处理 sendToNextProcessor(request); } if (!commitIsWaiting) { commitIsWaiting = !committedRequests.isEmpty(); } /* * * 存在已提交的事务：意味着在pendingRequests和committedRequests都有request */ if (commitIsWaiting \u0026amp;\u0026amp; !stopped) { /* * Drain outstanding reads */ //Q\u0026amp;A 2024/8/19 // Q: 这里不理解，必须得是空了才能处理吗？ // A: waitForEmptyPool(); if (stopped) { return; } int commitsToProcess = maxCommitBatchSize; Set \u0026lt; Long \u0026gt; queuesToDrain = new HashSet \u0026lt; \u0026gt; (); long startWriteTime = Time.currentElapsedTime(); int commitsProcessed = 0; //处理事务请求 while (commitIsWaiting \u0026amp;\u0026amp; !stopped \u0026amp;\u0026amp; commitsToProcess \u0026gt; 0) { // Process committed head request = committedRequests.peek(); if (!queuedWriteRequests.isEmpty() \u0026amp;\u0026amp; queuedWriteRequests.peek().sessionId == request.sessionId \u0026amp;\u0026amp; queuedWriteRequests.peek().cxid == request.cxid) { Deque \u0026lt; Request \u0026gt; sessionQueue = pendingRequests.get(request.sessionId); ServerMetrics.getMetrics().PENDING_SESSION_QUEUE_SIZE.add(pendingRequests.size()); //想象不出来什么时候会是这种情况 if (sessionQueue == null || sessionQueue.isEmpty() || !needCommit(sessionQueue.peek())) { break; } else { ServerMetrics.getMetrics().REQUESTS_IN_SESSION_QUEUE.add(sessionQueue.size()); // If session queue != null, then it is also not empty. Request topPending = sessionQueue.poll(); topPending.setHdr(request.getHdr()); topPending.setTxn(request.getTxn()); topPending.setTxnDigest(request.getTxnDigest()); topPending.zxid = request.zxid; topPending.commitRecvTime = request.commitRecvTime; request = topPending; if (request.isThrottled()) { LOG.error(\u0026#34;Throttled request in committed \u0026amp; pending pool: {}. Exiting.\u0026#34;, request); ServiceUtils.requestSystemExit(ExitCode.UNEXPECTED_ERROR.getValue()); } numWriteQueuedRequests.decrementAndGet(); //queuedWriteRequests出队 queuedWriteRequests.poll(); //由于处理了该session的写事务，因此可以处理该session的只读请求了 queuesToDrain.add(request.sessionId); } } //出队 committedRequests.remove(); commitsToProcess--; commitsProcessed++; // Process the write inline. //交由下一个Processor处理 processWrite(request); commitIsWaiting = !committedRequests.isEmpty(); } readsProcessed = 0; for (Long sessionId: queuesToDrain) { Deque \u0026lt; Request \u0026gt; sessionQueue = pendingRequests.get(sessionId); int readsAfterWrite = 0; //取出对应session的待处理请求，只处理只读请求，当遇到事务请求就停止（得等待该事务被提交后处理） while (!stopped \u0026amp;\u0026amp; !sessionQueue.isEmpty() \u0026amp;\u0026amp; !needCommit(sessionQueue.peek())) { numReadQueuedRequests.decrementAndGet(); sendToNextProcessor(sessionQueue.poll()); readsAfterWrite++; } readsProcessed += readsAfterWrite; // Remove empty queues if (sessionQueue.isEmpty()) { pendingRequests.remove(sessionId); } } } } while (!stoppedMainLoop); } } 参考文档: Zab协议 (史上最全) - 疯狂创客圈 - 博客园\n【图解源码】Zookeeper3.7源码剖析，Session的管理机制，Leader选举投票规则，集群数据同步流程 - 掘金\n《Zookeeper》源码分析（十九）之 LearnerHandler-CSDN博客\n20 共识算法：一次性说清楚 Paxos、Raft 等算法的区别\n","date":"2024-08-14T15:08:39+08:00","permalink":"https://qisiii.github.io/post/tech/distributed/zookeeper/zab/","title":"Zookeeper源码分析-Zab协议"},{"content":"hugo官网|Stack官网\nstack自带小部件： Widgets | Stack\nwidgets: homepage: - type: search - type: archives params: limit: 5 - type: categories params: limit: 10 - type: tag-cloud params: limit: 10 在stack的配置文件中，搜索工具、归档工具、分类和标签都是启用的。但是启用并不代表默认会出现，依然需要各种地方指定了值才能出现。\n分类\u0026amp;标签 在你的内容文件的front matter中，需要指定tag的值和categories的值，我这里的front matter是toml格式\ntag = [\u0026#39;hugo\u0026#39;,\u0026#39;stack\u0026#39;] categories = [\u0026#34;个人网站\u0026#34;] 归档： 需要在content/post目录下新建archives.md，内容如下，不需要任何正文内容\n+++ title = \u0026#39;Archives\u0026#39; layout = \u0026#34;archives\u0026#34; hidden = true comments = false +++ layout是指定为分类样式，hidden表示该文件不会被展示出来，comments表示评论区关闭.\n其次，需要在 项目/layouts/_default 或者 主题/layouts/_default下存在archives.html，由于stack主题下默认就有这个文件，所以正常来说添加了archives.md就可以使用归档功能了。\n搜索: 增加search.md 首先是同归档类似，需要在content/post目录下新建search.md，内容如下，不需要任何正文内容\n+++ title = \u0026#34;search\u0026#34; layout = \u0026#34;search\u0026#34; hidden = true comments = false +++ 增加搜索引擎的文件 静态网站的搜索本质上是将你的文档进行分词汇总到一个json文件，实际搜索的时候就是在搜索这个json文件。比较常用的是fuse.js,lunr.js或者主题自己封装的搜索能力。\nstack主题\n增加search.html和search.json\n需要在 项目/layouts/_default 或者 主题/layouts/_default 存在两个文件（对于stack来说），分别是search.html和search.json。\n在我clone的stack版本中，这两个文件在_default并不存在，但是在/layouts/page下面是有的，所以从cp layouts/page/* layouts/_default\n成功的话，会在public/post/search目录下生成index.html index.json两个文件，主要是index.json文件\nfuse\n我有看过两个文章是使用fuse的，但是我自己都没有实验成功，加上对hugo的模板还不熟，先不折腾了。\n给hugo添加搜索功能 | 搜百谷\nhttps://ttys3.dev/blog/hugo-fast-search\nDocsy主题\n可以参考官方文档Search | Docsy\n修改总配置hugo.yaml outputs: home: - HTML - JSON page: - HTML - JSON 这里home和page两种kind都配置的原因是:\n假如你没有修改过总配置中的permalinks，那么你的博客的路径应该是 域名/p/文章名，这种情况下kind对应的是home类型\n但是假如你像我一下修改了permalinks，比如我改成了 post: /:sections/:slug，这个是为了让我的博客地址以路径+文件名来显示，但是由于有了层级关系，里面的博客文章的kind就变成了page，因此在配置的时候，将home和page两个都指定是最好的\n说实话，我其实还是不能理解这个kind的设计~\n增加评论功能： hugo支持许多评论框架，具体可以看hugo-comments|Comments | Stack，我选择的是\nTwikoo 建议跟着快速上手 | Twikoo 文档去部署一遍，我这里选用的是Hugging Face免费部署的方案。\n部署主要有两部分：一部分是生成一个mogodb的密钥串，二部分则是在hugging face上新建空间和项目，最终获得envId\n然后修改站点配置文件\nGitalk\nGitalk本身就依赖的是github的issue功能，因此不需要额外部署；但是需要创建一个OAuthApp\ncomments: enabled: true provider: gitalk twikoo: envId: https://你的项目空间.hf.space region: path: lang: gitalk: owner: github用户名 admin: github用户名 repo: 建议填博客项目，比如我的是qisiii.github.io clientID: OAuth\bApp创建得到 clientSecret: OAuth\bApp创建得到 自定义博客的路径名： slug: 一个正常的网址格式是下面这样的，其中路径的最后一段就是slug。\n\u0026lt;协议\u0026gt;://\u0026lt;主机名\u0026gt;/\u0026lt;路径\u0026gt;/\u0026lt;文件slug\u0026gt;?\u0026lt;查询字符串\u0026gt;#\u0026lt;片段\u0026gt;` 据说简短清晰的slug有助于SEO，但哪怕没有这个功能，我们的文件名很多时候也是中文的，经过编码后可读性太差。因此，设置一个简短的slug是很有必要的。\n建议在模板文件archetypes/default.md直接新增slug字段，这样就不用每个文件手动添加了\n+++ title = \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; description = \u0026#34;\u0026#34; date = {{ .Date }} image = \u0026#34;\u0026#34; draft = true slug = \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; +++ permalinks: 如果只设置slug，stack主题配置默认路径是 域名/p/slug这样子，其实对于文件的组织管理和展示路径依然不是很明朗，因此，我这里是以文件夹层级的方式生成路径。\n在总配置中，修改或者新增\npermalinks: post: /:sections/:slug 这里的:sections是指多个路径，但是hugo默认处理顶级目录会自动识别为section外，其他目录需要手动添加_index.md文件才行。\n通过Github Action进行部署 我这里是将hugo目录作为一个私有项目，而public下文件的作为github.io的pages项目，因此等于是要将hugo的public文件部署到github.io的配置下；并且我还指定了自定义域名，所以要额外添加CNAME配置，不然每次执行action，都不会生成CNAME文件\nname: GitHub Pages on: push: branches: - master # Set a branch to deploy pull_request: jobs: deploy: runs-on: ubuntu-20.04 concurrency: group: ${{ github.workflow }}-${{ github.ref }} steps: - uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.129.0\u0026#39; # 是否启用 hugo extend extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 if: ${{ github.ref == \u0026#39;refs/heads/master\u0026#39; }} with: PERSONAL_TOKEN: ${{ secrets.ACTION_TOKEN }} EXTERNAL_REPOSITORY: qisiii/qisiii.github.io # 你的GitHub Pages仓库 PUBLISH_BRANCH: master # 或者是你的GitHub Pages分支 PUBLISH_DIR: ./public commit_message: ${{ github.event.head_commit.message }} cname: custom.domain #这里填你配置页的自定义域名 基于 Github Action 自动构建 Hugo 博客 -\n【Hugo网站搭建】GitHub Action自动化部署Hugo博客 | Eddy's blog\nhttps://zenlian.github.io/github-actions-hugo/\n标签云增加数量统计\u0026amp;归档页增加标签云: Hugo Stack主题装修笔记\n增加返回顶部按钮： 添加一键返回顶部功能 | Dlog\n修改自己喜欢的指定按钮样式\n.top-link { position: fixed; bottom: 30px; right: 30px; z-index: 99; background: #066fd1; width: 35px; height: 35px; align-items: center; justify-content: center; padding: 7px; border-radius: 5px; transition: visibility .5s, opacity .8s linear; } 滚动到顶部时，需要隐藏置顶按钮，所以引用了jquery，处理逻辑\n\u0026lt;a href=\u0026#34;#top\u0026#34; aria-label=\u0026#34;go to top\u0026#34; class=\u0026#34;top-link\u0026#34; id=\u0026#34;top-link\u0026#34; accesskey=\u0026#34;g\u0026#34; style=\u0026#34;visibility: visible; opacity: 1;\u0026#34;\u0026gt; \u0026lt;svg xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34; width=\u0026#34;24\u0026#34; height=\u0026#34;24\u0026#34; viewBox=\u0026#34;0 0 24 24\u0026#34; fill=\u0026#34;none\u0026#34; stroke=\u0026#34;currentColor\u0026#34; stroke-width=\u0026#34;2\u0026#34; stroke-linecap=\u0026#34;round\u0026#34; stroke-linejoin=\u0026#34;round\u0026#34; class=\u0026#34;icon icon-tabler icons-tabler-outline icon-tabler-chevron-up\u0026#34;\u0026gt;\u0026lt;path stroke=\u0026#34;none\u0026#34; d=\u0026#34;M0 0h24v24H0z\u0026#34; fill=\u0026#34;none\u0026#34;/\u0026gt;\u0026lt;path d=\u0026#34;M6 15l6 -6l6 6\u0026#34; /\u0026gt;\u0026lt;/svg\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;script src=\u0026#34;https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; $(window).scroll(function(){ if($(this).scrollTop()\u0026gt;300){ $(\u0026#34;#top-link\u0026#34;).show() }else{ $(\u0026#34;#top-link\u0026#34;).hide() } }) \u0026lt;/script\u0026gt; 增加友链: 参考Hugo Stack主题装修笔记Part 2，结合自己的版本和主题略有修改\n我的links.html是放在 layouts/_default下才有效，在layouts/page下面没起效\ndata/json中指定的图片路径按博客所说需要放置在assets下再挂载到static中，我直接放在了static/link-img下\n菜单-友链需要格外的配置，这里的路径是你对应的文件，我这里不是新建了一个friend文件夹，然后在下面再创建index.md,而是在post下直接创建了个friend.md\n- identifier: friends name: 友链|Friends url: /post/friends weight: 2 params: icon: friends newTab: true bing和google的收录： bing 将 Github Pages 个人博客录入搜索引擎（以 Bing 为例） - RainbowC0 - 博客园\ngoogle Google搜索收录Github Pages（Blog可以被Google搜索到） | Marvin\u0026rsquo;s blog\n图片支持放大查看~~ Hexo 折腾：利用 Fancybox 添加图片放大预览查看功能 | Tianma\n网站添加favicon 截取成圆形图作物圈图像在线-最佳图像裁剪工具\n添加Favicon到Hugo的网站中\n通过githubWebHook通知服务器自动构建 使用 GitHub Webhook 实现静态网站自动化部署 · Jimmy Song\n添加备案 在foot.customText:添加 '\u0026lt;a href=\u0026quot;https://beian.miit.gov.cn/\u0026quot; target=\u0026quot;_blank\u0026quot;\u0026gt;京ICP备2023017017号-1\u0026lt;/a\u0026gt;'\n","date":"2024-08-10T16:32:55+08:00","permalink":"https://qisiii.github.io/post/site/hugo_stack_record/","title":"Hugo\u0026Stack主题的使用和装修记录"},{"content":"部署 在单机上部署伪集群，需要根据不同的配置文件启动不同的进程。\n#这是zoo1.cfg的内容 tickTime=2000 initLimit=10 syncLimit=5 dataDir=/opt/soft/zookeeper/data/1 clientPort=2181 #第一个端口号用于zk集群同步数据，第二个端口用于重新选举 server.1=127.0.0.1:2287:3387 server.2=127.0.0.1:2288:3388 server.3=127.0.0.1:2289:3389 #zoo2.cfg需要修改两个地方 clientPort=2182 dataDir=/opt/soft/zookeeper/data/2 #zoo3.cfg需要修改两个地方 clientPort=2183 dataDir=/opt/soft/zookeeper/data/3 在三个data目录下创建myid文件，内容只有单个数字代表当前zookeeper节点的myid,对应上面配置里server.id的id\ntouch 1/myid echo 1 \u0026gt;1/myid echo 2 \u0026gt;2/myid echo 3 \u0026gt;3/myid #启动三个进程 ./apache-zookeeper-3.7.1-bin/bin/zkServer.sh start conf/zoo1.cfg ./apache-zookeeper-3.7.1-bin/bin/zkServer.sh start conf/zoo2.cfg ./apache-zookeeper-3.7.1-bin/bin/zkServer.sh start conf/zoo3.cfg #然后可以查看三个节点的状态 选举逻辑： 集群模式的核心类是QuorumPeer，其启动方法中核心的就只有startLeaderElection和super.start这两个方法的调用\npublic synchronized void start() { if (!getView().containsKey(myid)) { throw new RuntimeException(\u0026#34;My id \u0026#34; + myid + \u0026#34; not in the peer list\u0026#34;); } loadDataBase(); //同单机逻辑一样 startServerCnxnFactory(); try { adminServer.start(); } catch (AdminServerException e) { LOG.warn(\u0026#34;Problem starting AdminServer\u0026#34;, e); } //创建QuorumCnxManager和FastLeaderElection两个类，一个是管理连接，一个是处理选举时收发消息 startLeaderElection(); startJvmPauseMonitor(); //真正的选举逻辑在这里，QuorumPeer也是个线程，所以要看run的逻辑 super.start(); } 其中，QuorumCnxManager负责节点之间的通信，节点中两两之间都需要建立连接。\nQuorumCnxManager通过给每个节点地址分配了一个ListenerHandler，来接受或者建立连接。ListenerHandler内的SendWorker和RecvWorker则是建立连接后进行真正进行发送和接受消息的类。\nFastLeaderElection是专门负责选举工作的，其内部针对于通信有两个组件，分别是workerSender和workerReceiver，这两个类只是负责将选票信息封装为ByteBuffer，然后转发到queueSendMap，由QuorumCnxManager的SendWorker去进行发送。\n建立连接 首次发起建立连接的地方是在FastLeaderElection发消息前，如果判断没有建立好连接，就要建立连接\npublic void toSend(Long sid, ByteBuffer b) { if (this.mySid == sid) { b.position(0); //发给自己的消息，直接添加到接受队列，不走网络请求了 addToRecvQueue(new Message(b.duplicate(), sid)); /* * Otherwise send to the corresponding thread to send. */ } else { BlockingQueue\u0026lt;ByteBuffer\u0026gt; bq = queueSendMap.computeIfAbsent(sid, serverId -\u0026gt; new CircularBlockingQueue\u0026lt;\u0026gt;(SEND_CAPACITY)); addToSendQueue(bq, b); //发消息给其他节点之前要建立连接 connectOne(sid); } } synchronized void connectOne(long sid) { //如果已经存在连接，直接返回；senderWorkerMap中存在对应的senderWorker类表明已经建立好连接 if (senderWorkerMap.get(sid) != null) { LOG.debug(\u0026#34;There is a connection already for server {}\u0026#34;, sid); if (self.isMultiAddressEnabled() \u0026amp;\u0026amp; self.isMultiAddressReachabilityCheckEnabled()) { senderWorkerMap.get(sid).asyncValidateIfSocketIsStillReachable(); } return; } 建立的逻辑，就不细分析了；主要是通过QuorumConnectionReqThread类去实现的，且当建立成功后会在senderWorkerMap中存储对应的线程，对应上面代码判断存在线程直接返回。\n接受连接请求的地方就是在ListenerHandler中\n由于是每两个节点都要建立连接，且两个节点都可能发起连接，那么以哪个为主呢？zookeeper的设计是以myId大的为主，即只能myid大的发起连接，这样才会判定有效\nif (sid \u0026lt; self.getMyId()) { SendWorker sw = senderWorkerMap.get(sid); if (sw != null) { sw.finish(); } /* * Now we start a new connection */ LOG.debug(\u0026#34;Create new connection to server: {}\u0026#34;, sid); closeSocket(sock); //如果是小id连大id，那就重新建立连接 if (electionAddr != null) { connectOne(sid, electionAddr); } else { connectOne(sid); } } else if (sid == self.getMyId()) { // we saw this case in ZOOKEEPER-2164 LOG.warn(\u0026#34;We got a connection request from a server with our own ID. \u0026#34; + \u0026#34;This should be either a configuration error, or a bug.\u0026#34;); } else { // Otherwise start worker threads to receive data. SendWorker sw = new SendWorker(sock, sid); RecvWorker rw = new RecvWorker(sock, din, sid, sw); sw.setRecv(rw); SendWorker vsw = senderWorkerMap.get(sid); if (vsw != null) { vsw.finish(); } senderWorkerMap.put(sid, sw); queueSendMap.putIfAbsent(sid, new CircularBlockingQueue\u0026lt;\u0026gt;(SEND_CAPACITY)); sw.start(); rw.start(); } 选举 ELECTION 选举\nVote 是选票的意思，结构是（myid,LastZxid,currentEpoch）(节点id，最大事务id，当前周期)\nEpoch 直译是纪元、时期，我理解是当前周期，类比于第15届领导中的这个15，选票需要表明这个是为哪期领导投票的\nServerState 节点状态\npublic enum ServerState { LOOKING,//正在选举 FOLLOWING,//节点处理跟从者状态，拥有投票的权利 LEADING,//节点处于领导状态，拥有投票的权利 OBSERVING//观察者,节点无投票权利 } QuorumPeer本身就是一个线程，其真正的选举逻辑也在run方法中，去除掉杂七杂八的逻辑后，其核心逻辑如下：\n默认是LOOKING状态，所以会进入到LOOKING的分支：根据readonlymode.enabled决定是否启动一个只读的服务器，然后进入选举，核心代码是setCurrentVote(makeLEStrategy().lookForLeader());\n当选举结果出来之后，每个节点会更改自身的状态，所以会进入到其他分支，处理不同的逻辑，以Leader为例，会创建一个LeaderZooKeeperServer来接受客户端请求，并做好一些转发工作等，这里先不展开讲。\npublic void run() { while (running) { switch (getPeerState()) { case LOOKING: LOG.info(\u0026#34;LOOKING\u0026#34;); ServerMetrics.getMetrics().LOOKING_COUNT.add(1); if (Boolean.getBoolean(\u0026#34;readonlymode.enabled\u0026#34;)) { LOG.info(\u0026#34;Attempting to start ReadOnlyZooKeeperServer\u0026#34;); //选举期间启动一个只读的server，不提供写的能力，其processor是ReadOnlyRequestProcessor final ReadOnlyZooKeeperServer roZk = new ReadOnlyZooKeeperServer(logFactory, this, this.zkDb); roZk.startup(); try { //发起选举并记录最终成功的选票 setCurrentVote(makeLEStrategy().lookForLeader()); checkSuspended(); } finally { roZkMgr.interrupt(); roZk.shutdown(); } } else { setCurrentVote(makeLEStrategy().lookForLeader()); } break; case OBSERVING: try { LOG.info(\u0026#34;OBSERVING\u0026#34;); setObserver(makeObserver(logFactory)); observer.observeLeader(); } catch (Exception e) { LOG.warn(\u0026#34;Unexpected exception\u0026#34;, e); } finally { observer.shutdown(); setObserver(null); updateServerState(); break; case FOLLOWING: try { LOG.info(\u0026#34;FOLLOWING\u0026#34;); setFollower(makeFollower(logFactory)); follower.followLeader(); } catch (Exception e) { LOG.warn(\u0026#34;Unexpected exception\u0026#34;, e); } finally { follower.shutdown(); setFollower(null); updateServerState(); } break; case LEADING: LOG.info(\u0026#34;LEADING\u0026#34;); try { setLeader(makeLeader(logFactory)); leader.lead(); setLeader(null); } catch (Exception e) { LOG.warn(\u0026#34;Unexpected exception\u0026#34;, e); } finally { if (leader != null) { leader.shutdown(\u0026#34;Forcing shutdown\u0026#34;); setLeader(null); } updateServerState(); } break; } } } 下面具体分析一下选举逻辑\nmakeLEStrategy().lookForLeader()实际上是FastLeaderElection.lookForLeader\n选票PK逻辑： 周期大的为准\n同周期的情况下，以事务Id大的为准\n同周期同事务的情况下，以myid大的为准\nprotected boolean totalOrderPredicate(long newId, long newZxid, long newEpoch, long curId, long curZxid, long curEpoch) { //myid对应的权重为0，表示不算选票 if (self.getQuorumVerifier().getWeight(newId) == 0) { return false; } return ((newEpoch \u0026gt; curEpoch) || ((newEpoch == curEpoch) \u0026amp;\u0026amp; ((newZxid \u0026gt; curZxid) || ((newZxid == curZxid) \u0026amp;\u0026amp; (newId \u0026gt; curId))))); } lookForLeader流程图： public Vote lookForLeader() throws InterruptedException { try { //选举期间每个节点的选票集合 Map\u0026lt;Long, Vote\u0026gt; recvset = new HashMap\u0026lt;\u0026gt;(); //选举成功之后的选票存储在这里，是在其他节点发消息时存储的，可以让迟到的节点立马知道谁是领导 Map\u0026lt;Long, Vote\u0026gt; outofelection = new HashMap\u0026lt;\u0026gt;(); int notTimeout = minNotificationInterval; synchronized (this) { //选举周期的具体值，用于和其他节点选票中的周期比较 logicalclock.incrementAndGet(); //更新提案-其实就是更新选票 updateProposal(getInitId(), getInitLastLoggedZxid(), getPeerEpoch()); } //发送投票 sendNotifications(); SyncedLearnerTracker voteSet = null; while ((self.getPeerState() == ServerState.LOOKING) \u0026amp;\u0026amp; (!stop)) { //收取选票消息 Notification n = recvqueue.poll(notTimeout, TimeUnit.MILLISECONDS); if (n == null) { //假如所有连接的待发送消息都发送了，就可以再次尝试发消息了 if (manager.haveDelivered()) { sendNotifications(); } else { //没有的话就代表有些连接还没建立，去建立连接 manager.connectAll(); } notTimeout = Math.min(notTimeout \u0026lt;\u0026lt; 1, maxNotificationInterval); //这里没理解这个timeout的作用 if (self.getQuorumVerifier() instanceof QuorumOracleMaj \u0026amp;\u0026amp; self.getQuorumVerifier().revalidateVoteset(voteSet, notTimeout != minNotificationInterval)) { setPeerState(proposedLeader, voteSet); Vote endVote = new Vote(proposedLeader, proposedZxid, logicalclock.get(), proposedEpoch); leaveInstance(endVote); return endVote; } } else if (validVoter(n.sid) \u0026amp;\u0026amp; validVoter(n.leader)) { switch (n.state) { case LOOKING: //当选举周期大于当前节点的周期时，选举周期更新 if (n.electionEpoch \u0026gt; logicalclock.get()) { logicalclock.set(n.electionEpoch); recvset.clear(); //比拼选票，赢了按我的来，输了按你的来 if (totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, getInitId(), getInitLastLoggedZxid(), getPeerEpoch())) { updateProposal(n.leader, n.zxid, n.peerEpoch); } else { updateProposal(getInitId(), getInitLastLoggedZxid(), getPeerEpoch()); } sendNotifications(); //如果选举周期小于当前节点的周期，直接不予响应 } else if (n.electionEpoch \u0026lt; logicalclock.get()) { break; //周期相等就pk吧 } else if (totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, proposedLeader, proposedZxid, proposedEpoch)) { updateProposal(n.leader, n.zxid, n.peerEpoch); sendNotifications(); } //记录每个节点的选票 recvset.put(n.sid, new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch)); //每次收到消息都要重新统计，正常来讲应该只有一个Tacker voteSet = getVoteTracker(recvset, new Vote(proposedLeader, proposedZxid, logicalclock.get(), proposedEpoch)); //有结果了，值超过半数票 if (voteSet.hasAllQuorums()) { //当不再有新消息时，表明选举成功；当还有新消息时，判断投票是否有效，有效的话再次轮回 // Verify if there is any change in the proposed leader while ((n = recvqueue.poll(finalizeWait, TimeUnit.MILLISECONDS)) != null) { //最终校验 if (totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, proposedLeader, proposedZxid, proposedEpoch)) { recvqueue.put(n); break; } } //不再有新的比当前领导票更新的消息了，那就以当前领导为准 if (n == null) { //设置节点状态 setPeerState(proposedLeader, voteSet); Vote endVote = new Vote(proposedLeader, proposedZxid, logicalclock.get(), proposedEpoch); leaveInstance(endVote); return endVote; } } break; case OBSERVING: break; case FOLLOWING: //收到follower的消息，有follower就代表有leader了,所以更新自己的状态 Vote resultFN = receivedFollowingNotification(recvset, outofelection, voteSet, n); if (resultFN == null) { break; } else { return resultFN; } case LEADING: //收到leader的消息，表明半数人已经同意了，直接更新自己的leader Vote resultLN = receivedLeadingNotification(recvset, outofelection, voteSet, n); VoteTracker 该类是选票记录器，主要工作是在当前节点确定了自己的选票后，统计所有节点选票和自己选票相符的数量，可以理解为画正\nprotected SyncedLearnerTracker getVoteTracker(Map\u0026lt;Long, Vote\u0026gt; votes, Vote vote) { //这里原则上其实只有1个的，但是假如LastSeenQuorumVerifier有值，就也要参考 SyncedLearnerTracker voteSet = new SyncedLearnerTracker(); voteSet.addQuorumVerifier(self.getQuorumVerifier()); if (self.getLastSeenQuorumVerifier() != null \u0026amp;\u0026amp; self.getLastSeenQuorumVerifier().getVersion() \u0026gt; self.getQuorumVerifier().getVersion()) { voteSet.addQuorumVerifier(self.getLastSeenQuorumVerifier()); } //比如我的选票投给2，那么统计所有选票为2的节点 for (Map.Entry\u0026lt;Long, Vote\u0026gt; entry : votes.entrySet()) { if (vote.equals(entry.getValue())) { voteSet.addAck(entry.getKey()); } } return voteSet; } //判断同意的票数是否大于一半 public boolean hasAllQuorums() { for (QuorumVerifierAcksetPair qvAckset : qvAcksetPairs) { if (!qvAckset.getQuorumVerifier().containsQuorum(qvAckset.getAckset())) { return false; } } return true; } public boolean containsQuorum(Set\u0026lt;Long\u0026gt; ackSet) { //超过半数 return (ackSet.size() \u0026gt; half); } ReadOnlyZookeeperServer 当处于选举状态时，假如readonlymode.enabled为true，那么就创建一个只读的服务器，该服务器只提供查询，不能写入。\n在zookeeper学习-单机模式中，我们知道zkserver是由三个processor处理的，其中SyncRequestProcessor是处理事务的，将事务写入日志里。而在只读模式下可以看到，不存在这个processor，所以只能查，不能写。\nprotected void setupRequestProcessors() { RequestProcessor finalProcessor = new FinalRequestProcessor(this); RequestProcessor prepProcessor = new PrepRequestProcessor(this, finalProcessor); ((PrepRequestProcessor) prepProcessor).start(); firstProcessor = new ReadOnlyRequestProcessor(this, prepProcessor); ((ReadOnlyRequestProcessor) firstProcessor).start(); } 对于所有的写入命令，都直接抛异常\n当然了，这也只是选举期间的一个临时措施，在选举结束后会关闭该服务器，并创建对应节点状态的服务器。\n参考文档: Zookeeper系列 - Leader选举_zk集群查看哪个节点是leader-CSDN博客\nZooKeeper: Because Coordinating Distributed Systems is a Zoo\nzookeeper（单机、伪集群、集群）部署-腾讯云开发者社区-腾讯云\nZookeeper的安装和使用 - 商商-77 - 博客园\n【Zookeeper源码阅读】leader选举源码分析 - 掘金\n【图解源码】Zookeeper3.7源码剖析，Session的管理机制，Leader选举投票规则，集群数据同步流程 - 掘金\n","date":"2024-08-09T18:01:30+08:00","permalink":"https://qisiii.github.io/post/tech/distributed/zookeeper/election/","title":"Zookeeper源码分析-选举机制"},{"content":"Zookeeper框架设计了一种叫做watch的机制，客户端可以给某个节点添加watcher，当节点改变的时候，服务端会推送一个消息到客户端。\n在3.6.0之前的版本，node上的watcher都是一次性的，即当收到服务端的通知后，如果还想监听需要再次设置，在3.6.0之后，可以设置一个永久且递归的watcher。\n这个技术是很有用的，比如在dubbo中，consumer端可以只关注自己感兴趣的provider，而不用关心全部的provider，本文就来梳理一下这个watch机制。\n目前普通的方法，watch机制仅允许在getData、exist、getChildren这三个方法调用的时候进行添加。或者直接调用addWatch方法给指定节点添加watcher。\n当我们使用的时候，可以自定义watcher的逻辑，也可以使用创建zookeeper时指定的watcher逻辑。\n//使用默认的watch zookeeper.getData(nodePath, true, null); zookeeper.addWatch(nodePath,AddWatchMode.PERSISTENT); //使用自定义逻辑 zookeeper.getData(nodePath, watchedEvent-\u0026gt;{ if(watchedEvent.getType()==Watcher.Event.EventType.NodeCreated){ System.out.println(\u0026#34;新增节点\u0026#34;+watchedEvent.getPath()); } if(watchedEvent.getType()==Watcher.Event.EventType.NodeDeleted){ System.out.println(\u0026#34;删除节点\u0026#34;+watchedEvent.getPath()); } },null); zookeeper.addWatch(nodePath,watchedEvent-\u0026gt;{ //业务逻辑 },AddWatchMode.PERSISTENT); 客户端 zookeeper的客户端本质上也是一个socket客户端，主要分为两个线程，一个是sendThread，主要用于发送和接受消息。另一个则是eventThread，就是用来处理诸如watcher的回调信息的。\n当我们通过getData方法添加了一个watcher时，底层做了两件事情：\n一是在request中标识watch为true，告诉服务端我对于这个路径注册了watcher\n二是当请求执行完的时候，将watcher添加到watchManager中的集合中去。\n当收到服务端回调的时候，本质上是一个code为NOTIFICATION_XID的消息，在sendThread接收到消息后，会通过调用EventThread的queueEvent方法通过队列解耦，让eventThread去异步处理事件\nprivate void queueEvent(WatchedEvent event, Set\u0026lt;Watcher\u0026gt; materializedWatchers) { if (event.getType() == EventType.None \u0026amp;\u0026amp; sessionState == event.getState()) { return; } sessionState = event.getState(); final Set\u0026lt;Watcher\u0026gt; watchers; if (materializedWatchers == null) { // 会根据路径找到本地存储的对应的watcher watchers = watchManager.materialize(event.getState(), event.getType(), event.getPath()); } else { watchers = new HashSet\u0026lt;\u0026gt;(materializedWatchers); } WatcherSetEventPair pair = new WatcherSetEventPair(watchers, event); // 添加到队列去异步处理 waitingEvents.add(pair); } 服务端 服务端核心的类是WatchManager。在DataTree类中实例化了两个对象，分别是dataWatchers（对应getData)和childWatches(对应getChildren)\n而服务端又将watcher分为三种类型:普通、持久、持久且递归，后两种只能通过zookeeper.addWatch来指定\npublic enum WatcherMode { STANDARD(false, false), PERSISTENT(true, false), PERSISTENT_RECURSIVE(true, true), ; 当接收到getData、exist、getChildren、setWatcher的请求时,会调用WatchManager的两个addWatch重载方法中的一个，将其添加到watchTable的map中，key为nodePath，value是watcher的集合。\n这里需要强调一下！map中的value虽然类型是Watcher，但是其本质上确实一个socket连接，即客户端和服务端的连接。\n以getData为例追溯一下这个watcher的赋值\n这里又对应上客户端组装request时，给watch赋值的情况\n当发生了对应的事件，比如createNode、deleteNode、setData等变更事件时，会调用WatchManager.triggerWatch方法来触达\n这里先了解一下WatchStats是什么，其实就是各个模式的组合，然后看源码\npublic WatcherOrBitSet triggerWatch(String path, EventType type, long zxid, WatcherOrBitSet supress) { WatchedEvent e = new WatchedEvent(type, KeeperState.SyncConnected, path, zxid); Set\u0026lt;Watcher\u0026gt; watchers = new HashSet\u0026lt;\u0026gt;(); synchronized (this) { PathParentIterator pathParentIterator = getPathParentIterator(path); for (String localPath : pathParentIterator.asIterable()) { //取出path对应的watcher Set\u0026lt;Watcher\u0026gt; thisWatchers = watchTable.get(localPath); if (thisWatchers == null || thisWatchers.isEmpty()) { continue; } Iterator\u0026lt;Watcher\u0026gt; iterator = thisWatchers.iterator(); while (iterator.hasNext()) { Watcher watcher = iterator.next(); //取出watch对应的监听模式 Map\u0026lt;String, WatchStats\u0026gt; paths = watch2Paths.getOrDefault(watcher, Collections.emptyMap()); WatchStats stats = paths.get(localPath); if (stats == null) { LOG.warn(\u0026#34;inconsistent watch table for watcher {}, {} not in path list\u0026#34;, watcher, localPath); continue; } if (!pathParentIterator.atParentPath()) { //添加到待处理的集合 watchers.add(watcher); //移除标准模式的watcher，这也是为什么普通的watcher是一次性的原因 WatchStats newStats = stats.removeMode(WatcherMode.STANDARD); //如果完全没有任何模式的监听，则移除该watcher if (newStats == WatchStats.NONE) { iterator.remove(); paths.remove(localPath); } else if (newStats != stats) { paths.put(localPath, newStats); } //处理持久且递归的情况 } else if (stats.hasMode(WatcherMode.PERSISTENT_RECURSIVE)) { watchers.add(watcher); } } if (thisWatchers.isEmpty()) { watchTable.remove(localPath); } } } ... for (Watcher w : watchers) { if (supress != null \u0026amp;\u0026amp; supress.contains(w)) { continue; } //通知客户端 w.process(e); } //最终其实就是发送了一个code为NOTIFICATION_XID的消息到客户端 public void process(WatchedEvent event) { ReplyHeader h = new ReplyHeader(ClientCnxn.NOTIFICATION_XID, event.getZxid(), 0); WatcherEvent e = event.getWrapper(); int responseSize = sendResponse(h, e, \u0026#34;notification\u0026#34;, null, null, ZooDefs.OpCode.error); ServerMetrics.getMetrics().WATCH_BYTES.add(responseSize); } 至此，和客户端完成闭环。\n","date":"2024-08-08T23:34:10+08:00","permalink":"https://qisiii.github.io/post/tech/distributed/zookeeper/watch/","title":"Zookeeper源码分析-watch机制"},{"content":"调试前准备 对于大部分的开源项目，一般都可以从其启动shell脚本中分析出来java启动类。我这里clone源码后以tag 3.9.1为主创建了一个分支，方便注释，调试。\n在bin/zkServer.sh脚本中，其启动逻辑如下，如果是执行的./zkServer.sh start的话，最终执行的命令大概是\nnohup java [一堆参数] org.apache.zookeeper.server.quorum.QuorumPeerMain [输出日志],ZOOMAIN变量可以往上溯源，四个出现的地方最终都是QuorumPeerMain类。因此QuorumPeerMain类就是zookeeper的启动类。\ncase $1 in start) echo -n \u0026#34;Starting zookeeper ... \u0026#34; if [ -f \u0026#34;$ZOOPIDFILE\u0026#34; ]; then if kill -0 `cat \u0026#34;$ZOOPIDFILE\u0026#34;` \u0026gt; /dev/null 2\u0026gt;\u0026amp;1; then echo $command already running as process `cat \u0026#34;$ZOOPIDFILE\u0026#34;`. exit 1 fi fi nohup \u0026#34;$JAVA\u0026#34; $ZOO_DATADIR_AUTOCREATE \u0026#34;-Dzookeeper.log.dir=${ZOO_LOG_DIR}\u0026#34; \\ \u0026#34;-Dzookeeper.log.file=${ZOO_LOG_FILE}\u0026#34; \\ -XX:+HeapDumpOnOutOfMemoryError -XX:OnOutOfMemoryError=\u0026#39;kill -9 %p\u0026#39; \\ # $ZOOMAIN= org.apache.zookeeper.server.quorum.QuorumPeerMain -cp \u0026#34;$CLASSPATH\u0026#34; $JVMFLAGS $ZOOMAIN \u0026#34;$ZOOCFG\u0026#34; \u0026gt; \u0026#34;$_ZOO_DAEMON_OUT\u0026#34; 2\u0026gt;\u0026amp;1 \u0026lt; /dev/null \u0026amp; 知道启动类之后，就要进入debug模式进行调试，这里有两个点需要注意：\n设置启动参数\n由于shell脚本通过命令行模式执行的时候拼接了非常多的参数，虽然大部分参数都可以忽略，但是config参数确是必须的，即ZOOMAIN 后的 \u0026ldquo;ZOOCFG\u0026rdquo;。因此在通过idea等编辑器进行debug的时候，要设置program arguments为zk的配置文件(这里的zoo.cfg是复制的zoo_sample.cfg)\n启动时报类找不到，编译失败\n这是由于在pom文件中，有部分依赖的scope是provider类型，即zk项目本身不提供，由依赖方提供。我这里为了省事，将zookeeper-server的pom.xml里所有\u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt;都够注释掉了\n当涉及到客户端和服务端通信时，建议session过期时间设置的长一些，不然在debug的时候总是会session过期，连接关闭\n但是由于有最大限制，因此建议临时注释掉最大限制的逻辑\n源码分析 QuorumPeerMain QuorumPeerMain类的逻辑相对简单，需要注意的是集群和单机两种模式走的是不同的逻辑。下面我会先分析单机模式熟悉结构后，再去看集群模式。\npublic static void main(String[] args) { QuorumPeerMain main = new QuorumPeerMain(); try { main.initializeAndRun(args); } protected void initializeAndRun(String[] args) throws ConfigException, IOException, AdminServerException { //args[0]一般是zk的配置文件zoo.cfg,即这里将配置文件转换为javaBean QuorumPeerConfig config = new QuorumPeerConfig(); if (args.length == 1) { config.parse(args[0]); } // Start and schedule the the purge task //通过定时执行PurgeTask来清楚data数据和datalog数据 DatadirCleanupManager purgeMgr = new DatadirCleanupManager( config.getDataDir(), config.getDataLogDir(), config.getSnapRetainCount(), config.getPurgeInterval()); purgeMgr.start(); // 集群和单机两种方式 if (args.length == 1 \u0026amp;\u0026amp; config.isDistributed()) { runFromConfig(config); } else { LOG.warn(\u0026#34;Either no config or no quorum defined in config, running in standalone mode\u0026#34;); // there is only server in the quorum -- run as standalone //单机模式 ZooKeeperServerMain.main(args); } } ZooKeeperServerMain 单机版的组件主要如上图所示。\nAdminServer: zk通过jetty简单实现了一个后端admin，可通过http://localhost:8080/commands去进行一些操作。\nMetricsProvider：用于记录、监控一些指标，本文不做分析\nJvmPauseMonitor: 来源于hadoop的一个监控，有个线程一直死循环，当判断系统暂停时间大于一定指标，打印一条信息\nJMX: java所提供的jmx\nQuorumPeerConfig: 读取的是zoo.cfg，服务于zk集群模式\nServerConfig: 读取的也是zoo.cfg，但是仅限于zk单机模式，且主要服务于通信组件\n启动入口 final ZooKeeperServer zkServer = new ZooKeeperServer(jvmPauseMonitor, txnLog, config.tickTime, config.minSessionTimeout, config.maxSessionTimeout, config.listenBacklog, null, config.initialConfig); boolean needStartZKServer = true; if (config.getClientPortAddress() != null) { cnxnFactory = ServerCnxnFactory.createFactory();//默认是NIOServerCnxnFactory cnxnFactory.configure(config.getClientPortAddress(), config.getMaxClientCnxns(), config.getClientPortListenBacklog(), false); //启动入口 cnxnFactory.startup(zkServer); // zkServer has been started. So we don\u0026#39;t need to start it again in secureCnxnFactory. needStartZKServer = false; } public void startup(ZooKeeperServer zks, boolean startServer) throws IOException, InterruptedException { //启动socket相关的线程 start(); setZooKeeperServer(zks); if (startServer) { //启动zkDataBase zks.startdata(); //启动其他组件（限流、processor、session、jmx等） zks.startup(); } } 通信流程 ServerCnxnFactory public void start() { stopped = false; if (workerPool == null) { workerPool = new WorkerService(\u0026#34;NIOWorker\u0026#34;, numWorkerThreads, false); } for (SelectorThread thread : selectorThreads) { if (thread.getState() == Thread.State.NEW) { thread.start(); } } // ensure thread is started once and only once if (acceptThread.getState() == Thread.State.NEW) { acceptThread.start(); } if (expirerThread.getState() == Thread.State.NEW) { expirerThread.start(); } } ServerCnxnFactory主要负责socket相关的部分，从start方法可以看出，zk的serverSocket设计为了四种线程，acceptThread来监听accept事件，selectorThread监听读写io，workerPool负责处理IO，expirerThread负责处理过期的连接。\nAcceptThread AcceptThread只处理accept事件，且通过队列进行解耦。\nprivate boolean doAccept() { boolean accepted = false; SocketChannel sc = null; try { //获取到socketChannel sc = acceptSocket.accept(); accepted = true; //中间会校验一下是否达到最大连接 sc.configureBlocking(false); //建立连接后分配给selector线程，轮询分配 // Round-robin assign this connection to a selector thread if (!selectorIterator.hasNext()) { selectorIterator = selectorThreads.iterator(); } SelectorThread selectorThread = selectorIterator.next(); //将新accept的socket传递给selector if (!selectorThread.addAcceptedConnection(sc)) { throw new IOException(\u0026#34;Unable to add connection to selector queue\u0026#34; + (stopped ? \u0026#34; (shutdown in progress)\u0026#34; : \u0026#34;\u0026#34;)); } acceptErrorLogger.flush(); } return accepted; } } public boolean addAcceptedConnection(SocketChannel accepted) { //将socket放入acceptedQueue，在selectorThread进行处理 if (stopped || !acceptedQueue.offer(accepted)) { return false; } //唤醒阻塞在selectorThread上的select方法 wakeupSelector(); return true; } SelectorThread public void run() { try { while (!stopped) { try { //处理读写IO事件 select(); //新accept的socket注册read事件 processAcceptedConnections(); //暂时没理解透下面这个方法 processInterestOpsUpdateRequests(); } }}} private void select() { try { //当收到accept事件或者由wakeupSelector()唤醒selector，下面的循环可能有事件，也可能没有事件，有事件优先处理，没有的话跳出select方法，去给新accept的socket注册read事件 selector.select(); Set\u0026lt;SelectionKey\u0026gt; selected = selector.selectedKeys(); ArrayList\u0026lt;SelectionKey\u0026gt; selectedList = new ArrayList\u0026lt;\u0026gt;(selected); Collections.shuffle(selectedList); Iterator\u0026lt;SelectionKey\u0026gt; selectedKeys = selectedList.iterator(); while (!stopped \u0026amp;\u0026amp; selectedKeys.hasNext()) { SelectionKey key = selectedKeys.next(); selected.remove(key); if (!key.isValid()) { cleanupSelectionKey(key); continue; } if (key.isReadable() || key.isWritable()) { //处理IO，其实是将key包装为request扔到workerpool handleIO(key); } else { LOG.warn(\u0026#34;Unexpected ops in select {}\u0026#34;, key.readyOps()); } } } private void processAcceptedConnections() { SocketChannel accepted; while (!stopped \u0026amp;\u0026amp; (accepted = acceptedQueue.poll()) != null) { SelectionKey key = null; try { //当前socket注册read事件 key = accepted.register(selector, SelectionKey.OP_READ); //根据socketChannel创建连接 NIOServerCnxn cnxn = createConnection(accepted, key, this); //这里key持有了cnxn，这样在处理io的时候才能获取到对应对象 key.attach(cnxn); addCnxn(cnxn); } catch (IOException e) { // register, createConnection cleanupSelectionKey(key); fastCloseSock(accepted); } } } expirerThread public void run() { try { while (!stopped) { long waitTime = cnxnExpiryQueue.getWaitTime(); if (waitTime \u0026gt; 0) { Thread.sleep(waitTime); continue; } //关闭过期的链接 for (NIOServerCnxn conn : cnxnExpiryQueue.poll()) { ServerMetrics.getMetrics().SESSIONLESS_CONNECTIONS_EXPIRED.add(1); conn.close(ServerCnxn.DisconnectReason.CONNECTION_EXPIRED); } } } catch (InterruptedException e) { LOG.info(\u0026#34;ConnnectionExpirerThread interrupted\u0026#34;); } } expirer线程的run逻辑是很简单的，就是从一个队列取出过期的连接，并进行关闭。程序会通过touchCnxn方法，来延长连接的过期时间。touchCnxn方法在创建连接，处理IO事件的前后都会调用。\n由于连接和session的过期机制都是一样的，所以这里先不分析cnxnExpiryQueue.poll和cnxnExpiryQueue.update方法，在下面讲到sessionTrack的时候进行分析\npublic void touchCnxn(NIOServerCnxn cnxn) { cnxnExpiryQueue.update(cnxn, cnxn.getSessionTimeout()); } workPool worker线程的核心任务，是将socket中的数据读取并封装为request，然后交由processor去处理。\nvoid doIO(SelectionKey k) throws InterruptedException { try { //前4个字节用来记录长度 if (k.isReadable()) { //将消息长度写到incomingBuffer，返回值小于0表示没有读到消息长度 int rc = sock.read(incomingBuffer); if (rc \u0026lt; 0) { handleFailedRead(); } //正常来讲，消息长度占4个字节，所以此时limit==position if (incomingBuffer.remaining() == 0) { boolean isPayload; //这里没有特别理解，incomingBuffer什么情况下才会不等于呢？？ if (incomingBuffer == lenBuffer) { // start of next request //变成读模式，会在readLength读到incomingBuffer写入的数据（即长度） incomingBuffer.flip(); //incomingBuffer在这里会重新分配 isPayload = readLength(k); incomingBuffer.clear(); } else { // continuation isPayload = true; } if (isPayload) { // not the case for 4letterword //读取具体的数据 readPayload(); } else { // four letter words take care // need not do anything else return; } } } private boolean readLength(SelectionKey k) throws IOException { // Read the length, now get the buffer //获取到数据长度 int len = lenBuffer.getInt(); zkServer.checkRequestSizeWhenReceivingMessage(len); //重新分配长度 incomingBuffer = ByteBuffer.allocate(len); return true; } private void readPayload() throws IOException, InterruptedException, ClientCnxnLimitException { //刚分配了新的空间，所以这里一定不等于0，因此可以将socket剩余信息写到incomingBuffer if (incomingBuffer.remaining() != 0) { // have we read length bytes? int rc = sock.read(incomingBuffer); // sock is non-blocking, so ok if (rc \u0026lt; 0) { handleFailedRead(); } } //incomingBuffer已经写完数据了，所以下面就是flip后再读数据了 if (incomingBuffer.remaining() == 0) { // have we read length bytes? incomingBuffer.flip(); packetReceived(4 + incomingBuffer.remaining()); if (!initialized) { //只在这里面会将initialized设置为true，所以第一次建立连接一定会走进来 readConnectRequest(); } else { readRequest(); } lenBuffer.clear(); incomingBuffer = lenBuffer; } } 当建立连接后第一次处理io会走到readConnectRequest方法，这个方法封装的是ConnectRequest，由processConnectRequest进行处理\nBinaryInputArchive bia = BinaryInputArchive.getArchive(new ByteBufferInputStream(incomingBuffer)); ConnectRequest request = protocolManager.deserializeConnectRequest(bia); zkServer.processConnectRequest(this, request); 其他时候会走到readRequest，封装的是普通的RequestRecord，由processPacket进行处理\nRequestHeader h = new RequestHeader(); ByteBufferInputStream.byteBuffer2Record(incomingBuffer, h); RequestRecord request = RequestRecord.fromBytes(incomingBuffer.slice()); zkServer.processPacket(this, h, request); processConnectRequest最核心的工作就是创建了session，并封装了个createSession的request进行处理\nif (sessionId == 0) { long id = createSession(cnxn, passwd, sessionTimeout); long createSession(ServerCnxn cnxn, byte[] passwd, int timeout) { if (passwd == null) { // Possible since it\u0026#39;s just deserialized from a packet on the wire. passwd = new byte[0]; } long sessionId = sessionTracker.createSession(timeout); Random r = new Random(sessionId ^ superSecret); r.nextBytes(passwd); CreateSessionTxn txn = new CreateSessionTxn(timeout); cnxn.setSessionId(sessionId); Request si = new Request(cnxn, sessionId, 0, OpCode.createSession, RequestRecord.fromRecord(txn), null); submitRequest(si);//所以首次创建session最终还是会走到submitRequest return sessionId; } processPacket的工作则是进行认证校验和request转发\npublic void processPacket(ServerCnxn cnxn, RequestHeader h, RequestRecord request) throws IOException { //除了校验之外则是正常的请求转发 if (h.getType() == OpCode.auth) { ... } else if (h.getType() == OpCode.sasl) { ... } else { if (!authHelper.enforceAuthentication(cnxn, h.getXid())) { // Authentication enforcement is failed // Already sent response to user about failure and closed the session, lets return return; } else { Request si = new Request(cnxn, cnxn.getSessionId(), h.getXid(), h.getType(), request, cnxn.getAuthInfo()); int length = request.limit(); if (isLargeRequest(length)) { // checkRequestSize will throw IOException if request is rejected checkRequestSizeWhenMessageReceived(length); si.setLargeRequestSize(length); } si.setOwner(ServerCnxn.me); //正常的请求则会从这里进去 submitRequest(si); } } } 至此，我们发现都会走到submitRequest方法，而这个方法的逻辑则是将request扔到节流器\npublic void submitRequest(Request si) { if (restoreLatch != null) { try { LOG.info(\u0026#34;Blocking request submission while restore is in progress\u0026#34;); restoreLatch.await(); } catch (final InterruptedException e) { LOG.warn(\u0026#34;Unexpected interruption\u0026#34;, e); } } enqueueRequest(si);//会将request扔到throttler的submittedRequests } public void enqueueRequest(Request si) { if (requestThrottler == null) { synchronized (this) { try { // Since all requests are passed to the request // processor it should wait for setting up the request // processor chain. The state will be updated to RUNNING // after the setup. while (state == State.INITIAL) { wait(1000); } } catch (InterruptedException e) { LOG.warn(\u0026#34;Unexpected interruption\u0026#34;, e); } if (requestThrottler == null) { throw new RuntimeException(\u0026#34;Not started\u0026#34;); } } } requestThrottler.submitRequest(si); } RequestThrottler throttler的创建和启动是在startupWithServerState方法中\nprivate void startupWithServerState(State state) { if (sessionTracker == null) { createSessionTracker(); } //用于管理每个链接的session startSessionTracker(); //以单链表的方式串起来processor setupRequestProcessors(); //节流器，所有的request都会先过一遍这个 startRequestThrottler(); } protected void startRequestThrottler() { requestThrottler = createRequestThrottler(); requestThrottler.start(); } 上面讲到所有的请求都执行了requestThrottler.submitRequest,这个操作实际是将请求放入了submittedRequests队列中，requestThrottler作为一个线程，循环取出队列中的请求并判断是否做限流。\n下面的代码主要有两个逻辑：\n一是当正在执行的请求数量达到上限时，要一直阻塞到数量小于maxRequests\n二是假如请求在队列里等待的时间大于throttled_op_wait_time，标记为已限流，后面的Processor处理时会抛异常。\npublic void run() { try { while (true) { if (killed) { break; } //从队列取出一个请求 Request request = submittedRequests.take(); if (Request.requestOfDeath == request) { break; } if (request.mustDrop()) { continue; } // Throttling is disabled when maxRequests = 0 if (maxRequests \u0026gt; 0) { while (!killed) { //一直都没有处理，导致连接都关闭了，或者session超时了，丢掉请求 if (dropStaleRequests \u0026amp;\u0026amp; request.isStale()) { // Note: this will close the connection dropRequest(request); ServerMetrics.getMetrics().STALE_REQUESTS_DROPPED.add(1); request = null; break; } //没达到上限时跳出循环 if (zks.getInProcess() \u0026lt; maxRequests) { break; } //达到上限了的话，等待stallTime这么在重新进循环，避免过多执行循环 throttleSleep(stallTime); } } if (killed) { break; } // A dropped stale request will be null if (request != null) { if (request.isStale()) { ServerMetrics.getMetrics().STALE_REQUESTS.add(1); } final long elapsedTime = Time.currentElapsedTime() - request.requestThrottleQueueTime; ServerMetrics.getMetrics().REQUEST_THROTTLE_QUEUE_TIME.add(elapsedTime); //当在队列等待时间过长，大于限流等待时间时，会将请求标志位已限流；已限流的请求在finalRequestProcessor中会抛异常Code.THROTTLEDOP if (shouldThrottleOp(request, elapsedTime)) { request.setIsThrottled(true); ServerMetrics.getMetrics().THROTTLED_OPS.add(1); } //交由Processor去处理 zks.submitRequestNow(request); } } } 假如没有被限流的话，执行到zks.submitRequestNow(request);后就将request交给processor处理了\nRequestProcessor zookeeper中将Processor分为了三个Processor，其启动是在setupRequestProcessors方法中，以链表的形式串起了三个processor，以PrepRequestProcessor为head，FinalRequestProcessor为tail。\nprotected void setupRequestProcessors() { RequestProcessor finalProcessor = new FinalRequestProcessor(this); RequestProcessor syncProcessor = new SyncRequestProcessor(this, finalProcessor); ((SyncRequestProcessor) syncProcessor).start(); firstProcessor = new PrepRequestProcessor(this, syncProcessor); ((PrepRequestProcessor) firstProcessor).start(); } public PrepRequestProcessor(ZooKeeperServer zks, RequestProcessor nextProcessor) { this.nextProcessor = nextProcessor; public SyncRequestProcessor(ZooKeeperServer zks, RequestProcessor nextProcessor) { this.zks = zks; this.nextProcessor = nextProcessor; PrepRequestProcessor PrepRequestProcessor的主要工作就是校验和创建事务。\n当调用processRequest时，也是通过队列解耦了一下，通过线程去异步执行，核心方法就是pRequestHelper\npublic void processRequest(Request request) { request.prepQueueStartTime = Time.currentElapsedTime(); submittedRequests.add(request); ServerMetrics.getMetrics().PREP_PROCESSOR_QUEUED.add(1); } public void run() { LOG.info(String.format(\u0026#34;PrepRequestProcessor (sid:%d) started, reconfigEnabled=%s\u0026#34;, zks.getServerId(), zks.reconfigEnabled)); try { while (true) { Request request = submittedRequests.take(); ...不重要的逻辑 pRequest(request); } } protected void pRequest(Request request) throws RequestProcessorException { request.setHdr(null); request.setTxn(null); //正常情况下request的isThrottled应该是false，所以会执行pRequestHelper if (!request.isThrottled()) { //一些前置的校验，事务的创建等 pRequestHelper(request); } //获取事务ID， request.zxid = zks.getZxid(); long timeFinishedPrepare = Time.currentElapsedTime(); ServerMetrics.getMetrics().PREP_PROCESS_TIME.add(timeFinishedPrepare - request.prepStartTime); //由syncRequestProcessor执行 nextProcessor.processRequest(request); ServerMetrics.getMetrics().PROPOSAL_PROCESS_TIME.add(Time.currentElapsedTime() - timeFinishedPrepare); } pRequestHelper方法里根据不同的OpCode有各自的处理方法，但是总共依旧可以区分为两大类：需要创建事务和不需要创建事务\n不需要创建事务的如下，就只执行checkSession方法，就是校验一下session是否正常\n而需要创建事务的逻辑则也差不多，大多数都是封装为一个Request对象，然后执行pRequest2Txn方法\npRequest2Txn方法的主要逻辑则是校验request、校验Acl权限、校验路径、校验[quota](Zookeeper笔记之quota - CC11001100 - 博客园)、创建事务和创建事务摘要\n//校验request validateCreateRequest(path, createMode, request, ttl); //acl权限校验 zks.checkACL(request.cnxn, parentRecord.acl, ZooDefs.Perms.CREATE, request.authInfo, path, listACL); //校验路径名称合规 validatePath(path, request.sessionId); //校验节点数和字节数 zks.checkQuota(path, null, data, OpCode.create); //创建事务 request.setTxn(new CreateTxn(path, data, listACL, createMode.isEphemeral(), newCversion)); //事务摘要 setTxnDigest(request, nodeRecord.precalculatedDigest); SyncRequestProcessor SyncRequestProcessor主要有两个操作，一个是写事务，一个是生成快照。\n对于非事务操作，这个processor是没有意义的；只有事务操作，才会进行日志的持久化。\npublic void run() { try { // we do this in an attempt to ensure that not all of the servers // in the ensemble take a snapshot at the same time resetSnapshotStats(); lastFlushTime = Time.currentElapsedTime(); while (true) { ServerMetrics.getMetrics().SYNC_PROCESSOR_QUEUE_SIZE.add(queuedRequests.size()); long pollTime = Math.min(zks.getMaxWriteQueuePollTime(), getRemainingDelay()); //之所有先poll一次是为了当queuedRequests队列为null的时候，期望可以触发一下flush Request si = queuedRequests.poll(pollTime, TimeUnit.MILLISECONDS); if (si == null) { /* We timed out looking for more writes to batch, go ahead and flush immediately */ flush(); si = queuedRequests.take(); } if (si == REQUEST_OF_DEATH) { break; } long startProcessTime = Time.currentElapsedTime(); ServerMetrics.getMetrics().SYNC_PROCESSOR_QUEUE_TIME.add(startProcessTime - si.syncQueueStartTime); // 普通的查询都没有事务，所以都会返回false；append这里只是写到了流里，还需要在commit方法中调用flush才会落盘 if (!si.isThrottled() \u0026amp;\u0026amp; zks.getZKDatabase().append(si)) { if (shouldSnapshot()) { resetSnapshotStats(); // roll the log zks.getZKDatabase().rollLog(); // take a snapshot if (!snapThreadMutex.tryAcquire()) { LOG.warn(\u0026#34;Too busy to snap, skipping\u0026#34;); } else { new ZooKeeperThread(\u0026#34;Snapshot Thread\u0026#34;) { public void run() { try { zks.takeSnapshot(); } catch (Exception e) { LOG.warn(\u0026#34;Unexpected exception\u0026#34;, e); } finally { snapThreadMutex.release(); } } }.start(); } } } else if (toFlush.isEmpty()) { // optimization for read heavy workloads // iff this is a read or a throttled request(which doesn\u0026#39;t need to be written to the disk), // and there are no pending flushes (writes), then just pass this to the next processor //当没有需要flush的内容，直接调用下一个processor处理；但假如toFlush队列有内容，就只能排队处理了 if (nextProcessor != null) { nextProcessor.processRequest(si); if (nextProcessor instanceof Flushable) { ((Flushable) nextProcessor).flush(); } } continue; } //排队处理 toFlush.add(si); if (shouldFlush()) { flush(); } ServerMetrics.getMetrics().SYNC_PROCESS_TIME.add(Time.currentElapsedTime() - startProcessTime); } } catch (Throwable t) { handleException(this.getName(), t); } LOG.info(\u0026#34;SyncRequestProcessor exited!\u0026#34;); } 关于写事务的方法是append和flush\npublic synchronized boolean append(Request request) throws IOException { TxnHeader hdr = request.getHdr(); //普通的查询都没有事务，所以都会返回false if (hdr == null) { return false; } ... //当logStream == null时会新创建文件，首次创建或者文件达到上限新创建 if (logStream == null) { LOG.info(\u0026#34;Creating new log file: {}\u0026#34;, Util.makeLogName(hdr.getZxid())); logFileWrite = new File(logDir, Util.makeLogName(hdr.getZxid())); fos = new FileOutputStream(logFileWrite); logStream = new BufferedOutputStream(fos); oa = BinaryOutputArchive.getArchive(logStream); FileHeader fhdr = new FileHeader(TXNLOG_MAGIC, VERSION, dbId); long dataSize = oa.getDataSize(); fhdr.serialize(oa, \u0026#34;fileheader\u0026#34;); // Make sure that the magic number is written before padding. //新建文件的文件头要立刻flush logStream.flush(); filePosition += oa.getDataSize() - dataSize; filePadding.setCurrentSize(filePosition); //在commit的时候进行flush streamsToFlush.add(fos); } fileSize = filePadding.padFile(fos.getChannel(), filePosition); //request序列化 byte[] buf = request.getSerializeData(); if (buf == null || buf.length == 0) { throw new IOException(\u0026#34;Faulty serialization for header \u0026#34; + \u0026#34;and txn\u0026#34;); } long dataSize = oa.getDataSize(); Checksum crc = makeChecksumAlgorithm(); crc.update(buf, 0, buf.length); oa.writeLong(crc.getValue(), \u0026#34;txnEntryCRC\u0026#34;); //将request写到流里 Util.writeTxnBytes(oa, buf); unFlushedSize += oa.getDataSize() - dataSize; return true; } private void flush() throws IOException, RequestProcessorException { if (this.toFlush.isEmpty()) { return; } ServerMetrics.getMetrics().BATCH_SIZE.add(toFlush.size()); long flushStartTime = Time.currentElapsedTime(); //将事务日志从流里刷到盘里 zks.getZKDatabase().commit(); ServerMetrics.getMetrics().SYNC_PROCESSOR_FLUSH_TIME.add(Time.currentElapsedTime() - flushStartTime); if (this.nextProcessor == null) { this.toFlush.clear(); } else { while (!this.toFlush.isEmpty()) { final Request i = this.toFlush.remove(); long latency = Time.currentElapsedTime() - i.syncQueueStartTime; ServerMetrics.getMetrics().SYNC_PROCESSOR_QUEUE_AND_FLUSH_TIME.add(latency); //到finalRequestProcessor this.nextProcessor.processRequest(i); } if (this.nextProcessor instanceof Flushable) { ((Flushable) this.nextProcessor).flush(); } } lastFlushTime = Time.currentElapsedTime(); } public synchronized void commit() throws IOException { if (logStream != null) { logStream.flush(); filePosition += unFlushedSize; // If we have written more than we have previously preallocated, // we should override the fileSize by filePosition. if (filePosition \u0026gt; fileSize) { fileSize = filePosition; } unFlushedSize = 0; } for (FileOutputStream log : streamsToFlush) { //刷盘 log.flush(); ... } while (streamsToFlush.size() \u0026gt; 1) { streamsToFlush.poll().close(); } // 达到上限了创建新事务文件 if (txnLogSizeLimit \u0026gt; 0) { long logSize = getCurrentLogSize(); if (logSize \u0026gt; txnLogSizeLimit) { LOG.debug(\u0026#34;Log size limit reached: {}\u0026#34;, logSize); //创建新文件 rollLog(); } } } FinalRequestProcessor 到目前为止，如果是查询请求，那还没有进行查询操作；如果是事务请求，只是将事务落盘了，内存中还没有进行修改。加上返回对象的组装，这些都是在这个Processor进行处理的。下面分别以创建节点和查询数据两个为例\n创建节点（create）\n创建节点属于事务操作，所以在返回结果之间要同步修改内存中的值，核心方法是applyRequest，一直会执行到DataTree的processTxn\npublic void processRequest(Request request) { LOG.debug(\u0026#34;Processing request:: {}\u0026#34;, request); ProcessTxnResult rc = null; if (!request.isThrottled()) { //处理事务或session rc = applyRequest(request); } 将其执行结果封装为response，并发送出去\n查询数据（getData）\n由于查询数据不是事务，所以在applyRequest中并没有啥操作，直接走到下面的switch，封装request，然后从zkDataBase获取节点，再获取数据封装为response并返回\nSessionTracker session是逻辑上客户端和服务端的一次长连接的通话，依托于物理的长连接connection。当第一次建立连接之后，zookeeper会为这个链接创建一个session并设置一个过期时间，只要没到过期时间，期间哪怕连接断开，只要可以重新连接，那依然算作一个session内。\nzookeeper利用session实现了如临时节点，即当session过期，当前session所建立的临时节点都会被删除。\nsessionTrack的创建也是在zookeeperServer.start的时候\n而session的过期处理和connect的过期处理逻辑基本一样，在这里以session讲解一下逻辑，上面的connect过期部分也就看的懂了。\npublic void run() { try { while (running) { long waitTime = sessionExpiryQueue.getWaitTime(); if (waitTime \u0026gt; 0) { Thread.sleep(waitTime); continue; } //看似是poll，其实是取出expiryMap中已经过期的队列 for (SessionImpl s : sessionExpiryQueue.poll()) { ServerMetrics.getMetrics().STALE_SESSIONS_EXPIRED.add(1); setSessionClosing(s.sessionId); expirer.expire(s);//其实就是close操作 } } } } 过期逻辑核心是一个队列ExpiryQueue，核心方法是update和poll方法。\nExpiryQueue持有两个集合对象elemMap和expiryMap，\nelemMap的key为连接对象，在这里就是指session，在connect逻辑中就是指connect，value是其过期时间。\nexpiryMap的key是过期时间，value是当前过期时间下对应的连接的集合。结构大概如下图。\n此外，ExpiryQueue还记录了下一个要过期的时间nextExpirationTime，因此，对于poll方法，就是遍历expiryMap，找到nextExpirationTime\u0026lt;now\u0026lt;key的values，并关闭即可\npublic Set\u0026lt;E\u0026gt; poll() { long now = Time.currentElapsedTime(); //当前最后一个要过期的时间 long expirationTime = nextExpirationTime.get(); //时间还没到，所以都不过期 if (now \u0026lt; expirationTime) { return Collections.emptySet(); } Set\u0026lt;E\u0026gt; set = null; //计算下一个周期并赋值 long newExpirationTime = expirationTime + expirationInterval; if (nextExpirationTime.compareAndSet(expirationTime, newExpirationTime)) { //取到上一个过期的周期的集合 set = expiryMap.remove(expirationTime); } if (set == null) { return Collections.emptySet(); } return set; } 而update方法也好理解，其实就是给session续期，假如续期之后其落到下个周期了，则要从上个周期对应的集合移除，添加到下个周期的集合\npublic Long update(E elem, int timeout) { //取到session的之前过期时间 Long prevExpiryTime = elemMap.get(elem); long now = Time.currentElapsedTime(); //续期 Long newExpiryTime = roundToNextInterval(now + timeout); //续期之后依然属于上个周期，则不需要改变expiryMap if (newExpiryTime.equals(prevExpiryTime)) { // No change, so nothing to update return null; } //续期之后不属于上个周期了，则要将当前sessoin加到下一个周期的集合，并从上一个集合删除 // First add the elem to the new expiry time bucket in expiryMap. Set\u0026lt;E\u0026gt; set = expiryMap.get(newExpiryTime); if (set == null) { // Construct a ConcurrentHashSet using a ConcurrentHashMap set = Collections.newSetFromMap(new ConcurrentHashMap\u0026lt;\u0026gt;()); // Put the new set in the map, but only if another thread // hasn\u0026#39;t beaten us to it Set\u0026lt;E\u0026gt; existingSet = expiryMap.putIfAbsent(newExpiryTime, set); if (existingSet != null) { set = existingSet; } } set.add(elem); // Map the elem to the new expiry time. If a different previous // mapping was present, clean up the previous expiry bucket. prevExpiryTime = elemMap.put(elem, newExpiryTime); if (prevExpiryTime != null \u0026amp;\u0026amp; !newExpiryTime.equals(prevExpiryTime)) { Set\u0026lt;E\u0026gt; prevSet = expiryMap.get(prevExpiryTime); if (prevSet != null) { prevSet.remove(elem); } } return newExpiryTime; } 而update方法的调用上层是touchSession，在Processor处理前会调用。\n参考文档： 【图解源码】Zookeeper3.7源码分析，包含服务启动流程源码、网络通信源码、RequestProcessor处理请求源码 - 掘金\n【图解源码】Zookeeper3.7源码剖析，Session的管理机制，Leader选举投票规则，集群数据同步流程 - 掘金\nZookeeper源码分析 | Coding Tree\nZookeeper笔记之quota - CC11001100 - 博客园\n","date":"2024-08-05T12:59:08+08:00","permalink":"https://qisiii.github.io/post/tech/distributed/zookeeper/zookeeperservermain/","title":"Zookeeper源码学习-单机部分通信组件"},{"content":"部署 参考Redis 集群教程使用单云服务器启动多个节点来当做redis集群，这里使用7000-7005这6个节点，三主三从\n#准备好文件夹 mkdir redis-cluster cd redis-cluster mkdir 7000 7001 7002 7003 7004 7005 #下载redis wget https://download.redis.io/redis-stable.tar.gz tar -zxvf redis-stable.tar.gz cd redis-stable make #回到redis-cluster \u0026amp;\u0026amp;新建公共配置文件 cd redis-cluster touch redis.conf ##redis.conf 模板内容 port 7000 #单节点的端口号 cluster-enabled yes #开启集群模式 cluster-config-file \u0026#34;nodes.conf\u0026#34; #集群配置文件，启动后节点后会自动新建 cluster-node-timeout 5000 #节点能够失联的最大时间 appendonly yes #aof持久化 protected-mode no #方便其他机器访问云服务器 cluster-announce-ip 服务器公网IP #这是在通过spring连接集群时需要配置的，不配置的话会连接局域网ip #复制模板redis.conf到6个端口号文件夹 echo 7000 7001 7002 7003 7004 7005 | xargs -n 1 cp -v redis.conf 修改每个文件夹下的redis.conf的port，和文件夹名保持一致 #启动6个redis实例 cd 7000 nohup ../redis-stable/src/redis-server ./redis.conf \u0026amp; cd 7001 nohup ../redis-stable/src/redis-server ./redis.conf \u0026amp; ... 或者在redis-cluster目录直接启动所有 nohup ./redis-stable/src/redis-server 7000/redis.conf \u0026gt;\u0026gt; ./7000/nohup.out \u0026amp;;nohup ./redis-stable/src/redis-server 7001/redis.conf \u0026gt;\u0026gt; ./7001/nohup.out \u0026amp;;nohup ./redis-stable/src/redis-server 7002/redis.conf \u0026gt;\u0026gt; ./7002/nohup.out \u0026amp;;nohup ./redis-stable/src/redis-server 7003/redis.conf \u0026gt;\u0026gt; ./7003/nohup.out \u0026amp;;nohup ./redis-stable/src/redis-server 7004/redis.conf \u0026gt;\u0026gt; ./7004/nohup.out \u0026amp;;nohup ./redis-stable/src/redis-server 7005/redis.conf \u0026gt;\u0026gt; ./7005/nohup.out \u0026amp; 全部启动完之后，可以通过ps -ef | grep redis来确认正常启动，且是cluster模式\n使用以下命令新建集群\nredis-stable/src/redis-cli --cluster create 公网ip:7000 公网ip:7001 公网ip:7002 公网ip:7003 公网ip:7004 公网ip:7005 --cluster-公网ip --cluster-replicas 1\n当看到 [OK] All 16384 slots covered表明启动成功\n设置密码 依次访问每个节点，并进行设置 redis-cli -c -p 端口 config set requirepass 密码 config set masterauth 密码 config rewrite 设置完之后去看conf文件会发现改变了以下三行\nuser default on sanitize-payload #94eef65a0de53368e43fe0f363193bebcc0fb13784a3b23defa1e8616f0af ~* \u0026amp;* +@all requirepass \u0026#34;密码\u0026#34; masterauth \u0026#34;密码\u0026#34; 关闭\u0026amp;重启\u0026amp;删除 关闭集群 依次连接每个节点redis-cli -c -p [端口]并输入shutdown命令或者直接用kill -15 掉对应的pid\n鉴于我们启动的节点较多，可以通过ps -ef | grep redis | cut -c 9-15 | xargs kill -15 批量删除\n重启集群 重新启动节点，会自动加入到集群里\n#启动6个redis实例 cd 7000 nohup ../redis-stable/src/redis-server ./redis.conf \u0026amp; cd 7001 nohup ../redis-stable/src/redis-server ./redis.conf \u0026amp; 删除集群 删除集群需要先关闭集群的所有节点，然后删除每个节点的集群自动生成的文件，可以通过命令批量删除rm -rf 700*/nodes.conf 700*/dump.rdb 700*/appendonlydir\n使用 redis-cli 通过redis-cli 连接任一节点，添加或者获取缓存时会计算key落到哪个节点（crc16(key)%16384)，然后重定向到该节点再去获取或者赋值。\nredisinsight 创建新的db连接，Host中是公网ip，创建成功后会显示类别是OSS Cluster，普通的单机类型则是Standalone\n里面会显示所有的节点的key，刚才在redis-cli设置值的时候，key【hello】是7000节点，key【hello】是7002节点，这里都会显示出来\n同时，在Analysis Tool看板会显示集群的一些信息\nSpring连接 引入依赖，设置配置文件，成功启动后会打印出world；\n#pom.xml \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; #application.yml spring: redis: cluster: nodes: [公网ip]:7000,[公网ip]:7001,[公网ip]:7002,[公网ip]:7003,[公网ip]:7004,[公网ip]:7005 password: 密码 @SpringBootApplication public class RedisClusterApplication { public static void main(String[] args) { ConfigurableApplicationContext context = SpringApplication.run(RedisClusterApplication.class); StringRedisTemplate template = context.getBean(StringRedisTemplate.class); template.opsForValue().set(\u0026#34;hello\u0026#34;,\u0026#34;world\u0026#34;); String value=template.opsForValue().get(\u0026#34;hello\u0026#34;); System.out.println(value); } } 注意事项： redis-cli --cluster create命令里公网ip如果是127.0.0.1或者内网ip的话，可以正常启动集群，也可以通过redis-cli 命令连接。但是无法通过spring来启动，且无法通过redis的客户端redisinsight进行连接。\nspring会报错Unable to connect to [127.0.0.1:7001]: Connection refused: /127.0.0.1:7001这样的错误\nredisinsight会报Could not connect to [公网ip:端口号],please check the connection details\n安全组和防火墙都需要开启7000-7005和17000-17005端口号，其中端口号+10000是集群总线的端口，不然的话通过redis-cli --cluster create命令创建集群的时候，waiting for the cluster to join后一直等待\n配置文件中需要指定cluster-announce-ip 为公网ip，不然通过spring去连接的时候，哪怕你创建命令指定的是公网ip，但依然会报Unable to connect to [内网ip:7001]: Connection refused: /内网ip:7001\n配置protected-mode no其实是远程连通redis的一种方案，在不设置且没有密码的情况下会报下面这个错误，正如NOTE中所述，选择其中任一一种就可以了。\n-DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command \u0026#39;CONFIG SET protected-mode no\u0026#39; from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to \u0026#39;no\u0026#39;, and then restarting the server. 3) If you started the server manually just for testing, restart it with the \u0026#39;--protected-mode no\u0026#39; option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside. 参考文档: Redis 集群教程\nspringboot lettcue连接redis cluster定时刷新拓扑和遇到的问题解决-CSDN博客\n","date":"2024-07-30T23:27:58+08:00","permalink":"https://qisiii.github.io/post/tech/distributed/redis_cluster_deploy/","title":"单服务器Redis集群部署记录"},{"content":"Jstack应用 jstack是java提供的工具，一般用于分析栈-线程相关的问题，常见的比如死锁问题，cpu过高问题。\njstack 命令使用方式如下：\njstack [-F][-l][-m] pid 或者jstack [-F][-l][-m] [server_id@]\u0026lt;remote server IP or hostname\n可以通过-h或者-help来了解每个参数具体的作用，pid指的是java项目所属的进程Id，一般通过jps命令或者top、ps等命令获取。\nJstack文件分析 参数分析 大部分的信息都如上图所示：\n\u0026ldquo;pool-1-thread-2\u0026rdquo; 表示线程的名字\n#12 猜测是线程的nativeId，和arthas的线程id列很像，但是arthas官网文档又强调不是nativeId\nprio表示java内定义的线程的优先级\nos_prio操作系统级别的优先级\ntid 猜测是一个地址，但具体不清楚\nnid 操作系统级别线程的线程id,可通过top -pid [java应用进程id] 获取\n下面的红色部分则是状态、调用链路、一些锁的操作信息，具体下面分开讲\n状态 Java中线程的状态有六种：NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED\n其中，NEW和TERMINATED是创建和销毁时的状态，在stack中没有见到过，基本上都是其他四种状态在流转。) RUNNABLE:表示当前可以被cpu调度执行或者已经在执行。\n为了更好的解释BLOCKED，这里要结合synchronized的底层原理Monitor来进行讲解： Monitor是java对象规定的一个区域，可以视作一个房间。\n当持有synchronized锁的时候，表示当前线程持有Monitor，释放锁表示释放Monitor。因此，同一时刻只有一个线程可以持有，这个信息被记录在对象头的markword部分中。\n左边的entrySet用于记录等待获取锁的线程（即最开始抢锁失败的线程），此时这些线程的状态就为BLOCKED，抢到锁的线程状态为RUNNABLE。\n当拥有锁的线程释放锁的时候，存在两种可能：\n一种是释放了并且再也不使用了，即线程工作完成了，此时线程就结束掉，状态变为TERMINATED。\n一种是释放了但是线程是核心线程，可能还会继续调用，此时线程状态会为WAITING或者TIMED_WAITING，此时这个线程就会被放入到右边的waitSet。当调用notify或者到指定时间之后，就会将线程重新添加到左边的entrySet中再次尝试获取锁。\n线程的操作 线程的操作是指在stack文件堆栈信息中，用于描述线程对锁、对象的一些操作，堆栈信息一般如下面这般，-locked就是线程的操作，分为几类：\njava.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at com.qisi.simple.Jvisualvm.JStackExample.test1(JStackExample.java:18) - locked \u0026lt;0x000000076adddbb8\u0026gt; (a com.qisi.simple.Jvisualvm.JStackExample) at com.qisi.simple.Jvisualvm.JStackExample$$Lambda$1/777874839.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:750) java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for \u0026lt;0x000000076adddb80\u0026gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2044) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:750) locked [地址]：当前线程持有锁，即持有monitor\nwaiting on [地址] ：线程释放锁，等待通知，即在waitSet中\nwaiting to lock [地址]：线程获取锁失败，正在等待获取锁，即在entrySet中\nparking to wait for [地址]：这种的是属于非synchronized锁的信息，多用于Lock锁，对应park方法，具体参考multithreading - Java thread dump: Difference between \u0026quot;waiting to lock\u0026quot; and \u0026quot;parking to wait for\u0026quot;? - Stack Overflow\n例子： static Boolean flag = true; synchronized void producer(){ System.out.println(Thread.currentThread().getName()+\u0026#34;抢到了锁\u0026#34;); while (flag) { try { flag = false; Thread.sleep(5000); this.wait(); System.out.println(Thread.currentThread().getName()+\u0026#34;执行了test1\u0026#34;); } catch (InterruptedException e) { throw new RuntimeException(e); } } } synchronized void consumer(){ System.out.println(Thread.currentThread().getName()+\u0026#34;抢到了锁\u0026#34;); while (!flag) { flag = true; this.notify(); } try { Thread.sleep(5000); } catch (InterruptedException e) { throw new RuntimeException(e); } System.out.println(Thread.currentThread().getName()+\u0026#34;执行了test2\u0026#34;); } ExecutorService executorService = Executors.newFixedThreadPool(2); JStackExample example = new JStackExample(); for (int i = 0; i \u0026lt; 10; i++) { executorService.execute(example::producer); executorService.execute(example::consumer); }; 一个简单的生产者-消费者例子，生成两次堆栈，分别在producer sleep时和\n2024-07-28 21:52:21 Full thread dump OpenJDK 64-Bit Server VM (25.392-b08 mixed mode): \u0026#34;Attach Listener\u0026#34; #14 daemon prio=9 os_prio=31 tid=0x0000000128811800 nid=0x5b03 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE \u0026#34;DestroyJavaVM\u0026#34; #13 prio=5 os_prio=31 tid=0x0000000159922000 nid=0x1503 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE \u0026#34;pool-1-thread-2\u0026#34; #12 prio=5 os_prio=31 tid=0x0000000159921000 nid=0x5a03 waiting for monitor entry [0x0000000172c56000] java.lang.Thread.State: BLOCKED (on object monitor) at com.qisi.simple.Jvisualvm.JStackExample.test2(JStackExample.java:27) - waiting to lock \u0026lt;0x000000076adddbb8\u0026gt; (a com.qisi.simple.Jvisualvm.JStackExample) at com.qisi.simple.Jvisualvm.JStackExample$$Lambda$2/930990596.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:750) \u0026#34;pool-1-thread-1\u0026#34; #11 prio=5 os_prio=31 tid=0x00000001598dc800 nid=0x5903 waiting on condition [0x0000000172a4a000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at com.qisi.simple.Jvisualvm.JStackExample.test1(JStackExample.java:18) - locked \u0026lt;0x000000076adddbb8\u0026gt; (a com.qisi.simple.Jvisualvm.JStackExample) at com.qisi.simple.Jvisualvm.JStackExample$$Lambda$1/777874839.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:750) 2024-07-28 21:52:26 Full thread dump OpenJDK 64-Bit Server VM (25.392-b08 mixed mode): \u0026#34;pool-1-thread-2\u0026#34; #12 prio=5 os_prio=31 tid=0x0000000159921000 nid=0x5a03 waiting on condition [0x0000000172c56000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at com.qisi.simple.Jvisualvm.JStackExample.test2(JStackExample.java:33) - locked \u0026lt;0x000000076adddbb8\u0026gt; (a com.qisi.simple.Jvisualvm.JStackExample) at com.qisi.simple.Jvisualvm.JStackExample$$Lambda$2/930990596.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:750) \u0026#34;pool-1-thread-1\u0026#34; #11 prio=5 os_prio=31 tid=0x00000001598dc800 nid=0x5903 in Object.wait() [0x0000000172a4a000] java.lang.Thread.State: BLOCKED (on object monitor) at java.lang.Object.wait(Native Method) - waiting on \u0026lt;0x000000076adddbb8\u0026gt; (a com.qisi.simple.Jvisualvm.JStackExample) at java.lang.Object.wait(Object.java:502) at com.qisi.simple.Jvisualvm.JStackExample.test1(JStackExample.java:19) - locked \u0026lt;0x000000076adddbb8\u0026gt; (a com.qisi.simple.Jvisualvm.JStackExample) at com.qisi.simple.Jvisualvm.JStackExample$$Lambda$1/777874839.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:750) 先看21:52:21时的信息，\n由于是thread1先执行producer，获取到锁，表现为-locked \u0026lt;0x000000076adddbb8\u0026gt;，当执行到sleep时，状态变为TIMED_WAITING\n当执行到wait时，thread1会释放锁，所以在2024-07-28 21:52:26，新增了一条- waiting on \u0026lt;0x000000076adddbb8\u0026gt;，同时状态变为了BLOCKED，表示在等待锁。此时thread2获取到锁,thread2新增- locked \u0026lt;0x000000076adddbb8\u0026gt;，状态为TIMED_WAITING\n当thread的sleep醒来执行了notify时，后面的堆栈信息虽然没有抓取到，但可以推测出来，thread1被唤醒，因此，thread1会再次获取到锁，从堆栈信息来看则是waiting on会变为lock，因为此时只有thread1需要锁，如果有多个线程都需要锁，有可能会变成waiting to lock\n死循环cpu打满问题 测试代码： /** * @author : qisi * @date: 2024/7/28 * @description: cpu打满测试用例 */ public class CpuFullExample { public static void main(String[] args) { Runnable empty = new Runnable() { @Override public void run() { int count=0; while (count\u0026lt;1000){ count++; } System.out.println(count); } }; Runnable full = new Runnable() { @Override public void run() { int count=0; while(true){ count++; } } }; new Thread(empty).start(); new Thread(full).start(); } } 根据top -pid [应用Id]找到cpu最高的tid，将10进制tid转换为16进制\n根据jstack pid 生成tdump文件，根据转换出来的16进制，搜索对应的nid，此时的线程大概率是runnbale，不然怎么可能死循环，然后根据调用链路去找项目中对应的位置。\n死锁问题 测试代码\npublic class DeadLockExample { public Object resourceA = new Object(); public Object resourceB = new Object(); public static void main(String[] args) { DeadLockExample deadLockExample = new DeadLockExample(); Runnable runnableA = new Runnable() { @Override public void run() { synchronized(deadLockExample.resourceA) { System.out.printf( \u0026#34;[INFO]: %s get resourceA\u0026#34; + System.lineSeparator(), Thread.currentThread().getName() ); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.printf( \u0026#34;[INFO]: %s trying to get resourceB\u0026#34; + System.lineSeparator(), Thread.currentThread().getName() ); synchronized(deadLockExample.resourceB) { System.out.printf( \u0026#34;[INFO]: %s get resourceB\u0026#34; + System.lineSeparator(), Thread.currentThread().getName() ); } System.out.printf( \u0026#34;[INFO]: %s has done\u0026#34; + System.lineSeparator(), Thread.currentThread().getName() ); } } }; Runnable runnableB = new Runnable() { @Override public void run() { synchronized(deadLockExample.resourceB) { System.out.printf( \u0026#34;[INFO]: %s get resourceB\u0026#34; + System.lineSeparator(), Thread.currentThread().getName() ); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.printf( \u0026#34;[INFO]: %s trying to get resourceA\u0026#34; + System.lineSeparator(), Thread.currentThread().getName() ); synchronized(deadLockExample.resourceA) { System.out.printf( \u0026#34;[INFO]: %s get resourceA\u0026#34; + System.lineSeparator(), Thread.currentThread().getName() ); } System.out.printf( \u0026#34;[INFO]: %s has done\u0026#34; + System.lineSeparator(), Thread.currentThread().getName() ); } } }; new Thread(runnableA).start(); new Thread(runnableB).start(); } } 这段程序执行后，runnableA在持有resourceA后会再尝试获取resourceB锁，但此时resourceB锁已经被runnableB获取，释放的条件则是runnableB执行完，但是runnableB执行过程又在等待resourceA锁，这样就陷入了死锁。\n使用jps获取pid，使用jstack pid生成文件。文件内容大致就是下面这样，其中大部分都是如同第一段一般，只有在出现死锁的时候，才会出现第二段（Found one Java-level deadlock），并清楚的告诉是哪些线程陷入死锁。\n\u0026#34;Thread-1\u0026#34; #14 prio=5 os_prio=31 tid=0x0000000125809000 nid=0x7a03 waiting for monitor entry [0x000000016efba000] java.lang.Thread.State: BLOCKED (on object monitor) at com.qisi.simple.Jvisualvm.DeadLockExample$2.run(DeadLockExample.java:59) - waiting to lock \u0026lt;0x000000076b5dee40\u0026gt; (a java.lang.Object) - locked \u0026lt;0x000000076b5dee50\u0026gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:750) ...... Found one Java-level deadlock: \u0026#34;Thread-1\u0026#34;: waiting to lock monitor 0x0000000124055770 (object 0x000000076b5dee40, a java.lang.Object), which is held by \u0026#34;Thread-0\u0026#34; \u0026#34;Thread-0\u0026#34;: waiting to lock monitor 0x0000000124058000 (object 0x000000076b5dee50, a java.lang.Object), which is held by \u0026#34;Thread-1\u0026#34; ...... Found 1 deadlock. 参考文档： https://zihengcat.github.io/2019/08/09/java-tutorial-for-language-adavanced-deadlock-example-and-solution/\n图解 Java 线程生命周期-腾讯云开发者社区-腾讯云\nJVM系列\u0026ndash;jstack工具详解 | 奚新灿的博客-Chronos\njstack 命令的使用和问题排查分析思路_jstack pid-CSDN博客\nMonitor对象全解析 - 张高峰的博客 | Peakiz Blog\n","date":"2024-07-28T17:14:47+08:00","permalink":"https://qisiii.github.io/post/tech/lang/jstack/","title":"Jstack使用"},{"content":"建站方式 选择建站方式，是使用动态建站（如WordPress、halo），还是使用静态建站（Jekyll、hexo、hugo）。\n前者更偏向于传统的CMS管理系统，有后台管理页面，可以在管理页面发布，修改文章。除了需要服务器之外，需要同时了解前端、后端、数据库相关的知识，当然现有的项目完全可以简单配置后就可以开箱使用。\n后者一般是使用各种开源项目，将文档转为静态资源（html），部署在服务器或者以GithubPages的方式供他人访问。而使用哪个开源项目进行建站，可以去Static Site Generators -Jamstack选择个人喜欢的项目，本文使用hugo项目进行搭建。\nhugo安装和使用 参考hugo中文官网，进行安装，我这里是mac os系统，所以直接使用 brew install hugo进行安装。\n使用命令hugo new site [路径]创建项目根目录，比如我这边路径是/Users/qisi/Research/hugo，则会在/Users/qisi/Research/hugo目录下创建以下文件夹\n其中，content文件夹用来存储你的文档，themes文件夹用来存储你想要的主题，hugo.toml是总的配置，其他的后面可以跟着官网慢慢熟悉。\n在主题网站安装想要的主题，我这里是使用的stack主题，可以通过两种方式安装\n通过git命令，在当前目录执行\ngit init git submodule add --depth=1 https://github.com/CaiJimmy/hugo-theme-stack.git themes/hugo-theme-stack 手动安装则是自己新建文件夹，然后clone\ncd themes mkdir hugo-theme-stack git clone https://github.com/CaiJimmy/hugo-theme-stack.git 安装完成之后，将stack主题的配置复制一份到hugo根目录，并删除hugo.toml文件\ncp themes/hugo-theme-stack/exampleSite/hugo.yaml ./\n执行以下命令来新建文件，会自动在content/post目录下新建test.md\nhugo new post/test.md\n文件内容是,draft表示是草稿\n+++ title = \u0026#39;Test\u0026#39; date = 2024-07-29T14:25:00+08:00 draft = true +++ ## 这里是我手动添加的内容 通过hugo server --buildDrafts 启动后台，\u0026ndash;buildDrafts 表示会编译draft=true的文档，通过在浏览器访问http://localhost:1313打开网站，页面如图\nGithub Page 通过hugo server已经可以在本地电脑进行访问了，但如果想要通过互联网访问，则需要进行额外的设置。\n如果拥有自己的服务器，可以在服务器上启动hugo，然后使用nginx监听并转发到public目录；但如果没有服务器，则可以通过Github Page功能来托管自己的项目。\n首先需要创建一个项目，项目名称以github.io结尾，前缀一般用自己的用户名或者有标识的单词\n将hugo项目的public文件夹作为一个git项目，推送到刚新建的这个Repository中\ncd public git init git add . git commit -am 首次commit git remote add origin git@github.com:qisiii/qisiii.github.io.git git push --set-upstream origin master 在setting-pages下进行一些设置，如下图所示，保存后就可以通过[关键词].github.io来访问了\n如果想要更个性化的域名，则需要购买一个域名，添加一个cname类型的解析，同时在上图Custom domain的文本框中填入对应的域名，这样子就可以以自己的域名访问了。\nMarkdown工具 市面上的markdown工具还是蛮多的，各种开发用的ide，或者专门用于markdown的编辑器。我使用的是MarkText(GitHub - marktext/marktext: 📝A simple and elegant markdown editor, available for Linux, macOS and Windows.)，建议直接安装中文版markText。\nMarkText的图床功能存在bug：\nuploader为github时上传失败 原因是GithubApi要求content是base64格式的，所以需要额外做一下处理，参考pr\n无法上传剪贴板的图片 其中，无法上传剪贴板图片的bug是由于项目中fileSystem.js中path.join方法参数类型错误导致的；参考Fix Failure when uploading clipboard images with PicGo （#3360） by Jakentop · Pull Request #3366 · marktext/marktext · GitHub\n无法检测到picgo存在 这个可能是由于env的路径并不包含picgo所在的路径，在env.js有一段逻辑是这样的\nconst patchEnvPath = () =\u0026gt; { if (process.platform === \u0026#39;darwin\u0026#39;) { process.env.PATH += (process.env.PATH.endsWith(path.delimiter) ? \u0026#39;\u0026#39; : path.delimiter) + \u0026#39;/Library/TeX/texbin:/opt/homebrew/bin:/usr/local/bin\u0026#39; } } 修改为下面这样，我是用yarn 安装的picgo，路径在/opt/homebrew/bin 下面，我为了省事，就将/opt/homebrew/bin和/usr/local/bin都追加在后面了\nconst patchEnvPath = () =\u0026gt; { if (process.platform === \u0026#39;darwin\u0026#39;) { process.env.PATH += (process.env.PATH.endsWith(path.delimiter) ? \u0026#39;\u0026#39; : path.delimiter) + \u0026#39;/Library/TeX/texbin:/opt/homebrew/bin:/usr/local/bin\u0026#39; } } 修改完之后打包会是下面这样，就能识别到picgo了\n但是可能依然会存在上传截图失败的情况，这种场景下是找不到node，可以自己给node建立一个软连接到/usr/local/bin下，比如我这边是nvm管理的node 18，通过ln -s /Users/hkc/.nvm/versions/node/v18.15.0/bin/node /usr/local/bin/node 建立软链接\n参考博客： 个人网站的建立过程（二）：使用Hugo框架搭建个人网站\n个人网站的建立过程（二）：使用Hugo框架搭建个人网站\n","date":"2024-07-23T00:00:00Z","permalink":"https://qisiii.github.io/post/site/personsite/","title":"搭建自己的博客"},{"content":"@Service public class Bean1 { @Autowired private Bean2 bean2; // @Async public void test(){ System.out.println(\u0026#34;Bean1\u0026#34;); } } @Service public class Bean2 { @Autowired private Bean1 bean1; // @Async public void test(){ System.out.println(\u0026#34;Bean2\u0026#34;); } } 在doGetBean的第一个节点上，会调用到getSingleon这个方法，正常来说，Bean1和Bean2首次获取都会是空，只有在实例化后\u0026amp;属性注入前，才会将当前状态的Bean暴露到singleton工厂来获取。\n分为三级缓存 protected Object getSingleton(String beanName, boolean allowEarlyReference) { // Quick check for existing instance without full singleton lock Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null \u0026amp;\u0026amp; isSingletonCurrentlyInCreation(beanName)) { singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null \u0026amp;\u0026amp; allowEarlyReference) { synchronized (this.singletonObjects) { // Consistent creation of early reference within full singleton lock singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) { singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null) { ObjectFactory\u0026lt;?\u0026gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) { singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); } } } } } } return singletonObject; } protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) { Object exposedObject = bean; if (!mbd.isSynthetic() \u0026amp;\u0026amp; hasInstantiationAwareBeanPostProcessors()) { for (SmartInstantiationAwareBeanPostProcessor bp : getBeanPostProcessorCache().smartInstantiationAware) { exposedObject = bp.getEarlyBeanReference(exposedObject, beanName); } } return exposedObject; } 所以是在Bean2注入属性Bean1的时候，可以获取到Bean1的暴露对象，同时放到了二级缓存中。\n为什么要有三级缓存，二级不够吗？\n三级缓存主要是为了解决aop的，分两点，一点是保证所有的aop只代理一次，之后的bean则从二级缓存获取。\n第二点这是，aop代理正常情况下是在bean初始化之后才进行的aop代理，只是在循环依赖的时候提前进行了代理。当一个bean本身不知道是否存在循环依赖的时候，不应该提前就进行代理，所以这里不管怎样都要放入二级缓存中去。\n有没有循环依赖没有解决的场景？\n有，对于都是构造器注入的bean，由于spring处理的循环依赖是在实例化后进行暴露的bean，而在构造器阶段，双方都需要对方的实力作为参数，就会报循环依赖。\n还有一种情况，则是在bean已经被循环依赖处理后，自己通过其他方式返回了一个不是原来bean的bean，比如@Async的代理对象，通过beanpostprocessor进行了增强，导致Bean2所持有的bean1不对了，这个时候也算错误。\n","date":"2024-06-20T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/spring/cycle_bean/","title":"SpringBean循环依赖处理流程"},{"content":"Spring中是存在多个Scope的，比如大部分的bean都是单例(Singleton)，还有一些不常用的比如原型(Prototype)、request、session、thread、servlet以及refresh。除了单例之外，其他的都是表示在某一个限定的范围内，是相同的bean，比如原型表示每次都是全新的bean，request表示每一次request是全新的bean。\nRefreshScope，则表示每次Refresh的时候，都会获取全新的bean。这个注解的核心在于Scope注解，且value是refresh。\n@Target({ ElementType.TYPE, ElementType.METHOD }) @Retention(RetentionPolicy.RUNTIME) @Scope(\u0026#34;refresh\u0026#34;) @Documented public @interface RefreshScope { /** * @see Scope#proxyMode() * @return proxy mode */ //默认是cglib代理 ScopedProxyMode proxyMode() default ScopedProxyMode.TARGET_CLASS; } 注册代理bean 标有Scope的类，无论是那种加载beanDefinition的情况，在注册beanDefinition的时候会注册成代理bean并持有scope范围的bean。例如，bean名字是simpleBean,那么在spring容器中会注册两个bean，scopedTarget.simpleBean(非单例）和simpleBean（单例）。所有的依赖，如@Autowired和@Value类的属性，都只会注入到simpleBean中\n这里以ClassPathBeanDefinitionScanner.doScan为例。\nprotected Set\u0026lt;BeanDefinitionHolder\u0026gt; doScan(String... basePackages) { Assert.notEmpty(basePackages, \u0026#34;At least one base package must be specified\u0026#34;); Set\u0026lt;BeanDefinitionHolder\u0026gt; beanDefinitions = new LinkedHashSet\u0026lt;\u0026gt;(); for (String basePackage : basePackages) { Set\u0026lt;BeanDefinition\u0026gt; candidates = findCandidateComponents(basePackage); for (BeanDefinition candidate : candidates) { //解析Scope注解的元数据信息 ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(candidate); candidate.setScope(scopeMetadata.getScopeName()); String beanName = this.beanNameGenerator.generateBeanName(candidate, this.registry); if (candidate instanceof AbstractBeanDefinition) { postProcessBeanDefinition((AbstractBeanDefinition) candidate, beanName); } if (candidate instanceof AnnotatedBeanDefinition) { AnnotationConfigUtils.processCommonDefinitionAnnotations((AnnotatedBeanDefinition) candidate); } if (checkCandidate(beanName, candidate)) { BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(candidate, beanName); //额外处理 definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); beanDefinitions.add(definitionHolder); registerBeanDefinition(definitionHolder, this.registry); } } } return beanDefinitions; } 需要关注的就两个方法resolveScopeMetadata和AnnotationConfigUtils.applyScopedProxyMode\n//就是组装注解元数据信息 public ScopeMetadata resolveScopeMetadata(BeanDefinition definition) { ScopeMetadata metadata = new ScopeMetadata(); if (definition instanceof AnnotatedBeanDefinition) { AnnotatedBeanDefinition annDef = (AnnotatedBeanDefinition) definition; AnnotationAttributes attributes = AnnotationConfigUtils.attributesFor( annDef.getMetadata(), this.scopeAnnotationType); if (attributes != null) { metadata.setScopeName(attributes.getString(\u0026#34;value\u0026#34;)); ScopedProxyMode proxyMode = attributes.getEnum(\u0026#34;proxyMode\u0026#34;); if (proxyMode == ScopedProxyMode.DEFAULT) { proxyMode = this.defaultProxyMode; } metadata.setScopedProxyMode(proxyMode); } } return metadata; } static BeanDefinitionHolder applyScopedProxyMode( ScopeMetadata metadata, BeanDefinitionHolder definition, BeanDefinitionRegistry registry) { ScopedProxyMode scopedProxyMode = metadata.getScopedProxyMode(); //为no表示不代理 if (scopedProxyMode.equals(ScopedProxyMode.NO)) { return definition; } //是否是cglib代理 boolean proxyTargetClass = scopedProxyMode.equals(ScopedProxyMode.TARGET_CLASS); return ScopedProxyCreator.createScopedProxy(definition, registry, proxyTargetClass); } //这段代码的主要作用就是将bean本身注册为了一个代理bean，且这个代理bean持有一个名字为scopedTarget.+原名字的内部bean public static BeanDefinitionHolder createScopedProxy(BeanDefinitionHolder definition, BeanDefinitionRegistry registry, boolean proxyTargetClass) { String originalBeanName = definition.getBeanName(); BeanDefinition targetDefinition = definition.getBeanDefinition(); //代理bean的名字是scopedTarget.+原名字 String targetBeanName = getTargetBeanName(originalBeanName); // Create a scoped proxy definition for the original bean name, // \u0026#34;hiding\u0026#34; the target bean in an internal target definition. RootBeanDefinition proxyDefinition = new RootBeanDefinition(ScopedProxyFactoryBean.class); proxyDefinition.setDecoratedDefinition(new BeanDefinitionHolder(targetDefinition, targetBeanName)); //持有targetBean proxyDefinition.setOriginatingBeanDefinition(targetDefinition); proxyDefinition.setSource(definition.getSource()); proxyDefinition.setRole(targetDefinition.getRole()); proxyDefinition.getPropertyValues().add(\u0026#34;targetBeanName\u0026#34;, targetBeanName); if (proxyTargetClass) { targetDefinition.setAttribute(AutoProxyUtils.PRESERVE_TARGET_CLASS_ATTRIBUTE, Boolean.TRUE); // ScopedProxyFactoryBean\u0026#39;s \u0026#34;proxyTargetClass\u0026#34; default is TRUE, so we don\u0026#39;t need to set it explicitly here. } else { proxyDefinition.getPropertyValues().add(\u0026#34;proxyTargetClass\u0026#34;, Boolean.FALSE); } // Copy autowire settings from original bean definition. proxyDefinition.setAutowireCandidate(targetDefinition.isAutowireCandidate()); proxyDefinition.setPrimary(targetDefinition.isPrimary()); if (targetDefinition instanceof AbstractBeanDefinition) { proxyDefinition.copyQualifiersFrom((AbstractBeanDefinition) targetDefinition); } // The target bean should be ignored in favor of the scoped proxy. targetDefinition.setAutowireCandidate(false); targetDefinition.setPrimary(false); // Register the target bean as separate bean in the factory. //这里注册了targetBean，bean名字是scopedTarget.+原名字 registry.registerBeanDefinition(targetBeanName, targetDefinition); // Return the scoped proxy definition as primary bean definition // (potentially an inner bean). //这里返回代理bean的信息，但是bean名字还是原来的bean return new BeanDefinitionHolder(proxyDefinition, originalBeanName, definition.getAliases()); } 实例化scopeBean 由于scopeBean都不是单例，所以不是在熟知的refresh遍历beanNames进行实例化的。\n而是在finishRefresh方法中，对于ContextRefreshedEvent事件进行处理时，在RefresScope中进行的getBean\n@Override public void onApplicationEvent(ContextRefreshedEvent event) { start(event); } public void start(ContextRefreshedEvent event) { if (event.getApplicationContext() == this.context \u0026amp;\u0026amp; this.eager \u0026amp;\u0026amp; this.registry != null) { eagerlyInitialize(); } } private void eagerlyInitialize() { for (String name : this.context.getBeanDefinitionNames()) { BeanDefinition definition = this.registry.getBeanDefinition(name); if (this.getName().equals(definition.getScope()) \u0026amp;\u0026amp; !definition.isLazyInit()) { Object bean = this.context.getBean(name); if (bean != null) { bean.getClass(); } } } } 在doGetBean时，对于Scope类型，是要走特殊的逻辑的，会从scopes中获取对应的scope。\nif (mbd.isSingleton()) {...} else if (mbd.isPrototype()) {...} else { String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) { throw new IllegalStateException(\u0026#34;No Scope registered for scope name \u0026#39;\u0026#34; + scopeName + \u0026#34;\u0026#39;\u0026#34;); } try { //会调到RefreshScope的get方法，将其添加到cache中 Object scopedInstance = scope.get(beanName, () -\u0026gt; { beforePrototypeCreation(beanName); try { return createBean(beanName, mbd, args); } finally { afterPrototypeCreation(beanName); } }); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); } catch (IllegalStateException ex) { throw new BeanCreationException(beanName, \u0026#34;Scope \u0026#39;\u0026#34; + scopeName + \u0026#34;\u0026#39; is not active for the current thread; consider \u0026#34; + \u0026#34;defining a scoped proxy for this bean if you intend to refer to it from a singleton\u0026#34;, ex); } } RefreshScope 这里需要先了解下scopes里面的内容从何而来，以及认识一下ScopeRefresh类。\nRefreshScope是实现了BeanFactoryPostProcessor接口的类，因此在执行到postProcessBeanFactory时，就会添加到scopes中去。\npublic void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException { this.beanFactory = beanFactory; beanFactory.registerScope(this.name, this); setSerializationId(beanFactory); } public void registerScope(String scopeName, Scope scope) { Assert.notNull(scopeName, \u0026#34;Scope identifier must not be null\u0026#34;); Assert.notNull(scope, \u0026#34;Scope must not be null\u0026#34;); if (SCOPE_SINGLETON.equals(scopeName) || SCOPE_PROTOTYPE.equals(scopeName)) { throw new IllegalArgumentException(\u0026#34;Cannot replace existing scopes \u0026#39;singleton\u0026#39; and \u0026#39;prototype\u0026#39;\u0026#34;); } //scopeName为refresh，value是this Scope previous = this.scopes.put(scopeName, scope); if (previous != null \u0026amp;\u0026amp; previous != scope) { if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Replacing scope \u0026#39;\u0026#34; + scopeName + \u0026#34;\u0026#39; from [\u0026#34; + previous + \u0026#34;] to [\u0026#34; + scope + \u0026#34;]\u0026#34;); } } else { if (logger.isTraceEnabled()) { logger.trace(\u0026#34;Registering scope \u0026#39;\u0026#34; + scopeName + \u0026#34;\u0026#39; with implementation [\u0026#34; + scope + \u0026#34;]\u0026#34;); } } } 同时RefreshScope继承了GenericScope，其大部分核心的逻辑都在GenericScope，GenericScope持有一个cache的对象，就是当前scope对应的所有的bean，cache的类型是ConcurrentHashMap。\n而在doCreateBean方法，scope.get会真正调到这里。\n@Override public Object get(String name, ObjectFactory\u0026lt;?\u0026gt; objectFactory) { BeanLifecycleWrapper value = this.cache.put(name, new BeanLifecycleWrapper(name, objectFactory)); this.locks.putIfAbsent(name, new ReentrantReadWriteLock()); try { //实际是调用objectFactory.getObject(); return value.getBean(); } catch (RuntimeException e) { this.errors.put(name, e); throw e; } } public Object getBean() { if (this.bean == null) { synchronized (this.name) { if (this.bean == null) { this.bean = this.objectFactory.getObject(); } } } return this.bean; } 刷新ScopeBean 在RefreshScope类中，表示刷新的方法有两个，分别是刷新单个bean或者刷新全部的bean，本质是调用的cache的remove和clear。\n当在缓存中删除之后，下一次再调用的时候，就会重新调用getBean来创造新的bean，这也是scope为refresh的本质。\npublic boolean refresh(String name) { if (!name.startsWith(SCOPED_TARGET_PREFIX)) { // User wants to refresh the bean with this name but that isn\u0026#39;t the one in the // cache... name = SCOPED_TARGET_PREFIX + name; } // Ensure lifecycle is finished if bean was disposable if (super.destroy(name)) { this.context.publishEvent(new RefreshScopeRefreshedEvent(name)); return true; } return false; } @ManagedOperation(description = \u0026#34;Dispose of the current instance of all beans \u0026#34; + \u0026#34;in this scope and force a refresh on next method execution.\u0026#34;) public void refreshAll() { super.destroy(); this.context.publishEvent(new RefreshScopeRefreshedEvent()); } protected boolean destroy(String name) { //移除指定bean BeanLifecycleWrapper wrapper = this.cache.remove(name); if (wrapper != null) { Lock lock = this.locks.get(wrapper.getName()).writeLock(); lock.lock(); try { wrapper.destroy(); } finally { lock.unlock(); } this.errors.remove(name); return true; } return false; } public void destroy() { List\u0026lt;Throwable\u0026gt; errors = new ArrayList\u0026lt;Throwable\u0026gt;(); //移除所有的bean Collection\u0026lt;BeanLifecycleWrapper\u0026gt; wrappers = this.cache.clear(); for (BeanLifecycleWrapper wrapper : wrappers) { try { Lock lock = this.locks.get(wrapper.getName()).writeLock(); lock.lock(); try { wrapper.destroy(); } finally { lock.unlock(); } } catch (RuntimeException e) { errors.add(e); } } if (!errors.isEmpty()) { throw wrapIfNecessary(errors.get(0)); } this.errors.clear(); } ","date":"2024-05-26T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/spring/refershscope/","title":"RefershScope源码分析"},{"content":"AopAutoConfiguration 在spring-boot-autoconfiguration的spring.factories中指定了org.springframework.boot.autoconfigure.aop.AopAutoConfiguration这个bean，因此会进行执行\n@Configuration(proxyBeanMethods = false) //默认开启，如果不配或者为true都是开启，为false则是关闭 @ConditionalOnProperty(prefix = \u0026#34;spring.aop\u0026#34;, name = \u0026#34;auto\u0026#34;, havingValue = \u0026#34;true\u0026#34;, matchIfMissing = true) public class AopAutoConfiguration { //如果项目中引入aspectjweaver包，则实例化AspectJAutoProxyingConfiguration否则实例化ClassProxyingConfiguration @Configuration(proxyBeanMethods = false) @ConditionalOnClass(Advice.class) static class AspectJAutoProxyingConfiguration { @Configuration(proxyBeanMethods = false) @EnableAspectJAutoProxy(proxyTargetClass = false) @ConditionalOnProperty(prefix = \u0026#34;spring.aop\u0026#34;, name = \u0026#34;proxy-target-class\u0026#34;, havingValue = \u0026#34;false\u0026#34;) static class JdkDynamicAutoProxyConfiguration { } //默认启用的是cglib代理，通过@EnableAspectJAutoProxy引入其他类（EnableAspectJAutoProxy）的配置 @Configuration(proxyBeanMethods = false) @EnableAspectJAutoProxy(proxyTargetClass = true) @ConditionalOnProperty(prefix = \u0026#34;spring.aop\u0026#34;, name = \u0026#34;proxy-target-class\u0026#34;, havingValue = \u0026#34;true\u0026#34;, matchIfMissing = true) static class CglibAutoProxyConfiguration { } } @Configuration(proxyBeanMethods = false) @ConditionalOnMissingClass(\u0026#34;org.aspectj.weaver.Advice\u0026#34;) @ConditionalOnProperty(prefix = \u0026#34;spring.aop\u0026#34;, name = \u0026#34;proxy-target-class\u0026#34;, havingValue = \u0026#34;true\u0026#34;, matchIfMissing = true) static class ClassProxyingConfiguration { @Bean static BeanFactoryPostProcessor forceAutoProxyCreatorToUseClassProxying() { return (beanFactory) -\u0026gt; { if (beanFactory instanceof BeanDefinitionRegistry) { BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory; AopConfigUtils.registerAutoProxyCreatorIfNecessary(registry); //默认也是cglib AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); } }; } } } AspectJAutoProxyingConfiguration和ClassProxyingConfiguration的区别在于\nClassProxyingConfiguration想要注册的是InfrastructureAdvisorAutoProxyCreator\nAspectJAutoProxyingConfiguration注册的则是AnnotationAwareAspectJAutoProxyCreator\n这里是不同级别的creator，总共存在三个，如果存在低级则替换成高级\nprivate static BeanDefinition registerOrEscalateApcAsRequired( Class\u0026lt;?\u0026gt; cls, BeanDefinitionRegistry registry, @Nullable Object source) { Assert.notNull(registry, \u0026#34;BeanDefinitionRegistry must not be null\u0026#34;); if (registry.containsBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME)) { BeanDefinition apcDefinition = registry.getBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME); if (!cls.getName().equals(apcDefinition.getBeanClassName())) { int currentPriority = findPriorityForClass(apcDefinition.getBeanClassName()); int requiredPriority = findPriorityForClass(cls); //如果当前等级小于需要的等级，则改为高等级 if (currentPriority \u0026lt; requiredPriority) { apcDefinition.setBeanClassName(cls.getName()); } } return null; } RootBeanDefinition beanDefinition = new RootBeanDefinition(cls); beanDefinition.setSource(source); //这个顺序有啥用？ beanDefinition.getPropertyValues().add(\u0026#34;order\u0026#34;, Ordered.HIGHEST_PRECEDENCE); beanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); registry.registerBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME, beanDefinition); return beanDefinition; } 这里先不熟悉三个creator的区别，有时间了搞，由于事务这里注册的是最高级别-AnnotationAwareAspectJAutoProxyCreator，所以先分析这个类\nAnnotationAwareAspectJAutoProxyCreator 观察类图\n这个类实现了BeanFactoryAware接口来获取beanFacotry\n实现了SmartInstantiationAwareBeanPostProcessor接口，主要重写了四个方法：predictBeanType、postProcessBeforeInstantiation、getEarlyBeanReference和postProcessAfterInstantiation，\npostProcessBeforeInstantiation主要是用于自定义了TargetSource的情况，但是没见在哪用过；\ngetEarlyBeanReference则适用于处理循环依赖的时候，核心方法是wrapIfNecessary\npostProcessAfterInstantiation则是正常的bean初始化结束后对bean进行aop增强的逻辑\n@Override public Object getEarlyBeanReference(Object bean, String beanName) { Object cacheKey = getCacheKey(bean.getClass(), beanName); this.earlyProxyReferences.put(cacheKey, bean); return wrapIfNecessary(bean, beanName, cacheKey); } @Override public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) { if (bean != null) { Object cacheKey = getCacheKey(bean.getClass(), beanName); if (this.earlyProxyReferences.remove(cacheKey) != bean) { return wrapIfNecessary(bean, beanName, cacheKey); } } return bean; } 增强流程 wrapIfNecessary protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) { if (StringUtils.hasLength(beanName) \u0026amp;\u0026amp; this.targetSourcedBeans.contains(beanName)) { return bean; } //已经存在表示这个bean处理过了 if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) { return bean; } //Advice、Pointcut、Advisor、AopInfrastructureBean为基础架构类，永远不可被代理 //Q\u0026amp;A 2024/4/27 // Q:shouldSkip里逻辑不懂,而且isInfrastructureClass排除了Advisor.class.isAssignableFrom(beanClass)，但实际上查询Advicors的时候又找的这个类型的bean，这怎么搞 // A: if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) { this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; } // Create proxy if we have advice. // async最大的问题就是这里没有扫描到 //获取所有匹配的Advisor,是排好序的 Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); if (specificInterceptors != DO_NOT_PROXY) { this.advisedBeans.put(cacheKey, Boolean.TRUE); //进行增强 Object proxy = createProxy( bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; } this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; } protected List\u0026lt;Advisor\u0026gt; findEligibleAdvisors(Class\u0026lt;?\u0026gt; beanClass, String beanName) { //先查找所有的候选Advisor List\u0026lt;Advisor\u0026gt; candidateAdvisors = findCandidateAdvisors(); //进行匹配 List\u0026lt;Advisor\u0026gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName); //追加了一个ExposeInvocationInterceptor.ADVISOR extendAdvisors(eligibleAdvisors); if (!eligibleAdvisors.isEmpty()) { //进行排序 //默认是AnnotationAwareOrderComparator.sort(advisors)；但是AspectJAwareAdvisorAutoProxyCreator重写了排序逻辑 eligibleAdvisors = sortAdvisors(eligibleAdvisors); } return eligibleAdvisors; } findCandidateAdvisors findCandidateAdvisors有两种，一种是继承了Advisor接口的bean（通过beanFactory直接查询），一种是标有@Aspect的（需要扫描所有的bean，然后反射获取切面所有的方法，每个方法单独封装为一个Advisor\npublic List\u0026lt;Advisor\u0026gt; getAdvisors(MetadataAwareAspectInstanceFactory aspectInstanceFactory) { Class\u0026lt;?\u0026gt; aspectClass = aspectInstanceFactory.getAspectMetadata().getAspectClass(); String aspectName = aspectInstanceFactory.getAspectMetadata().getAspectName(); validate(aspectClass); // We need to wrap the MetadataAwareAspectInstanceFactory with a decorator // so that it will only instantiate once. MetadataAwareAspectInstanceFactory lazySingletonAspectInstanceFactory = new LazySingletonAspectInstanceFactoryDecorator(aspectInstanceFactory); List\u0026lt;Advisor\u0026gt; advisors = new ArrayList\u0026lt;\u0026gt;(); //获取所有类的方法并排序，按照注解排序Around.class, Before.class, After.class, AfterReturning.class, AfterThrowing.class)-\u0026gt;按照方法名排序 for (Method method : getAdvisorMethods(aspectClass)) { //获取切面-将pointCut和Advice组装起来 Advisor advisor = getAdvisor(method, lazySingletonAspectInstanceFactory, 0, aspectName); if (advisor != null) { advisors.add(advisor); } } //这个是introduction机制，需要使用@DeclareParents注解 for (Field field : aspectClass.getDeclaredFields()) { Advisor advisor = getDeclareParentsAdvisor(field); if (advisor != null) { advisors.add(advisor); } } ... } private List\u0026lt;Method\u0026gt; getAdvisorMethods(Class\u0026lt;?\u0026gt; aspectClass) { List\u0026lt;Method\u0026gt; methods = new ArrayList\u0026lt;\u0026gt;(); ReflectionUtils.doWithMethods(aspectClass, methods::add, adviceMethodFilter); if (methods.size() \u0026gt; 1) { methods.sort(adviceMethodComparator); } return methods; } //先按照注解排序，再按照方法名称排序 Comparator\u0026lt;Method\u0026gt; adviceKindComparator = new ConvertingComparator\u0026lt;\u0026gt;( new InstanceComparator\u0026lt;\u0026gt;( Around.class, Before.class, After.class, AfterReturning.class, AfterThrowing.class), (Converter\u0026lt;Method, Annotation\u0026gt;) method -\u0026gt; { AspectJAnnotation\u0026lt;?\u0026gt; ann = AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(method); return (ann != null ? ann.getAnnotation() : null); }); Comparator\u0026lt;Method\u0026gt; methodNameComparator = new ConvertingComparator\u0026lt;\u0026gt;(Method::getName); adviceMethodComparator = adviceKindComparator.thenComparing(methodNameComparator); 获取Advisor public Advisor getAdvisor(Method candidateAdviceMethod, MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrderInAspect, String aspectName) { validate(aspectInstanceFactory.getAspectMetadata().getAspectClass()); //切点其实封装的就是表达式和切面类 AspectJExpressionPointcut expressionPointcut = getPointcut( candidateAdviceMethod, aspectInstanceFactory.getAspectMetadata().getAspectClass()); if (expressionPointcut == null) { return null; } //封装切点和Advice，advice其实就是那几种注解@Before、@After之类的 return new InstantiationModelAwarePointcutAdvisorImpl(expressionPointcut, candidateAdviceMethod, this, aspectInstanceFactory, declarationOrderInAspect, aspectName); } 获取切点 private AspectJExpressionPointcut getPointcut(Method candidateAdviceMethod, Class\u0026lt;?\u0026gt; candidateAspectClass) { AspectJAnnotation\u0026lt;?\u0026gt; aspectJAnnotation = AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(candidateAdviceMethod); if (aspectJAnnotation == null) { return null; } AspectJExpressionPointcut ajexp = new AspectJExpressionPointcut(candidateAspectClass, new String[0], new Class\u0026lt;?\u0026gt;[0]); //将方法上的注解的value值放到expression属性 ajexp.setExpression(aspectJAnnotation.getPointcutExpression()); if (this.beanFactory != null) { ajexp.setBeanFactory(this.beanFactory); } return ajexp; } 获取Advice public Advice getAdvice(Method candidateAdviceMethod, AspectJExpressionPointcut expressionPointcut, MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrder, String aspectName) { .... //主要就这几种场景的advice switch (aspectJAnnotation.getAnnotationType()) { case AtPointcut: if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Processing pointcut \u0026#39;\u0026#34; + candidateAdviceMethod.getName() + \u0026#34;\u0026#39;\u0026#34;); } return null; case AtAround: springAdvice = new AspectJAroundAdvice( candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); break; case AtBefore: springAdvice = new AspectJMethodBeforeAdvice( candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); break; case AtAfter: springAdvice = new AspectJAfterAdvice( candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); break; case AtAfterReturning: springAdvice = new AspectJAfterReturningAdvice( candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); AfterReturning afterReturningAnnotation = (AfterReturning) aspectJAnnotation.getAnnotation(); if (StringUtils.hasText(afterReturningAnnotation.returning())) { springAdvice.setReturningName(afterReturningAnnotation.returning()); } break; case AtAfterThrowing: springAdvice = new AspectJAfterThrowingAdvice( candidateAdviceMethod, expressionPointcut, aspectInstanceFactory); AfterThrowing afterThrowingAnnotation = (AfterThrowing) aspectJAnnotation.getAnnotation(); if (StringUtils.hasText(afterThrowingAnnotation.throwing())) { springAdvice.setThrowingName(afterThrowingAnnotation.throwing()); } break; default: throw new UnsupportedOperationException( \u0026#34;Unsupported advice type on method: \u0026#34; + candidateAdviceMethod); } Advisor排序逻辑 默认是AnnotationAwareOrderComparator.sort(advisors)；但是AspectJAwareAdvisorAutoProxyCreator重写了排序逻辑\nAnnotationAwareOrderComparator 这个类实现了OrderComparator，正常对于OrderComparator来说，其compare调用doCompare，里面的顺序以getOrder方法为主，getOrder调用的又是findOrder，及根据接口Ordered.getOrder获取顺序值\nprivate int doCompare(@Nullable Object o1, @Nullable Object o2, @Nullable OrderSourceProvider sourceProvider) { boolean p1 = (o1 instanceof PriorityOrdered); boolean p2 = (o2 instanceof PriorityOrdered); if (p1 \u0026amp;\u0026amp; !p2) { return -1; } else if (p2 \u0026amp;\u0026amp; !p1) { return 1; } int i1 = getOrder(o1, sourceProvider); int i2 = getOrder(o2, sourceProvider); return Integer.compare(i1, i2); } protected Integer findOrder(Object obj) { return (obj instanceof Ordered ? ((Ordered) obj).getOrder() : null); } 而AnnotationAwareOrderComparator则进行了扩展，对于使用了@Order注解的也可以做排序，主要是重写了findOrder方法\nprotected Integer findOrder(Object obj) { Integer order = super.findOrder(obj); if (order != null) { return order; } return findOrderFromAnnotation(obj); } @Nullable private Integer findOrderFromAnnotation(Object obj) { AnnotatedElement element = (obj instanceof AnnotatedElement ? (AnnotatedElement) obj : obj.getClass()); MergedAnnotations annotations = MergedAnnotations.from(element, SearchStrategy.TYPE_HIERARCHY); Integer order = OrderUtils.getOrderFromAnnotations(element, annotations); if (order == null \u0026amp;\u0026amp; obj instanceof DecoratingProxy) { return findOrderFromAnnotation(((DecoratingProxy) obj).getDecoratedClass()); } return order; } org.springframework.core.annotation.OrderUtils#findOrder private static Integer findOrder(MergedAnnotations annotations) { MergedAnnotation\u0026lt;Order\u0026gt; orderAnnotation = annotations.get(Order.class); if (orderAnnotation.isPresent()) { return orderAnnotation.getInt(MergedAnnotation.VALUE); } MergedAnnotation\u0026lt;?\u0026gt; priorityAnnotation = annotations.get(JAVAX_PRIORITY_ANNOTATION); if (priorityAnnotation.isPresent()) { return priorityAnnotation.getInt(MergedAnnotation.VALUE); } return null; } AspectJAwareAdvisorAutoProxyCreator.sort protected List\u0026lt;Advisor\u0026gt; sortAdvisors(List\u0026lt;Advisor\u0026gt; advisors) { List\u0026lt;PartiallyComparableAdvisorHolder\u0026gt; partiallyComparableAdvisors = new ArrayList\u0026lt;\u0026gt;(advisors.size()); for (Advisor advisor : advisors) { partiallyComparableAdvisors.add( new PartiallyComparableAdvisorHolder(advisor, DEFAULT_PRECEDENCE_COMPARATOR)); } List\u0026lt;PartiallyComparableAdvisorHolder\u0026gt; sorted = PartialOrder.sort(partiallyComparableAdvisors); if (sorted != null) { List\u0026lt;Advisor\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(advisors.size()); for (PartiallyComparableAdvisorHolder pcAdvisor : sorted) { result.add(pcAdvisor.getAdvisor()); } return result; } else { return super.sortAdvisors(advisors); } } private static final Comparator\u0026lt;Advisor\u0026gt; DEFAULT_PRECEDENCE_COMPARATOR = new AspectJPrecedenceComparator(); 先梳理一下陌生的类\nPartiallyComparableAdvisorHolder：持有Advisor和一个Comparator，重写了compareTo和fallbackCompareTo\nprivate static class PartiallyComparableAdvisorHolder implements PartialComparable { private final Advisor advisor; private final Comparator\u0026lt;Advisor\u0026gt; comparator; public PartiallyComparableAdvisorHolder(Advisor advisor, Comparator\u0026lt;Advisor\u0026gt; comparator) { this.advisor = advisor; this.comparator = comparator; } @Override public int compareTo(Object obj) { Advisor otherAdvisor = ((PartiallyComparableAdvisorHolder) obj).advisor; return this.comparator.compare(this.advisor, otherAdvisor); } @Override public int fallbackCompareTo(Object obj) { return 0; } AspectJPrecedenceComparator：默认还是AnnotationAwareOrderComparator，但是对于同一个切面的advisor做了自己的处理。但是在spring 5.2.7 之前是有用的，5.2.7之后，declarationOrderInAspect全部强制改为0了\n// Prior to Spring Framework 5.2.7, advisors.size() was supplied as the declarationOrderInAspect\n// to getAdvisor(\u0026hellip;) to represent the \u0026ldquo;current position\u0026rdquo; in the declared methods list.\n// However, since Java 7 the \u0026ldquo;current position\u0026rdquo; is not valid since the JDK no longer\n// returns declared methods in the order in which they are declared in the source code.\n// Thus, we now hard code the declarationOrderInAspect to 0 for all advice methods\n// discovered via reflection in order to support reliable advice ordering across JVM launches.\n// Specifically, a value of 0 aligns with the default value used in\n// AspectJPrecedenceComparator.getAspectDeclarationOrder(Advisor).\npublic AspectJPrecedenceComparator() { this.advisorComparator = AnnotationAwareOrderComparator.INSTANCE; } public int compare(Advisor o1, Advisor o2) { //即先拿order比较 int advisorPrecedence = this.advisorComparator.compare(o1, o2); if (advisorPrecedence == SAME_PRECEDENCE \u0026amp;\u0026amp; declaredInSameAspect(o1, o2)) { advisorPrecedence = comparePrecedenceWithinAspect(o1, o2); } return advisorPrecedence; } //拿声明顺序比较 private int comparePrecedenceWithinAspect(Advisor advisor1, Advisor advisor2) { boolean oneOrOtherIsAfterAdvice = (AspectJAopUtils.isAfterAdvice(advisor1) || AspectJAopUtils.isAfterAdvice(advisor2)); int adviceDeclarationOrderDelta = getAspectDeclarationOrder(advisor1) - getAspectDeclarationOrder(advisor2); //对于是否存在after，是两种逻辑，存在after的话，最后声明的有最高优先级，否则，最先声明的有最高优先级 //Q\u0026amp;A 2024/4/27 // Q: 完全不理解 // A: if (oneOrOtherIsAfterAdvice) { // the advice declared last has higher precedence if (adviceDeclarationOrderDelta \u0026lt; 0) { // advice1 was declared before advice2 // so advice1 has lower precedence return LOWER_PRECEDENCE; } else if (adviceDeclarationOrderDelta == 0) { return SAME_PRECEDENCE; } else { return HIGHER_PRECEDENCE; } } else { // the advice declared first has higher precedence if (adviceDeclarationOrderDelta \u0026lt; 0) { // advice1 was declared before advice2 // so advice1 has higher precedence return HIGHER_PRECEDENCE; } else if (adviceDeclarationOrderDelta == 0) { return SAME_PRECEDENCE; } else { return LOWER_PRECEDENCE; } } } 此外，这里使用的不是TimSort，而是PartialOrder(离散里的偏序）\n","date":"2024-04-27T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/spring/aop/","title":"Aop执行逻辑"},{"content":"自定义扩展\nJdk的SPI缺点在于需要遍历所有的扩展类并实例化，dubbo对此做了优化。\n使其支持按需实例化，其本质是将所有的扩展类Class存到map，通过getExtension(key)来实例化。\n支持IOC，使得任意扩展可以任意组合\n支持AOP，使得扩展可以被前后加强\n@SPI ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(); public static \u0026lt;T\u0026gt; ExtensionLoader\u0026lt;T\u0026gt; getExtensionLoader(Class\u0026lt;T\u0026gt; type) { if (type == null) { throw new IllegalArgumentException(\u0026#34;Extension type == null\u0026#34;); } if (!type.isInterface()) { throw new IllegalArgumentException(\u0026#34;Extension type (\u0026#34; + type + \u0026#34;) is not an interface!\u0026#34;); } if (!withExtensionAnnotation(type)) { throw new IllegalArgumentException(\u0026#34;Extension type (\u0026#34; + type + \u0026#34;) is not an extension, because it is NOT annotated with @\u0026#34; + SPI.class.getSimpleName() + \u0026#34;!\u0026#34;); } ExtensionLoader\u0026lt;T\u0026gt; loader = (ExtensionLoader\u0026lt;T\u0026gt;) EXTENSION_LOADERS.get(type); if (loader == null) { EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader\u0026lt;T\u0026gt;(type)); loader = (ExtensionLoader\u0026lt;T\u0026gt;) EXTENSION_LOADERS.get(type); } return loader; } dubbo中，所有扩展的接口都标有@SPI注解，使用ExtensionLoader来进行获取，ExtensionLoader被设计为不可被外部实例化，只能通过getExtensionLoader来获取并存储到了map中，因此每个类型都是不同的ExtensionLoader实力对象。\ngetExtensionClasses 扫描所有的扩展类本质上是扫描META-INF/services/，META-INF/dubbo/internal，META-INF/dubbo/三个目录下以org.apache或者com.alibaba为前缀的配置文件，并将class信息存储到cachedClasses持有的map中\nprivate Map\u0026lt;String, Class\u0026lt;?\u0026gt;\u0026gt; loadExtensionClasses() { cacheDefaultExtensionName(); Map\u0026lt;String, Class\u0026lt;?\u0026gt;\u0026gt; extensionClasses = new HashMap\u0026lt;\u0026gt;(); loadDirectory(extensionClasses, DUBBO_INTERNAL_DIRECTORY, type.getName()); loadDirectory(extensionClasses, DUBBO_INTERNAL_DIRECTORY, type.getName().replace(\u0026#34;org.apache\u0026#34;, \u0026#34;com.alibaba\u0026#34;)); loadDirectory(extensionClasses, DUBBO_DIRECTORY, type.getName()); loadDirectory(extensionClasses, DUBBO_DIRECTORY, type.getName().replace(\u0026#34;org.apache\u0026#34;, \u0026#34;com.alibaba\u0026#34;)); loadDirectory(extensionClasses, SERVICES_DIRECTORY, type.getName()); loadDirectory(extensionClasses, SERVICES_DIRECTORY, type.getName().replace(\u0026#34;org.apache\u0026#34;, \u0026#34;com.alibaba\u0026#34;)); return extensionClasses; } @Adapter SPI可以直接使用导入的扩展类，也可以使用适配器来进行切换。\nExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 以Protocol为例，其默认协议为dubbo，但使用的时候就是转换为了适配器。在通过AdaptiveClassCodeGenerator生成类的字符串后，通过Comiler编译为实际的class，然后实例化，并进行IOC装配。其Adaptive的代码如下所示，主要是对方法上有@Adapter的方法进行编写，其优先取用url中的协议，然后使用dubbo来进行兜底。\npackage com.books.dubbo.demo.provider; import org.apache.dubbo.common.extension.ExtensionLoader; public class Protocol$Adaptive implements org.apache.dubbo.rpc.Protocol { public void destroy() { throw new UnsupportedOperationException(\u0026#34;The method public abstract void org.apache.dubbo.rpc.Protocol.destroy() of interface org.apache.dubbo.rpc.Protocol is not adaptive method!\u0026#34;); } public int getDefaultPort() { throw new UnsupportedOperationException(\u0026#34;The method public abstract int org.apache.dubbo.rpc.Protocol.getDefaultPort() of interface org.apache.dubbo.rpc.Protocol is not adaptive method!\u0026#34;); } public org.apache.dubbo.rpc.Invoker refer(java.lang.Class arg0, org.apache.dubbo.common.URL arg1) throws org.apache.dubbo.rpc.RpcException { if (arg1 == null) throw new IllegalArgumentException(\u0026#34;url == null\u0026#34;); org.apache.dubbo.common.URL url = arg1; String extName = (url.getProtocol() == null ? \u0026#34;dubbo\u0026#34; : url.getProtocol()); if (extName == null) throw new IllegalStateException(\u0026#34;Failed to get extension (org.apache.dubbo.rpc.Protocol) name from url (\u0026#34; + url.toString() + \u0026#34;) use keys([protocol])\u0026#34;); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); } public org.apache.dubbo.rpc.Exporter export(org.apache.dubbo.rpc.Invoker arg0) throws org.apache.dubbo.rpc.RpcException { if (arg0 == null) throw new IllegalArgumentException(\u0026#34;org.apache.dubbo.rpc.Invoker argument == null\u0026#34;); if (arg0.getUrl() == null) throw new IllegalArgumentException(\u0026#34;org.apache.dubbo.rpc.Invoker argument getUrl() == null\u0026#34;); org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = (url.getProtocol() == null ? \u0026#34;dubbo\u0026#34; : url.getProtocol()); if (extName == null) throw new IllegalStateException(\u0026#34;Failed to get extension (org.apache.dubbo.rpc.Protocol) name from url (\u0026#34; + url.toString() + \u0026#34;) use keys([protocol])\u0026#34;); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol) ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0); } } 对于API层来说，provider进行暴露的时候调用protocol.export实际上就是调用Protocol$Adaptive的export方法，如果是dubbo，那么就是DubboProtocol;如果是thrift，那么就是ThriftProtocol。\n在Protocol$Adaptive中会再次通过ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(extName)来找到对应的实现类然后进行调用。\nprivate T createExtension(String name) { //在map中找到对应的类 Class\u0026lt;?\u0026gt; clazz = getExtensionClasses().get(name); if (clazz == null) { throw findException(name); } try { T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) { //实例化 EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); } //进行IOC装配 injectExtension(instance); //进行AOP增强 Set\u0026lt;Class\u0026lt;?\u0026gt;\u0026gt; wrapperClasses = cachedWrapperClasses; if (CollectionUtils.isNotEmpty(wrapperClasses)) { for (Class\u0026lt;?\u0026gt; wrapperClass : wrapperClasses) { instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); } } return instance; } catch (Throwable t) { throw new IllegalStateException(\u0026#34;Extension instance (name: \u0026#34; + name + \u0026#34;, class: \u0026#34; + type + \u0026#34;) couldn\u0026#39;t be instantiated: \u0026#34; + t.getMessage(), t); } } IOC ioc的本质实际上给扩展类中的set方法进行赋值\nprivate T injectExtension(T instance) { try { if (objectFactory != null) { for (Method method : instance.getClass().getMethods()) { if (isSetter(method)) { /** * Check {@link DisableInject} to see if we need auto injection for this property */ if (method.getAnnotation(DisableInject.class) != null) { continue; } //如果是setProtocol，那么入参肯定是Protocol.class Class\u0026lt;?\u0026gt; pt = method.getParameterTypes()[0]; if (ReflectUtils.isPrimitives(pt)) { continue; } try { //setProtocol的话就是protocol String property = getSetterProperty(method); //所以实际上是在扩展中寻找类型为Protocol.class和name为protocol的实例 Object object = objectFactory.getExtension(pt, property); if (object != null) { method.invoke(instance, object); } } catch (Exception e) { AOP AOP的典型应用场景是Filter，在invoke的前后进行一些业务操作。\n在扩展类中，有一类扩展是Wrapper类，在loadResource中的loadClass\nprivate void loadClass(Map\u0026lt;String, Class\u0026lt;?\u0026gt;\u0026gt; extensionClasses, java.net.URL resourceURL, Class\u0026lt;?\u0026gt; clazz, String name) throws NoSuchMethodException { if (!type.isAssignableFrom(clazz)) { throw new IllegalStateException(\u0026#34;Error occurred when loading extension class (interface: \u0026#34; + type + \u0026#34;, class line: \u0026#34; + clazz.getName() + \u0026#34;), class \u0026#34; + clazz.getName() + \u0026#34; is not subtype of interface.\u0026#34;); } //适配类 if (clazz.isAnnotationPresent(Adaptive.class)) { cacheAdaptiveClass(clazz); //包装类 } else if (isWrapperClass(clazz)) { cacheWrapperClass(clazz); //普通扩展类 } else { if (ArrayUtils.isNotEmpty(names)) { //如果有@Activate注解进行记录 cacheActivateClass(clazz, names[0]); for (String n : names) { cacheName(clazz, n); saveInExtensionClass(extensionClasses, clazz, name); } } //决定是否是包装类的条件是，存在构造函数的入参为指定的类型 private boolean isWrapperClass(Class\u0026lt;?\u0026gt; clazz) { try { clazz.getConstructor(type); return true; } catch (NoSuchMethodException e) { return false; } //如果是的话就添加到了cachedWrapperClasses这个map中 private void cacheWrapperClass(Class\u0026lt;?\u0026gt; clazz) { if (cachedWrapperClasses == null) { cachedWrapperClasses = new ConcurrentHashSet\u0026lt;\u0026gt;(); } cachedWrapperClasses.add(clazz); } 像这种情况就是，ProtocolFilterWrapper是Protocol的包装类，回到之前的createExtension方法，就发现是实例化的包装类\nSet\u0026lt;Class\u0026lt;?\u0026gt;\u0026gt; wrapperClasses = cachedWrapperClasses; if (CollectionUtils.isNotEmpty(wrapperClasses)) { for (Class\u0026lt;?\u0026gt; wrapperClass : wrapperClasses) { instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); } } 激活多个扩展 上述的情况在使用的时候都是使用单个扩展，通过名字来指定。但是有些场景下是会同时实例化好多扩展的，这种场景下一般都是标为@Activate注解的扩展类。\n会根据dubbo对应的url进行分析，需要激活那些扩展。\npublic List\u0026lt;T\u0026gt; getActivateExtension(URL url, String[] values, String group) { List\u0026lt;T\u0026gt; exts = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;String\u0026gt; names = values == null ? new ArrayList\u0026lt;\u0026gt;(0) : Arrays.asList(values); if (!names.contains(Constants.REMOVE_VALUE_PREFIX + Constants.DEFAULT_KEY)) { getExtensionClasses(); for (Map.Entry\u0026lt;String, Object\u0026gt; entry : cachedActivates.entrySet()) { String name = entry.getKey(); Object activate = entry.getValue(); String[] activateGroup, activateValue; if (activate instanceof Activate) { activateGroup = ((Activate) activate).group(); activateValue = ((Activate) activate).value(); } else if (activate instanceof com.alibaba.dubbo.common.extension.Activate) { activateGroup = ((com.alibaba.dubbo.common.extension.Activate) activate).group(); activateValue = ((com.alibaba.dubbo.common.extension.Activate) activate).value(); } else { continue; } //根据url进行匹配，只有实际需要的才会添加 if (isMatchGroup(group, activateGroup)) { T ext = getExtension(name); if (!names.contains(name) \u0026amp;\u0026amp; !names.contains(Constants.REMOVE_VALUE_PREFIX + name) \u0026amp;\u0026amp; isActive(activateValue, url)) { exts.add(ext); } } } exts.sort(ActivateComparator.COMPARATOR); } List\u0026lt;T\u0026gt; usrs = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; names.size(); i++) { String name = names.get(i); if (!name.startsWith(Constants.REMOVE_VALUE_PREFIX) \u0026amp;\u0026amp; !names.contains(Constants.REMOVE_VALUE_PREFIX + name)) { if (Constants.DEFAULT_KEY.equals(name)) { if (!usrs.isEmpty()) { exts.addAll(0, usrs); usrs.clear(); } } else { T ext = getExtension(name); usrs.add(ext); } } } if (!usrs.isEmpty()) { exts.addAll(usrs); } return exts; } ","date":"2024-03-17T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/distributed/dubbo/dubbo_spi/","title":"Dubbo的SPI增强"},{"content":"单机的限流工具\n使用 //普通的限流，不支持预热，使用的是SmoothBursty RateLimiter rateLimiter=RateLimiter.create(10); //获取令牌的时间 double acquire = rateLimiter.acquire(); //能否获取令牌 boolean b = rateLimiter.tryAcquire(); //支持预热的限流，使用的是Smoothwarmup RateLimiter warmupLimiter=RateLimiter.create(10,10, TimeUnit.SECONDS); //虽然创建了100个线程，但是每秒只有10个令牌，所以要花10秒 static void mock(){ RateLimiter rateLimiter=RateLimiter.create(10); ExecutorService executorService = Executors.newFixedThreadPool(100); for (int i = 0; i \u0026lt; 100; i++) { executorService.submit(()-\u0026gt;{ System.out.println(Thread.currentThread().getName()+\u0026#34; \u0026#34;+rateLimiter.acquire()+\u0026#34;秒执行结束\u0026#34;); }); } } 源码分析 RateLimiter 类图如图中所示，RateLimiter类只有两个属性，一个是计数器，一个是令牌.\nSleepingStopWatch 计数器的类型是SleepingStopwatch，是个抽象类，但其实现是通过匿名内部类实例化的。主要是持有了一个Stopwatch实例，同时重写了两个方法。\n而Stopwatch是通过计算两个纳秒值的差值来进行使用的。\npublic static SleepingStopwatch createFromSystemTimer() { //匿名内部类 return new SleepingStopwatch() { final Stopwatch stopwatch = Stopwatch.createStarted(); @Override protected long readMicros() { //转换单位 微秒 return stopwatch.elapsed(MICROSECONDS); } @Override protected void sleepMicrosUninterruptibly(long micros) { if (micros \u0026gt; 0) { //不可中断的睡眠 Uninterruptibles.sleepUninterruptibly(micros, MICROSECONDS); } } }; } public final class Stopwatch { //本质是System.nanoTime(); private final Ticker ticker; private boolean isRunning; //经过的时间 elapsedNanos += tick - startTick; private long elapsedNanos; private long startTick; public long elapsed(TimeUnit desiredUnit) { //转换时间 纳秒转为指定单位（微秒） return desiredUnit.convert(elapsedNanos(), NANOSECONDS); } mutexDoNotUseDirectly 令牌相对简单，使用了volatile和synchronized，并且使用了double-check，用于acquire方法和dosetrate等核心方法之前，因此，RateLimiter是线程安全的。\n// Can\u0026#39;t be initialized in the constructor because mocks don\u0026#39;t call the constructor. @CheckForNull private volatile Object mutexDoNotUseDirectly; private Object mutex() { Object mutex = mutexDoNotUseDirectly; if (mutex == null) { synchronized (this) { mutex = mutexDoNotUseDirectly; if (mutex == null) { mutexDoNotUseDirectly = mutex = new Object(); } } } return mutex; } SmoothRateLimiter SmoothRateLimiter是继承了RateLimiter，其本质是个基类，提供一些公共逻辑。\n一个核心的逻辑是\n当前线程来获取令牌时，只要存在令牌，如果令牌足够直接扣减令牌；\n如果令牌不足够，那么先将令牌扣光，然后nextFreeTicketMicros会追加剩下需要新创建令牌所需的时间，但这个代价由下一个线程来承受，当前线程不会阻塞。\n因此，在storedPermits不为空的情况下，acquire(1)和acquire(1000)对当前线程来说没有区别，但下一个线程要等待(1000-storedPermits)*stableIntervalMicros的时间\n//当前存储的令牌数量double storedPermits; //最大可存储的令牌数量 double maxPermits; /** * 每间隔多少时间产生一个permit，比如1秒5个令牌，那就是200ms */ double stableIntervalMicros; /** * The time when the next request (no matter its size) will be granted. After granting a request, * this is pushed further in the future. Large requests push this further than small requests. * 下一次可以获取permits的时间，很关键 */ private long nextFreeTicketMicros = 0L; SmoothBursty 获取令牌的时候不用等待。\n初始化部分 主要是要初始化成员变量\n//创建的时候都是通过RateLimiter.create来创建的 //permitsPerSecond是指每秒创建多少令牌，用于设置速率 static RateLimiter create(double permitsPerSecond, SleepingStopwatch stopwatch) { //SmoothBursty的突发指的意思是能满足瞬间的突发流量而无需等待 // 他可以提前缓存一些令牌，当流量突发的时候可以瞬间处理 //maxBurstSeconds固定为1，所以最多最多缓存1秒的令牌 RateLimiter rateLimiter = new SmoothBursty(stopwatch, 1.0 /* maxBurstSeconds */); //设置速率 rateLimiter.setRate(permitsPerSecond); return rateLimiter; } public final void setRate(double permitsPerSecond) { checkArgument( permitsPerSecond \u0026gt; 0.0 \u0026amp;\u0026amp; !Double.isNaN(permitsPerSecond), \u0026#34;rate must be positive\u0026#34;); synchronized (mutex()) { doSetRate(permitsPerSecond, stopwatch.readMicros()); } } @Override final void doSetRate(double permitsPerSecond, long nowMicros) { //同步更新库存和时间 resync(nowMicros); double stableIntervalMicros = SECONDS.toMicros(1L) / permitsPerSecond; //间隔在这里才赋值 this.stableIntervalMicros = stableIntervalMicros; //设置速率，也可能是新速率 doSetRate(permitsPerSecond, stableIntervalMicros); } //RateLimiter的令牌不是通过一个额外的线程来追加维护的，而是在关键的节点前计算出来的 //具体的实现就是resync方法，会在reserveEarliestAvailable和doSetRate两个方法前调用 void resync(long nowMicros) { // 如果nextFreeTicketMicros比当前时间还大，那表明有别的线程已经等到未来了,所以现在到未来的令牌都被占用了 //如果nextFreeTicketMicros比当前时间小，那么表明这段时间应该产生了新的令牌 if (nowMicros \u0026gt; nextFreeTicketMicros) { //coolDownIntervalMicros在SmoothBurste里面是固定间隔stableIntervalMicros //但是在初始化时，stableIntervalMicros还未赋值 //浮点数0可以做除数，那这个Infinity（无限大）有啥意义呢？ double newPermits = (nowMicros - nextFreeTicketMicros) / coolDownIntervalMicros(); storedPermits = min(maxPermits, storedPermits + newPermits); nextFreeTicketMicros = nowMicros; } } //初始化时真正的复制逻辑在这里 @Override void doSetRate(double permitsPerSecond, double stableIntervalMicros) { double oldMaxPermits = this.maxPermits; //最大数量，maxPermits 为 1 秒产生的 permits maxPermits = maxBurstSeconds * permitsPerSecond; //oldMaxPermits什么情况才能是无穷大？ if (oldMaxPermits == Double.POSITIVE_INFINITY) { // if we don\u0026#39;t special-case this, we would get storedPermits == NaN, below storedPermits = maxPermits; } else { //初始化的时候是0 storedPermits = (oldMaxPermits == 0.0) ? 0.0 // initial state //假如本来有10个，本来最大是100，现在每秒速率调整成50，那么就应该剩10/100*50 : storedPermits * maxPermits / oldMaxPermits; } } 获取令牌 有两种方式，\n一种是acquire(n)，不传令牌数量默认为1，这种情况下，如果获取到令牌，会返回等待的时间；但是如果无法立即获取到令牌，那么会在睡眠一段时间后，再返回，等同于是阻塞住一段时间，类似于时间片\n另一种tryAcquire，不传令牌数量默认为1，需要传一个等待时间，如果在这段等待时间内可以获取到令牌，那么返回true，否则返回false\npublic double acquire() { return acquire(1); } public boolean tryAcquire(Duration timeout) { return tryAcquire(1, toNanosSaturated(timeout), TimeUnit.NANOSECONDS); } public double acquire(int permits) { //计算时间 long microsToWait = reserve(permits); //执行sleep stopwatch.sleepMicrosUninterruptibly(microsToWait); //返回sleep的时长（秒） return 1.0 * microsToWait / SECONDS.toMicros(1L); } //下面两个方法逻辑比较简单，核心的方法是reserveEarliestAvailable final long reserve(int permits) { checkPermits(permits); synchronized (mutex()) { return reserveAndGetWaitLength(permits, stopwatch.readMicros()); } } final long reserveAndGetWaitLength(int permits, long nowMicros) { long momentAvailable = reserveEarliestAvailable(permits, nowMicros); return max(momentAvailable - nowMicros, 0); } final long reserveEarliestAvailable(int requiredPermits, long nowMicros) { //更新库存令牌和休眠时间，可以再回resync看看原逻辑 resync(nowMicros); //老的等待时间，也是返回结果，但是会加上新的等待时间 long returnValue = nextFreeTicketMicros; //返回可以返回的令牌 double storedPermitsToSpend = min(requiredPermits, this.storedPermits); //不够的令牌 double freshPermits = requiredPermits - storedPermitsToSpend; //根据不够的令牌计算需要等待多久 long waitMicros = //这个方法很重要，是和warmingup的重要区别 storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend)//SmoothBursty固定是0 + (long) (freshPermits * stableIntervalMicros); //追加等待时间 this.nextFreeTicketMicros = LongMath.saturatedAdd(nextFreeTicketMicros, waitMicros); //减少库存 this.storedPermits -= storedPermitsToSpend; return returnValue; } //try的部分 public boolean tryAcquire(int permits, long timeout, TimeUnit unit) { long timeoutMicros = max(unit.toMicros(timeout), 0); checkPermits(permits); long microsToWait; synchronized (mutex()) { long nowMicros = stopwatch.readMicros(); //如果不能获取，立即返回false，否则和acquire一样的逻辑 if (!canAcquire(nowMicros, timeoutMicros)) { return false; } else { microsToWait = reserveAndGetWaitLength(permits, nowMicros); } } stopwatch.sleepMicrosUninterruptibly(microsToWait); return true; } private boolean canAcquire(long nowMicros, long timeoutMicros) { //当前时间+可以忍受的等待时间是否大于目前下一次可以获取令牌的时间，queryEarliestAvailable是nextFreeTicketMicros return queryEarliestAvailable(nowMicros) - timeoutMicros \u0026lt;= nowMicros; } SmoothWarmingUp 这个类主要是为了考虑资源需要预热的情况，不同于SmoothBursty，当并发量来的时候，会立刻返回存货，没有存货也是以固定的速率等待新的令牌产生；而这里，如果想要获取令牌，任何时候都是需要等待的，等待时间还是不固定的，当库存中令牌越多，等待时间要越久，这个时间就是为了预热其他资源的。\n观察这张图，x轴表示令牌，y轴表示获取令牌等待的时间。初始是stableIntervalMicros，和smoothBursty是一样的。但随着令牌增多，获取时等待的时间就越来越长。当桶中的令牌越多时，我们一般认为系统是越冷的，在这种情况下，获取令牌会越来越慢。\npublic static RateLimiter create(double permitsPerSecond, Duration warmupPeriod) { return create(permitsPerSecond, toNanosSaturated(warmupPeriod), TimeUnit.NANOSECONDS); } 在创建的时候，除了permitsPerSecond，还有一个warmupPeriod，\n图的理解 coldInterval=codeFactor*stableInterval,codeFactor恒定为3\n变冷速率等于 maxPermits/warmupPeriod\n从maxPermits到thresholdPermits是warmupPeriod\n从0移动到thresholdPermits是warmupPeriod/2\nThe reason that this is warmupPeriod/2 is to maintain the behavior of the original implementation where coldFactor was hard coded as 3\n为什么面积就是2倍呢？老版本的源码thresholdPermits就是halfPermits，如果halfPermits就是maxPermits的一半，那确实是两倍，那问题就是thresholdPermits为啥要是一半呢？\n源码分析 计算属性\nvoid doSetRate(double permitsPerSecond, double stableIntervalMicros) { double oldMaxPermits = maxPermits; double coldIntervalMicros = stableIntervalMicros * coldFactor; //warmupPeriodMicros为梯形面积，warmupPeriodMicros=2*s*t，所以 thresholdPermits = 0.5 * warmupPeriodMicros / stableIntervalMicros; //这里是因为梯形面积是warmupPeriod = 0.5 * (stableInterval + coldInterval) * (maxPermits - thresholdPermits) maxPermits = thresholdPermits + 2.0 * warmupPeriodMicros / (stableIntervalMicros + coldIntervalMicros); //对边比临边 slope = (coldIntervalMicros - stableIntervalMicros) / (maxPermits - thresholdPermits); if (oldMaxPermits == Double.POSITIVE_INFINITY) { // if we don\u0026#39;t special-case this, we would get storedPermits == NaN, below storedPermits = 0.0; } else { storedPermits = (oldMaxPermits == 0.0) ? maxPermits // initial state is cold : storedPermits * maxPermits / oldMaxPermits; } } 冷却时间（每隔多久产生一个令牌）\ndouble coolDownIntervalMicros() { return warmupPeriodMicros / maxPermits; } 等待时间\n对应的其实就是图中令牌k-x的面积\nlong storedPermitsToWaitTime(double storedPermits, double permitsToTake) { double availablePermitsAboveThreshold = storedPermits - thresholdPermits; long micros = 0; // measuring the integral on the right part of the function (the climbing line) //如果梯形里面有令牌 if (availablePermitsAboveThreshold \u0026gt; 0.0) { //梯形里面能取的令牌，也就是高 double permitsAboveThresholdToTake = min(availablePermitsAboveThreshold, permitsToTake); // TODO(cpovirk): Figure out a good name for this variable. // 理论上应该是上底+下底 double length = permitsToTime(availablePermitsAboveThreshold) + permitsToTime(availablePermitsAboveThreshold - permitsAboveThresholdToTake); micros = (long) (permitsAboveThresholdToTake * length / 2.0); permitsToTake -= permitsAboveThresholdToTake; } //permitsToTake是剩余的要取的令牌，所以这是长方形部分 // measuring the integral on the left part of the function (the horizontal line) micros += (long) (stableIntervalMicros * permitsToTake); return micros; } private double permitsToTime(double permits) { //s高+临边*斜率（对边） return stableIntervalMicros + permits * slope; } 参考文档: RateLimiter 源码分析(Guava 和 Sentinel 实现)_Javadoop\n","date":"2024-01-06T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/tool/guava_ratelimiter/","title":"Guava的RateLimiter"},{"content":"redolog 从ACID了解到，对于数据库来说，原子性和持久性是为了保证数据修改之后就不会再有变换，但是持久性这个动作不是一个原子性的操作，包含写入、未写入和正在写多个状态。\n假如是未提交事务（内存操作），这个时候就将数据落盘，那么这个时候如果崩溃了，在恢复数据的时候，就要将落盘的数据修改为未提交事务之前的数据。\n假如是提交事务了（内存操作），这个时候数据还没有落盘，这个时候如果崩溃，就要在磁盘补充所落下的部分。\n因此，不能将写入磁盘作为一个简单的动作看待，目前通用的方案是通过日志顺序写入，在提交事务后，日志追加Commit record语句，然后开始写入磁盘，当完全写入之后，追加End record语句，这种方案被称为Commit Log，这个日志被称为redo Log.\n至此redolog其实是为了解耦内存和硬盘的一致性，那核心原因是什么呢？\n就在于顺序IO和随机IO的不同\nundolog 但是这样存在的问题就是，写入磁盘的动作一定是在提交事务（日志写入Commit record）之后，这样子无法利用可能空闲的磁盘IO，这样对数据库的性能有一定的影响。\n因此，ARIES理论提出了一个 write-head logging（提前写入)的方案，他将根据事务提交前后分为不同的状态。\nForce：事务提交后就一定要落入磁盘。\nNoForce: 事务提交后不一定要立即落入磁盘。因为有了日志，随时可以落入磁盘。\nSTEAL：事务在提交前，允许数据提前写入。\nNOSTEAL：事务在提交前，不允许数据提前写入。\n像上面的Commit Log，就是属于 NotForce-NoSteal，这是因为假如事务提交前，数据已经提前写入，这个时候崩溃了的话，恢复的时候，不知道恢复成什么样子。\n因此，为了可以提前写入数据，崩溃时为了知道恢复成什么样子，就需要另一个日志来保证恢复数据，这个日志记录要记录各个版本的数据。这个日志就是undolog。\n这样子的话，崩溃恢复的时候，就会经历三个阶段\n分析：找到所有没有end record的事务\n重做：将所有有Commit record的数据落入磁盘，并追加end record\n回滚：将经历过上两个状态的剩余的事务，即没有Commit record的数据，根据undolog进行回滚。\nredolog和binlog的同步问题 redolog分析过了，主要是实现事务的原子性；\n由binlog可知，其内部也会记录事务相关的数据，主要用于恢复和主从中，那么redolog和binlog以谁为准呢？先写redolog还是binlog呢？\n假如先写redolog，那么在binlog写入之前crash的话，主库会由这个事务的更新记录，从库因为binlog中没有，所以主从不一致。\n假如先写binlog，在写redolog中发生crash，那么则是从库由，主库没有。\n因此，对于这个问题，不能简单的采用先后来完成，而是采用XA的两段式提交方案，\n先写redolog，此时redolog是prepare状态；然后写binlog（write/fsync)，在binlog写完之后，redolog追加commit标志事务提交。\n换句话说，就是将redolog和binlog视作不同的资源，只有两个资源都准备完成的时候，才进行提交，否则就进行回滚。\n而整体是以binlog为基准的\n当redolog在做的时候crash的话，由于此时事务还未提交，binlog中也没有，所以直接回滚即可，数据是一致的。\n当redolog做完，在写binlog的时候crash的话，binlog中也没有，因此还是回滚。\n当binlog写完的时候，crash的话，由于binlog中存在，已找到最新的事务id，然后在redolog重做，没有commit record的要追加commit record；\n但是这里的前提是，开始了binlog，因为binlog 是有可能不开启的。\n关于XA提交时引发的性能问题？ XA协议binlog 和 redo log的一致性问题\n参考文档： 11 | 本地事务如何实现原子性和持久性？-极客时间\n02 | 日志系统：一条SQL更新语句是如何执行的？-极客时间\nMySQL中binlog和redo log的一致性问题_binlog 和 redo不同步-CSDN博客\n23 | MySQL是怎么保证数据不丢的？-极客时间\n","date":"2023-12-30T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/mysql/undolog_redolog/","title":"UndoLog和redoLog"},{"content":"@EnableAsync @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Import(AsyncConfigurationSelector.class) public @interface EnableAsync { //这里应该是可以自定义注解 Class\u0026lt;? extends Annotation\u0026gt; annotation() default Annotation.class; boolean proxyTargetClass() default false; AdviceMode mode() default AdviceMode.PROXY; int order() default Ordered.LOWEST_PRECEDENCE; 由Spring注册BeanDefinition的方式 可知，@Enable的@Import注解中的AsyncConfigurationSelector是为了注册指定的bean，加上default AdviceMode.PROXY，结合下面代码，注册的是ProxyAsyncConfiguration，而里面最重要的是定义了AsyncAnnotationBeanPostProcessor这个Bean\n@Override @Nullable public String[] selectImports(AdviceMode adviceMode) { switch (adviceMode) { case PROXY: return new String[] {ProxyAsyncConfiguration.class.getName()}; case ASPECTJ: return new String[] {ASYNC_EXECUTION_ASPECT_CONFIGURATION_CLASS_NAME}; default: return null; } } public class ProxyAsyncConfiguration extends AbstractAsyncConfiguration { @Bean（name=\u0026#34;internalAsyncAnnotationProcessor\u0026#34;) public AsyncAnnotationBeanPostProcessor asyncAdvisor() { Assert.notNull(this.enableAsync, \u0026#34;@EnableAsync annotation metadata was not injected\u0026#34;); AsyncAnnotationBeanPostProcessor bpp = new AsyncAnnotationBeanPostProcessor(); //这两个配置默认是空的，想要自定义需要实现AsyncConfigurer接口 bpp.configure(this.executor, this.exceptionHandler); //这意味着可以自定义注解 Class\u0026lt;? extends Annotation\u0026gt; customAsyncAnnotation = this.enableAsync.getClass(\u0026#34;annotation\u0026#34;); if (customAsyncAnnotation != AnnotationUtils.getDefaultValue(EnableAsync.class, \u0026#34;annotation\u0026#34;)) { bpp.setAsyncAnnotationType(customAsyncAnnotation); } bpp.setProxyTargetClass(this.enableAsync.getBoolean(\u0026#34;proxyTargetClass\u0026#34;)); bpp.setOrder(this.enableAsync.\u0026lt;Integer\u0026gt;getNumber(\u0026#34;order\u0026#34;)); return bpp; } AsyncAnnotationBeanPostProcessor实现了BeanFactoryAware接口，因此在initializeBean之前就先调用了aware接口的setBeanFactory，最终是制造了一个AsyncAnnotationAdvisor作为后处理器的一个属性\n#AsyncAnnotationBeanPostProcessor @Override public void setBeanFactory(BeanFactory beanFactory) { super.setBeanFactory(beanFactory); AsyncAnnotationAdvisor advisor = new AsyncAnnotationAdvisor(this.executor, this.exceptionHandler); if (this.asyncAnnotationType != null) { advisor.setAsyncAnnotationType(this.asyncAnnotationType); } advisor.setBeanFactory(beanFactory); this.advisor = advisor; } #AsyncAnnotationAdvisor public AsyncAnnotationAdvisor( @Nullable Supplier\u0026lt;Executor\u0026gt; executor, @Nullable Supplier\u0026lt;AsyncUncaughtExceptionHandler\u0026gt; exceptionHandler) { ////默认应该是@Async和@Asynchronous注解，但可以调用setAsyncAnnotationType来覆盖 Set\u0026lt;Class\u0026lt;? extends Annotation\u0026gt;\u0026gt; asyncAnnotationTypes = new LinkedHashSet\u0026lt;\u0026gt;(2); asyncAnnotationTypes.add(Async.class); try { asyncAnnotationTypes.add((Class\u0026lt;? extends Annotation\u0026gt;) ClassUtils.forName(\u0026#34;javax.ejb.Asynchronous\u0026#34;, AsyncAnnotationAdvisor.class.getClassLoader())); } catch (ClassNotFoundException ex) { // If EJB 3.1 API not present, simply ignore. } //实例化了一个拦截器---AnnotationAsyncExecutionInterceptor this.advice = buildAdvice(executor, exceptionHandler); //构造了两个切点，一个是类维度，一个是方法维度的 this.pointcut = buildPointcut(asyncAnnotationTypes); } 所以，当实例化对象执行到postProcessAfterInitialization的时候，就会执行AsyncAnnotationBeanPostProcessor的postProcessAfterInitialization\npublic Object postProcessAfterInitialization(Object bean, String beanName) { if (this.advisor == null || bean instanceof AopInfrastructureBean) { // Ignore AOP infrastructure such as scoped proxies. return bean; } if (bean instanceof Advised) { Advised advised = (Advised) bean; if (!advised.isFrozen() \u0026amp;\u0026amp; isEligible(AopUtils.getTargetClass(bean))) { // Add our local Advisor to the existing proxy\u0026#39;s Advisor chain... if (this.beforeExistingAdvisors) { advised.addAdvisor(0, this.advisor); } else { advised.addAdvisor(this.advisor); } return bean; } } //如果是aop代理的 //通过getPointcut获取是否匹配 if (isEligible(bean, beanName)) { ProxyFactory proxyFactory = prepareProxyFactory(bean, beanName); if (!proxyFactory.isProxyTargetClass()) { evaluateProxyInterfaces(bean.getClass(), proxyFactory); } proxyFactory.addAdvisor(this.advisor); customizeProxyFactory(proxyFactory); // Use original ClassLoader if bean class not locally loaded in overriding class loader ClassLoader classLoader = getProxyClassLoader(); if (classLoader instanceof SmartClassLoader \u0026amp;\u0026amp; classLoader != bean.getClass().getClassLoader()) { classLoader = ((SmartClassLoader) classLoader).getOriginalClassLoader(); } //匹配的话会在这里对对象进行加强，通过调用getAdvice return proxyFactory.getProxy(classLoader); } // No proxy needed. return bean; } protected boolean isEligible(Class\u0026lt;?\u0026gt; targetClass) { Boolean eligible = this.eligibleBeans.get(targetClass); if (eligible != null) { return eligible; } if (this.advisor == null) { return false; } //底层是匹配getPointcut eligible = AopUtils.canApply(this.advisor, targetClass); this.eligibleBeans.put(targetClass, eligible); return eligible; } @Async 从上面知道，最终起效的是一个拦截器AnnotationAsyncExecutionInterceptor，这样，当我们执行到被@Async注释的方法时，其实是执行的拦截器的invoke方法\nprotected Advice buildAdvice( @Nullable Supplier\u0026lt;Executor\u0026gt; executor, @Nullable Supplier\u0026lt;AsyncUncaughtExceptionHandler\u0026gt; exceptionHandler) { AnnotationAsyncExecutionInterceptor interceptor = new AnnotationAsyncExecutionInterceptor(null); interceptor.configure(executor, exceptionHandler); return interceptor; } public void configure(@Nullable Supplier\u0026lt;Executor\u0026gt; defaultExecutor, @Nullable Supplier\u0026lt;AsyncUncaughtExceptionHandler\u0026gt; exceptionHandler) { //没设置也有兜底的线程池,在容器查找TaskExecutor.class或者名为taskExecutor，类型是Executor.class的bean this.defaultExecutor = new SingletonSupplier\u0026lt;\u0026gt;(defaultExecutor, () -\u0026gt; getDefaultExecutor(this.beanFactory)); this.exceptionHandler = new SingletonSupplier\u0026lt;\u0026gt;(exceptionHandler, SimpleAsyncUncaughtExceptionHandler::new); } public Object invoke(final MethodInvocation invocation) throws Throwable { Class\u0026lt;?\u0026gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); Method specificMethod = ClassUtils.getMostSpecificMethod(invocation.getMethod(), targetClass); final Method userDeclaredMethod = BridgeMethodResolver.findBridgedMethod(specificMethod); //获取线程池，@Async指定的线程池bean名称\u0026gt;AsyncConfigurer指定的线程池\u0026gt;beanFactory的线程池 AsyncTaskExecutor executor = determineAsyncExecutor(userDeclaredMethod); if (executor == null) { throw new IllegalStateException( \u0026#34;No executor specified and no default executor set on AsyncExecutionInterceptor either\u0026#34;); } Callable\u0026lt;Object\u0026gt; task = () -\u0026gt; { try { Object result = invocation.proceed(); if (result instanceof Future) { return ((Future\u0026lt;?\u0026gt;) result).get(); } } return null; }; return doSubmit(task, executor, invocation.getMethod().getReturnType()); } @Async循环依赖问题 以下面的代码为demo启动时，\n@Service public class Bean1 { @Autowired private Bean2 bean2; @Async public void test(){ System.out.println(\u0026#34;Bean1\u0026#34;); } } @Service public class Bean2 { @Autowired private Bean1 bean1; public void test(){ System.out.println(\u0026#34;Bean2\u0026#34;); } } //启动报错 Error creating bean with name \u0026#39;bean1\u0026#39;: Bean with name \u0026#39;bean1\u0026#39; has been injected into other beans [bean2] in its raw version as part of a circular reference, but has eventually been wrapped. This means that said other beans do not use the final version of the bean. This is often the result of over-eager type matching - consider using \u0026#39;getBeanNamesForType\u0026#39; with the \u0026#39;allowEagerInit\u0026#39; flag turned off, for example. 报错的地方是初始化完之后，再校验暴漏的bean和本来的bean是否一样时报的错\n本来的bean通过getEarlyBeanReference获取到，是没有代理的bean\n但是由于使用了@Async，导致在AsyncAnnotationBeanPostProcessor.postProcessAfterInitialization方法中对bean进行了加强\n但是，根据上面的源码研究，async其实也是属于使用了spring的aop机制，自定义了advisor，那为什么没有像aop一样使用二级缓存呢？\n最核心的问题就在于，getAdvicesAndAdvisorsForBean并没有找到自定义的advisor，原因是AsyncAnnotationAdvisor没有注册为bean,AsyncAnnotationAdvisor只是作为asyncAnnotationBeanPostProcessor的一个属性\n解决方案\n使用@lazy注解在任意一个bean上\n原理是在递归处理的时候，生成一个虚假的代理，真正使用的时候再生成真的\n补充，必须得是使用了@Async的提前暴漏了，才会抛这个异常；\n先加载的如果有@Async，那么后加载的bean注入的有@Async的bean就是一个未加强的，导致后加载的这个bean不正确；\n先加载的如果没有@Async，那么后加载的bean注入的本身就是原bean，所以后加载的没有问题，然后后加载的流程走完之后，由于其带有@async，所以是加强过的，而先加载的bean依赖的是加强过的bean，所以这个时候两个bean都正确\n参考文档: Spring Boot 2.0.0 升级到2.4.1 循环依赖问题的解决\n","date":"2023-12-26T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/spring/async/","title":"@Async源码分析"},{"content":"通过在org.springframework.beans.factory.support.DefaultListableBeanFactory#registerBeanDefinition这个方法打断点可以知晓所有的注册途径\nxml注册bean ClassPathXmlApplicationContext ctx = new ClassPathXmlApplicationContext(\u0026#34;/note/simpleApplication.xml\u0026#34;); assertThat(ctx.containsBean(\u0026#34;noteFirst\u0026#34;)).isTrue(); assertThat(ctx.containsBean(\u0026#34;noteBean\u0026#34;)).isTrue();ctx.close(); 需要在配置文件中指定bean或者指定扫描的包\n\u0026lt;bean id=\u0026#34;noteFirst\u0026#34; name=\u0026#34;noteFirst\u0026#34; class=\u0026#34;org.springframework.note.NoteFirst\u0026#34;/\u0026gt; \u0026lt;context:component-scan base-package=\u0026#34;org.springframework.note\u0026#34;\u0026gt;\u0026lt;/context:component-scan\u0026gt; 在refresh方法的obtainFreshBeanFactory-\u0026gt;refreshBeanFactory-\u0026gt;loadBeanDefinitions处理beanDefinition\n对于bean的处理，最终是在org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader#processBeanDefinition这个方法处理的\n对于context:component-scan，则会走到org.springframework.context.annotation.ComponentScanBeanDefinitionParser#parse，通过scan扫描到@Component、@ManagedBean、@Named的bean，通过org.springframework.beans.factory.support.BeanDefinitionReaderUtils#registerBeanDefinition方法注册\n注解注册 @Component 所有的@Component标注的类需要被扫描到才可以，不然不会加载，因此，也可以确定@Component标注的类是通过doScan来处理的\n对于这种的bean是需要通过beanDefinition的后处理器来加载bean，也就是refresh的invokeBeanFactoryPostProcessors方法\n这里的ConfigurationClassPostProcessor是通过内部注册到beanFactory的\n会调用ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry-\u0026gt;org.springframework.context.annotation.ConfigurationClassPostProcessor#processConfigBeanDefinitions\n如图，postProcessBeanDefinitionRegistry方法中处理ComponentBean的地方是在ConfigurationClassParser.parse，其最终执行的是ConfigurationClassParser#doProcessConfigurationClass\n但candidates必须有值，也就是说为了扫描别的bean，至少有一个bean已经注册且已经指定了ComponentScan的范围，一般来说如果是AnnotationConfigApplicationContext，那就是启动时指定的类\n而如果是springboot，那就是@SpringBootApplication标注的类\n最终会在下面这段代码扫描所有的Component\n@Bean @Bean是在加载@Component的bean之后进行处理的，虽然在bean定义阶段是一样的，但是@Configuration类中的@Bean是被动态代理了的\n当处理完所有的Component类之后，就可以通过ConfigClass处理里面的@bean所生产的bean，所以还是在ConfigurationClassPostProcessor#processConfigBeanDefinitions方法内\n最终走到的也是loadBeanDefinitionsForBeanMethod，然后调用了registerBeanDefinition\n@Import注册 分为两步\nprocessImports 第一步是将@Import内的类注册为ConfigClass，也是在ConfigurationClassParser#doProcessConfigurationClass 方法中，处理完ComponentScan就是@Import了\n同理，也必须是在某个bean类上的Import才有作用\n而processImport方法中，主要是有三部分，\nImportSelector 我们以事务为例，@EnableTransactionManagement注解，引入了TransactionManagementConfigurationSelector\n在处理到有@EnableTransactionManagement的任意一个bean的时候，就会走到上面的第一种情况\nselector字如其名，是通过某种选项来选择要构造的config类，\n下面的是TransactionManagementConfigurationSelector的实现，由于他是继承的aop的selector，所以是由adviceMdoe决定的，两种返回的bean是不同的；比如默认是PROXY，则返回的是两个bean，{AutoProxyRegistrar,ProxyTransactionManagementConfiguration}，之后会递归再次调用processImport方法\n因此这种情况只是为了提供一种选择，最终落地的还是二三种情况\nImportBeanDefinitionRegistrar 事务的selector提供的AutoProxyRegistrar会在递归之后执行到第二种情况，最终添加到了BeanDefinitionRegister中去，实现了ImportBeanDefinitionRegistrar接口的类主要工作是实现registerBeanDefinitions方法，用于自定义beanDefinition，这个方法后面才会调到\nConfigurationClass 事务的selector提供的第二个bean就是一个普通bean，最终会走到这种情况\n在这种情况下，会立即构建这个类为普通的config类\nimportStack.registerImport会在实例化之前设置一个元数据，除此之外不知道有啥用\n执行registerBeanDefinitions 这个方法的入口是在之前@bean处理的方法后面，具体工作就是注册自定义的bean\n比如MapperScan，就是注册指定包下所有的mapper和service\n具体实现具体分析\n内部注册 内部注册是指spring自己注册一些关键的bean，比如ConfigurationClassPostProcessor，通常是调用的AnnotationConfigUtils.registerAnnotationConfigProcessors方法注册的，一般是在refresh之前\n","date":"2023-12-25T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/spring/beandefinitionregistion/","title":"Spring注册BeanDefinition的方式"},{"content":"整体复盘： 一个不算普通的周五中午，同事收到了大量了cpu异常的报警。根据报警表现和通过arthas查看，很明显的问题就是内存不足，疯狂无效gc。而且结合arthas和gc日志查看，老年代打满了，gc不了一点。既然问题是内存问题，那么老样子，通过jmap和heap dump 文件分析。\n不感兴趣的可以直接看结论\n通过jmap命令查看的类似下图，并没有项目中明显的自定义类，而占空间最大的又是char数组，当时线上占900M左右，整个老年代也就1.8个G；此时dump文件同事还在下载，网速较慢。\n通过业务日志查看，很多restTempalte请求报错，根据报错信息可知是某xx认证过期了，导致接收到回调，业务处理时调接口报错了；查询数据库，大概有20多万回调。根据过期时间和内存监控，大概能对的上号，表明内存异常和这个认证过期有关。怀疑度最高的只有回调以及回调补偿任务，但是一行一行代码看过去，并不觉得有什么异常。\n在dump文件下载完之后，使用jvisualvm分析，最多的char里大部分都是一些请求的路径，如“example/test/1\u0026quot;，”“example/test/2\u0026quot;之类的，都是接口统一，但是参数不一样，因为是GET请求，所以实际路径都不一样。Jvisualvm点击gc_root又一直计算不出来，在等待计算的过程中，一度走了弯路（百度搜索到ImmutableTag这个类在skywalking有用过，但skywalking由于是jar包进行代理，项目中不存在对应的源码，所以又不得不下载公司的jar包反编译，然后去找http相关插件里翻源码，只是为了看一下ImmutableTag的具体结构）；此时，我们大概归纳到是http的监控在统计一些指标物料时，没有释放接口路径所引用的对象导致老年代打满）。 在gc_root终于计算出来之后，更是肯定了这个想法，但是hikari怎么可能监听http呢？\n于是又现下载jprofiler，通过jprofiler的聚类，确定了一定是这个Meter导致的，而通过JProfile的分析，终于定位到是\norg.springframework.boot.actuate.metrics.web.client.MetricsClientHttpRequestInterceptor#intercept这个类。然后发现，MetricsClientHttpRequestInterceptor 持有一个meterRegistry，里面核心是个map，所以一定是map没有清除。和我们最开始想的skywalking不一样，是springboot配套的监控，根据依赖分析，发现是有次需求引入了redisson-spring-boot-starter，而redisson依赖了spring-boot-starter-actuator，这东西默认启动了，会拦截所有的RestTempalte请求，然后记录一些指标。\n所以问题变成了，为什么map没有清掉已经执行完的请求？\n我之前并没有研究过spring的actuator，只是看过skywalking的流程，所以我以为也和skywalking一样，记录然后上报，上报之后删除本地的。所以当时怀疑，难道是和我们请求都异常了有关，但是正如下面的代码，无论是否异常，都是执行finnally，所以又不太可能。\nClientHttpResponse response = null; try { response = execution.execute(request, body); return response; } finally { try { getTimeBuilder(request, response).register(this.meterRegistry).record(System.nanoTime() - startTime, TimeUnit.NANOSECONDS); } catch (Exception ex) { logger.info(\u0026#34;Failed to record metrics.\u0026#34;, ex); } if (urlTemplate.get().isEmpty()) { urlTemplate.remove(); } } 而在我自己尝试复现之后，micrometer的指标根本不会被自动清除，生命周期和应用的生命周期一样。因为并不存在上报，数据全部在内存（虽然可以导出到数据库，但并没有深入研究）。其实也合理，因为如果要通过Grafana等可视化平台查看的时候，我们也希望查看任意时刻的监控。不过看代码应该是有留一些手动删除的，应该是页面操作之类的才会触发。\n结论 所以到此为止，可以定结论，那就是因为引入了redisson-spring-boot-starter，导致不知情引入了spring-boot-starter-actuator。\n因此默认开启了http.client.request指标的监控，关于http.client.request，有一个属性是maxUriTags，默认值是100，其作用是限制meterMap里uri的个数。但是maxUriTags起作用的地方MeterFilter没有生效。\n由于maxUriTags没有生效，导致监控信息里的uri因为业务大量的GET请求中存在唯一id，本身就很占内存。压死内存的最后稻草是认证过期和补偿任务。补偿任务为保证及时性一直在频繁执行，而接口的uri里两个变量（token和uniId）导致meterMap里的key不重复，一直在插入，20万回调，token两小时更新一次，持续了两天，最终产生了124万条字符串，被map持有，无法回收。\n解决方案 不需要监控 直接排除掉spring-boot-starter-actuator\n需要监控但不需要http.client.request指标 management: metrics: web: client: request: autotime: enabled: false 需要http.client.request指标 jar包升到2.5.1或以上\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-actuator-autoconfigure\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 复现： 新建测试项目\n相关代码和配置如下\n@SpringBootApplication @Slf4j public class Application { public static void main(String[] args) { ConfigurableApplicationContext run = SpringApplication.run(Application.class); RestTemplate bean = run.getBean(RestTemplate.class); for (int i = 0; i \u0026lt; 300000; i++) { try { String forObject = bean.getForObject(\u0026#34;http://localhost:9999/first/echo?i=\u0026#34;+i, String.class); }catch (Exception e){ log.error(\u0026#34;执行\u0026#34;+i+\u0026#34;次\u0026#34;); } } } } @Configuration public class RestTemplateTestConfig { @Bean public RestTemplate restTemplate(RestTemplateBuilder builder){ return builder.build(); } } \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.13.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; server: port: 8080 spring: redis: host: 101.43.164.254 password: hkc810215 #management: # endpoints: # web: # exposure: # include: \u0026#34;metrics\u0026#34; # metrics: # web: # client: # request: # autotime: # enabled: false 启动项目通过jconsole查看整个堆的监控和老年代监控分别如下，可以看出老年代一直在增长，并不会回收，\n甚至手动触发GC，老年代也回收不了\n[Full GC (System.gc()) [Tenured: 195217K-\u0026gt;195457K(204800K), 0.3975261 secs] 233021K-\u0026gt;195457K(296960K), [Metaspace: 30823K-\u0026gt;30823K(33152K)], 0.3976223 secs] [Times: user=0.39 sys=0.00, real=0.40 secs] 通过jprofiler确定主要是meterMap占据内存了，最多的都是字符串。\n分析 actuator导致rest启动了metrics记录 在使用RestTemplateBuilder构建RestTemplate的时候，会触发懒加载的RestTemplateAutoConfiguration里的RestTemplateBuilderConfigurer，在此期间，config中会注入RestTempalteCustomizer类型的bean。\n而项目中引用了redisson-spring-boot-starter，从依赖分析可以看出间接引用了actuator相关的包。\n这导致会在RestTemplateMetricsConfiguration配置类中实例化一个叫做MetricsRestTemplateCustomizer的bean，这个bean会通过上面的restTepalteBuilderConfigurer.configure方法给restTemplate添加拦截器MetricsClientHttpRequestInterceptor。\n拦截器的intercept方法会在finnally中最终记录此次请求的一些指标\nio.micrometer.core.instrument.Timer.Builder#register-\u0026gt;\nio.micrometer.core.instrument.MeterRegistry#time-\u0026gt;\nio.micrometer.core.instrument.MeterRegistry#registerMeterIfNecessary-\u0026gt;\nio.micrometer.core.instrument.MeterRegistry#getOrCreateMeter{\nmeterMap.put(mappedId, m);\n}\n最终存到了是SimpleMeterRegistry这个bean的meterMap中去，这个bean也是actuator-autoconfigure自动注入的\n但是到目前为止，只是启动了metrics记录，假如maxUriTags有效的话，会在超过100条记录后getOrCreateMeter方法里的accept这里过滤掉，并不会走到下面的meterMap.put(mappedId, m)\n为什么maxUriTags没有生效？ maxUriTags只在下图这个位置使用了，作用是构建了一个MeterFilter，根据debug我们可以确定bean是产生了的\n但是在accept这里打上断点，再触发一些请求可以发现，代码并不会走到这里\n往上跟，没有走到这里的情况只能是filters里没有这个MeterFilter，但我们刚才又确定metricsHttpCLientUriTagFilter这个bean是产生了的，那么就只能是没有添加到filters，也就是没有调用过meterFilter\n从meterFilter往上只有可能是addFilters，一层一层往上最终到了MeterRegistryPostProcessor#postProcessAfterInitialization这个方法\n我们上面说过负责记录的bean叫做simpleMeterRegistry，但是我们在这里打上条件断点发现并没有走到这里\n找到SimpleMeterRegistry和MeterRegistryPostProcessor这两个bean注入的地方打断点观察，都产生了，且MeterRegistryPostProcessor比SimpleMeterRegistry产生的要早\n理论上没问题，但现在确实没走到，所以只能在SimpleMeterRegistry产生的时候在org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#applyBeanPostProcessorsAfterInitialization打断点，然后可以发现，在simpleMeterRegistry实例化快结束的时候，调用后处理器时this.beanPostProcessors确实没有MeterRegistryPostProcessor\n一般来说，postPorcessor的bean注入是在refresh方法的registerBeanPostProcessors中，是早于普通bean的实例化\n所以simpleMeterRegistry实例化的时候没有MeterRegistryPostProcessor是不合理的情况，定位simpleMeterRegistry是何时实例化的成了关键问题\nsimpleMeterRegistry的实例化时机 在new SimpleMeterRegistry这里打上断点观察堆栈发现，simpleMeterRegistry是MetricsRepositoryMethodInvocationListener的参数，MetricsRepositoryMethodInvocationListener则是metricsRepositoryMethodInvocationListenerBeanPostProcessor的参数\n所以是在实例化metricsRepositoryMethodInvocationListenerBeanPostProcessor这个处理器的时候，因为依赖导致先实例化了simpleMeterRegistry这个bean\n依赖，导致实例化了SimpleMeterRegistry，而这个时候由于没有注册，所以SimpleMeterRegistry在执行applyBeanPostProcessorsAfterInitialization时就执行不到meterRegistryPostProcessor了\nspring已经修复了这个问题，spring-boot-actuator-autoconfigure版本大于2.5.0的都已经没有问题了。解决方案\n2.5.1 版本中，添加了一个这个ObjectProvider，在源头上不会立即把依赖的bean初始化完\n2.5.0 版本\npublic Object resolveDependency(DependencyDescriptor descriptor, @Nullable String requestingBeanName, @Nullable Set\u0026lt;String\u0026gt; autowiredBeanNames, @Nullable TypeConverter typeConverter) throws BeansException { descriptor.initParameterNameDiscovery(getParameterNameDiscoverer()); if (Optional.class == descriptor.getDependencyType()) { return createOptionalDependency(descriptor, requestingBeanName); } //由于使用了ObjectProvider，所以这里只是返回了一个DependencyObjectProvider else if (ObjectFactory.class == descriptor.getDependencyType() || ObjectProvider.class == descriptor.getDependencyType()) { return new DependencyObjectProvider(descriptor, requestingBeanName); } else if (javaxInjectProviderClass == descriptor.getDependencyType()) { return new Jsr330Factory().createDependencyProvider(descriptor, requestingBeanName); } else { //2.5.0版本中会在这个方法加载入参依赖的bean Object result = getAutowireCandidateResolver().getLazyResolutionProxyIfNecessary( descriptor, requestingBeanName); if (result == null) { result = doResolveDependency(descriptor, requestingBeanName, autowiredBeanNames, typeConverter); } return result; } } ","date":"2023-12-10T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/problem/springactuator_fullgc/","title":"偷偷开启的监控在吃内存"},{"content":"前言： 在看socket相关代码的时候，AbstractPlainSocketImpl中的一段代码吸引了我，其实之前见过很多次类似的代码，但一直不想去看，只知道肯定和权限什么的相关，这次既然又碰到了就研究一下，毕竟也不能对java基本代码一无所知。\nstatic { java.security.AccessController.doPrivileged( new java.security.PrivilegedAction\u0026lt;Void\u0026gt;() { public Void run() { System.loadLibrary(\u0026#34;net\u0026#34;); return null; } }); } 一些概念: 在jdk1.0的时代，applet依然是前端的一种可用的技术方案，比如可以嵌入在网页里运行。那个时候jdk的设计者们认为本地代码是安全的、远端代码是有风险的，而applet就是属于远端代码。因此，为了保证用户主机的安全和隐私，设计者参考了沙箱的思想，依托于当时jdk的体量很小，使用SecurityManager来分隔本地代码和远程代码，一个有权限，一个没有权限。\n当时还出现了签名相关的机制(本文不关心，所以没做了解），随着java发展，1.1的时候出现了JAVABEAN、JDBC、反射等新概念，于是有了更多的新权限。设计者发现完全授予本地代码所有权限变得不合理，在1.2的时候重构了SecurityManager，变成了现在这样以最小粒度控制权限。这个时候的SecurityManager有两个功能，一是防御远程代码、二是防御本地代码的漏洞。\n不知道是什么时候起，安全机制引入了域（ProtectDomain）的概念，也可以视作将一个大沙箱拆分为多个小沙箱。一个域对应一个沙箱，不同的代码（Codesource）被划分到不同域中，不同的域有着不同的权限（Permission），就像下图一样。同时可以给不同的域配置不同的权限，静态和动态均可，这个配置被称为策略(Policy)。 注意！\n在JDK20和JDK21的security-guide中都提到了，和SecurityManager与之相关的api已被弃用，并将在未来的版本中删除。SecurityManager没有替代者。有关讨论和备选方案，请参阅JEP 411: Deprecate the Security Manager for Removal。\nAccessController AccessController主要有两个功能，对应的核心方法也是两类\ncheckPermission(校验是否存在权限) public static void checkPermission(Permission perm) throws AccessControlException { AccessControlContext stack = getStackAccessControlContext(); // if context is null, we had privileged system code on the stack. //...其他获取context方法 AccessControlContext acc = stack.optimize(); acc.checkPermission(perm); } 调用该方法时，一般会new一个期望的权限，然后作为入参传入checkPermission方法。\nFilePermission perm = new FilePermission(\u0026#34;C:\\\\Users\\\\Administrator\\\\Desktop\\\\liveController.txt\u0026#34;, \u0026#34;read\u0026#34;); AccessController.checkPermission(perm); 注意，校验权限的时候会校验调用链路径上所有类的权限；假如调用链是从i开始，一直调用到m，校验逻辑如下\nfor (int i = m; i \u0026gt; 0; i--) { if (caller i\u0026#39;s domain does not have the permission) throw AccessControlException else if (caller i is marked as privileged) { if (a context was specified in the call to doPrivileged) context.checkPermission(permission) if (limited permissions were specified in the call to doPrivileged) { for (each limited permission) { if (the limited permission implies the requested permission) return; } } else return; } } 代码执行的时候，每一次方法的调用都代表着一次入栈，而权限校验的时候则正好是从栈顶开始，依次判断每个栈帧是否具有权限，一直到栈底。 doPrivileged(临时授权) public static native \u0026lt;T\u0026gt; T doPrivileged(PrivilegedAction\u0026lt;T\u0026gt; action); 这个方法的功能是将当前类所拥有的权限，能且仅能临时赋予其上游调用方。\n在这个场景下，必然存在多个域，且只有某些域拥有权限A，但是其他域并没有这个权限。在java语言中很容易出现这个情况，比如我们调用一些第三方jar包的方法，三方jar包还能调用别的三方jar包，这种场景很有可能只有最底层的方法所对应的域拥有权限。此时为了方法的成功，就可以使用该方法。\n使用的时候就是将代码逻辑放入AccessController.doPrivileged中即可，如下述代码一般。\n//项目B，会打成security-demo.jar public class PermissionDemo { /** * 使用特权访问机制 * @param file */ public void runWithOutPermission(String file){ AccessController.doPrivileged((PrivilegedAction\u0026lt;String\u0026gt;) () -\u0026gt; { //hutool的FileUtil String s = FileUtil.readString(file, \u0026#34;utf-8\u0026#34;); System.out.println(s); return s; }); } } //项目A，引入security-demo.jar public class Aperson { public static void main(String[] args) { new PermissionDemo().runWithOutPermission(\u0026#34;C:\\\\Users\\\\Administrator\\\\Desktop\\\\test.txt\u0026#34;); } } 这里需要注意的是，AccessController.doPrivileged所在的当前类也需要拥有权限。以这个例子为例，文件读写是在hutool的FileUtil中执行，hutool对应的是域C；PermissionDemo对应的是域B，且会将自身权限向上传递；而Aperson对应的是域A。这个例子中，想要Aperson执行成功，必须是域C和域B都拥有test.txt的read权限。\n对应的policy如下\ngrant codeBase \u0026#34;file:/C:/Users/Administrator/.m2/repository/cn/hutool/hutool-all/5.7.11/-\u0026#34;{ permission java.io.FilePermission \u0026#34;C:\\\\Users\\\\Administrator\\\\Desktop\\\\*\u0026#34;, \u0026#34;read\u0026#34;; }; grant codeBase \u0026#34;file:/C:/Users/Administrator/.m2/repository/xxx/xxx/security-demo/-\u0026#34;{ permission java.io.FilePermission \u0026#34;C:\\\\Users\\\\Administrator\\\\Desktop\\\\*\u0026#34;, \u0026#34;read\u0026#34;; }; 从栈帧的角度来看的话，判断到doPrivilege对应的那层之后，校验就直接返回了，不校验下面层是否存在权限。 ProtectDomain protectDomain类由codeSource和permission构成 CodeSource 类的来源，一般为jar包路径或者classpath路径（target/classes）\n因为所有类在通过ClassLoader引入的，所以ClassLoader知道类的基本信息，在defineClass时，将CodeSource和Permission进行了绑定。同理，由于类必须通过ClassLoader加载，对于使用自定义ClassLoader加载的类，就只有那个类加载器知道对应的CodeSource和permission。因此，不同的类加载器本身就属于不同的域。\nPermission Java抽象出的顶层的类，核心方法是implies，该方法用来判断当前线程是否隐含指定权限，由各自的子类实现。子类实现过多，这里就不列举了。\nPermissionCollection本质是个list，里面是某一类权限的多个实例，比如文件夹A-读权限，文件夹B-写权限，文件夹C-读写权限。\nPermissions核心是一个map,key是Permissoin子类,value是PermissionCollection\nSecurityManager SecurityManage里有一堆check方法，调用的是AccessController.checkPermission方法，入参就是Permission各个子类的实例化。\n开启方式： 隐性：启动时添加-Djava.security.manager\n显性：System.setSecurityManager\npublic class NoShowTest { static class CustomManager extends SecurityManager{ @Override public void checkRead(String file) { throw new AccessControlException(\u0026#34;无权限访问\u0026#34;); } } public static void main(String[] args) { System.setSecurityManager(new CustomManager()); System.getSecurityManager().checkRead(\u0026#34;C:\\\\Users\\\\Administrator\\\\Desktop\\\\liveController.txt\u0026#34;); } } Policy 启动时通过 -Djava.security.policy=xxxx\\custom.policy，如果没有指定，则默认使用jdk路径下\\jre\\lib\\security\\java.policy\n参考： Java安全:SecurityManager与AccessController - 掘金\nJava沙箱机制的实现——安全管理器、访问控制器 - 掘金\n第21章-再谈类的加载器\nhttps://openjdk.org/jeps/411\nhttps://docs.oracle.com/en/java/javase/20/security/java-security-overview1.html#GUID-BBEC2DC8-BA00-42B1-B52A-A49488FCF8FE\nAccessController.doPrivileged - 山河已无恙 - 博客园\n","date":"2023-11-08T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/lang/java_security/","title":"Java安全机制之一——SecurityManager和AccessController"},{"content":" 在定位公司问题的时候，需要了解一下skywalking的相关知识，而agent就提上了日程。\n官网文档\nAgent技术是Jdk在1.5版本之后，所提供的一个在jvm启动前后对部分java类代理加强的机制。由于是直接修改字节码，并不会对业务代码有注入，所以可以很好的应用于监控或者热部署等场景。\n正常所提到的Agent一般都是部署成jar包的样子，比如agent-1.0-SNAPSHOT.jar。\n在这个jar包中，要添加一个MANIFEST.MF文件，在文件中指定jar包的代理类，比如下面代码中的Premain-Class。\n在对应的代理类，要实现一个permain方法或者agentmain方法，这样jvm可以通过MANIFEST找到类，通过类再找到对应的方法，从而进行加强，所以加强逻辑是在permain方法或者agentmain方法内部实现的。\nManifest-Version: 1.0 Built-By: qisi Premain-Class: com.qisi.agent.InterviewAgent Agent-Class: com.qisi.agent.InterviewAgent Can-Redefine-Classes: true Can-Retransform-Classes: true Class-Path: byte-buddy-1.10.22.jar Created-By: Apache Maven 3.8.1 Build-Jdk: 1.8.0_332 public class InterviewAgent { public static void premain(String agentArgs, Instrumentation instrumentation) { } public static void agentmain(String agentArgs, Instrumentation instrumentation) { } } 而如果在permain或者agentmain方法打上debug可以发现，执行时是通过sun.instrument.InstrumentationImpl#loadClassAndCallPremain和sun.instrument.InstrumentationImpl#loadClassAndCallAgentmain两个方法通过反射来执行到我们指定的类的。\nAgent技术有两种场景，一种是在jvm启动之前，通过-javaagent:path来指定jar包，像是skywalking就是采用的这种方式；另一种则是在jvm启动之后，通过attach指定的进程，对jvm中的类进行加强，arthas就是采用的这种方式。\n在具体介绍这两种方式之前，需要先讲一下Instrumentation相关类和接口\njava.lang.Instrumentation Instrumentation Instrumentation相关的类都在java.lang.Instrumentation包下，两个异常，两个接口，一个类。 两个异常在这里不做介绍，功能就像类名一样。核心的其实是Instrumentation接口，本文仅关注红框内的几个方法。这几个方法都是通过permain和agentmain获取到的instrumentation实例进行的操作。\n从时间发展来看，其中jdk1.5开始支持的是下面几个方法，也就是说在jdk5的时候，仅支持添加和移除类转换器，且添加的类转换器只能在加载和重定义的时候使用。就是说如果类没有加载，那么通过addTransformer方法注册的ClassFileTransformer就可以对这个类进行增强，否则一旦类已经加载完毕，则只能通过redefineClasses，完全替换类定义再次触发loadClass来增强\naddTransformer(ClassFileTransformer transformer) removeTransformer(ClassFileTransformer transformer) isRedefineClassesSupported();//依赖于MANIFEST中的Can-Redefine-Classes值 redefineClasses(ClassDefinition... definitions) 而从jdk1.6开始，增加了一个retransformClasses的概念。retransform和redefine的区别，前者是在原有类的基础上进行修改，后者则是完全重定义，不使用原有类做任何参考。 需要注意的事，只有在首次调用addTransformer时，将canRetransform设置为true的类，才可以被重新转换。\naddTransformer(ClassFileTransformer transformer, boolean canRetransform); isRetransformClassesSupported(); retransformClasses(Class\u0026lt;?\u0026gt;... classes)//依赖于MANIFEST中的Can-Retransform-Classes值 isModifiableClass(Class\u0026lt;?\u0026gt; theClass); ClassFileTransformer、ClassDefinition 这两个类其实都是Instrumentation接口方法的入参，其中用的比较多的应该是ClassFileTransformer。这个类只有一个transform，jvm类加载的时候都会调用一遍这个方法。如果需要加强，那么就利用给定的参数，进行字节码的改动，将改动后的字节码作为返回值返回；如果无需增强，则直接返回null即可。\nbyte[] transform( ClassLoader loader, String className, Class\u0026lt;?\u0026gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) ClassDefinition也类似，不过是在对象里重新绑定class和byte的关系\npublic final class ClassDefinition { /** * The class to redefine */ private final Class\u0026lt;?\u0026gt; mClass; /** * The replacement class file bytes */ private final byte[] mClassFile; 实践 MANIFEST.MF配置 在pom文件中添加下面的代码，根据需要修改参数值\n\u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-jar-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;archive\u0026gt; \u0026lt;addMavenDescriptor\u0026gt;false\u0026lt;/addMavenDescriptor\u0026gt; \u0026lt;manifest\u0026gt; \u0026lt;addClasspath\u0026gt;true\u0026lt;/addClasspath\u0026gt; \u0026lt;/manifest\u0026gt; \u0026lt;manifestEntries\u0026gt; \u0026lt;Premain-Class\u0026gt; com.qisi.agent.InterviewByteButtyAgent \u0026lt;/Premain-Class\u0026gt; \u0026lt;Agent-Class\u0026gt; com.qisi.agent.InterviewByteButtyAgent \u0026lt;/Agent-Class\u0026gt; \u0026lt;Can-Redefine-Classes\u0026gt; true \u0026lt;/Can-Redefine-Classes\u0026gt; \u0026lt;Can-Retransform-Classes\u0026gt; true \u0026lt;/Can-Retransform-Classes\u0026gt; \u0026lt;Built-By\u0026gt; qisi \u0026lt;/Built-By\u0026gt; \u0026lt;/manifestEntries\u0026gt; \u0026lt;/archive\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; -javaagent: 在这种方式下，起作用的是permain，也就是说-javaagent和permain方法是配套使用的。 核心就是添加一个自定义的ClassFileTransformer，可以另起一个类，也可以这样匿名类。 如果只是熟悉流程可以像下面一样，直接打印一些日志，不去修改类；\npublic static void premain(String agentArgs, Instrumentation instrumentation) { System.out.println(\u0026#34;enhance by premain,params:\u0026#34;+agentArgs); instrumentation.addTransformer(new ClassFileTransformer() { @Override public byte[] transform(ClassLoader loader, String className, Class\u0026lt;?\u0026gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException { System.out.println(\u0026#34;premain load Class :\u0026#34; + className); return classfileBuffer; } }, true); } 如果要真实修改，需要引入asm javassist bytebuddy等修改字节码的框架。下面这部分就是使用了bytebuddy，作用是让任何类的testAgent方法，都返回固定值transformed\npublic static void premain(String agentArgs, Instrumentation instrumentation) throws ClassNotFoundException { System.out.println(\u0026#34;enhance by permain InterviewByteButtyAgent,params:\u0026#34;+agentArgs); new AgentBuilder.Default().type(any()).transform(new AgentBuilder.Transformer() { @Override public DynamicType.Builder\u0026lt;?\u0026gt; transform(DynamicType.Builder\u0026lt;?\u0026gt; builder, TypeDescription typeDescription, ClassLoader classLoader, JavaModule module) { return builder.method(named(\u0026#34;testAgent\u0026#34;)) .intercept(FixedValue.value(\u0026#34;transformed\u0026#34;)); } }).installOn(instrumentation); } 编写完之后，就可以在任意项目添加一个存在testAgent方法的进行尝试了，比如 java -javaagent:/xxxx/path/agent-1.0-SNAPSHOT.jar=key1:value1,key2:value2 -jar AppDemo.jar\nattach agentmain 这种方式需要实现agentmain方法，和permian不太一样的地方是需要在addTransformer之后触发需要retransformClasses想要加强的类。\npublic static void agentmain(String agentArgs, Instrumentation instrumentation) { System.out.println(\u0026#34;enhance by agentmain,params:\u0026#34;+agentArgs); instrumentation.addTransformer(new ClassFileTransformer() { @Override public byte[] transform(ClassLoader loader, String className, Class\u0026lt;?\u0026gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException { System.out.println(\u0026#34;agentmain load Class :\u0026#34; + className); return classfileBuffer; } }, true); try { instrumentation.retransformClasses(Class.forName(\u0026#34;com.qisi.mybatis.app.controller.FirstRequestController\u0026#34;)); } catch (UnmodifiableClassException e) { e.printStackTrace(); } catch (ClassNotFoundException e) { e.printStackTrace(); } } 同样，提供一个bytebuddy的例子，下面这个则是指定修改FirstRequestController的testAgent方法的返回值为transformed\npublic static void agentmain(String agentArgs, Instrumentation instrumentation) throws ClassNotFoundException { System.out.println(\u0026#34;enhance by agentmain InterviewByteButtyAgent,params:\u0026#34;+agentArgs); //这里RedefinitionStrategy必须注意，默认的DISABLED是不支持retransform new AgentBuilder.Default().with(AgentBuilder.RedefinitionStrategy.RETRANSFORMATION).type(new AgentBuilder.RawMatcher() { @Override public boolean matches(TypeDescription typeDescription, ClassLoader classLoader, JavaModule module, Class\u0026lt;?\u0026gt; classBeingRedefined, ProtectionDomain protectionDomain) { return typeDescription.getName().contains(\u0026#34;FirstRequestController\u0026#34;); } }).transform(new AgentBuilder.Transformer() { @Override public DynamicType.Builder\u0026lt;?\u0026gt; transform(DynamicType.Builder\u0026lt;?\u0026gt; builder, TypeDescription typeDescription, ClassLoader classLoader, JavaModule module) { System.out.println(\u0026#34;enhance\u0026#34;+typeDescription.getName()); return builder.method(named(\u0026#34;testAgent\u0026#34;)) .intercept(FixedValue.value(\u0026#34;transformed\u0026#34;)); } //这里采用disableClassFormatChanges的方案，好像还可以使用advice }).disableClassFormatChanges().installOn(instrumentation); try { instrumentation.retransformClasses(Class.forName(\u0026#34;com.qisi.mybatis.app.controller.FirstRequestController\u0026#34;)); } catch (UnmodifiableClassException e) { e.printStackTrace(); } catch (ClassNotFoundException e) { e.printStackTrace(); } } VirtualMachine 不同于-javaagent命令，这里需要使用自jdk6开始提供的VirtualMachine类，在tool.jar包里 下面的方法是我参考arthas写的一个attach的流程，选择我们想要attach的进程，然后加载我们上面写好的jar包就好了。\npublic class AgentTest { public static void main(String[] args) throws IOException, AttachNotSupportedException { String pid = null; try { Process jps = Runtime.getRuntime().exec(\u0026#34;jps\u0026#34;); InputStream inputStream = jps.getInputStream(); BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream)); String line; while ((line = bufferedReader.readLine()) != null) { System.out.println(line); } System.out.println(\u0026#34;选择要attach的进程\u0026#34;); pid= new Scanner(System.in).nextLine(); System.out.println(\u0026#34;选择的pid是\u0026#34;+pid); } catch (IOException e) { e.printStackTrace(); } for (VirtualMachineDescriptor virtualMachineDescriptor : VirtualMachine.list()) { if (virtualMachineDescriptor.id().equals(pid)){ VirtualMachine attach = VirtualMachine.attach(virtualMachineDescriptor); try { attach.loadAgent(\u0026#34;/xxxxx/agent/target/agent-1.0-SNAPSHOT.jar\u0026#34;,\u0026#34;参数1，参数2\u0026#34;); } catch (AgentLoadException e) { e.printStackTrace(); } catch (AgentInitializationException e) { e.printStackTrace(); } finally { attach.detach(); } break; } } } } 参考文档： 探秘 Java 热部署二（Java agent premain）\nJAVA热更新1:Agent方式热更 | 花隐间-JAVA游戏技术解决方案\nByteBuddy入门教程\n","date":"2023-09-10T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/lang/javaagent/","title":"JavaAgent技术"},{"content":"在阅读本篇文章之前，建议先了解agent的启动流程，这对分析controller加强原理有很大的帮助，Skywalking Agent启动流程源码分析\n项目启动时我指定skywalking官方jar包\n-javaagent:/xxxx/skywalking/skywalking-agent/skywalking-agent.jar\nInstMethodsInter 在agent启动原理那篇文章，我们知道Skywalking对于类的加强主要就是对静态方法、构造方法、实例方法各自的加强。虽然我们并没有深入研究AgentBuilder的每个方法，但通过附件的反编译可以了解到，对于要加强的类，\n其本质是new出一个新的类，继承EnhancedInstance，然后创建了一堆的代理对象，以hello方法为例，我们实际调用的是InstMethodsInter类的一个实例对象的intercept方法；\nintercept定义了三个钩子方法，分别是beforeMethod、handleMethodException和afterMethod。所以我们使用的插件一般来说也都是去实现定义的这三个方法。\nprivate InstanceMethodsAroundInterceptor interceptor; public Object intercept(@This Object obj, @AllArguments Object[] allArguments, @SuperCall Callable\u0026lt;?\u0026gt; zuper, @Origin Method method) throws Throwable { EnhancedInstance targetObject = (EnhancedInstance) obj; MethodInterceptResult result = new MethodInterceptResult(); try { interceptor.beforeMethod(targetObject, method, allArguments, method.getParameterTypes(), result); } catch (Throwable t) { LOGGER.error(t, \u0026#34;class[{}] before method[{}] intercept failure\u0026#34;, obj.getClass(), method.getName()); } Object ret = null; try { //这里在beforeMethod中设定了isContinue为true的话，就直接返回result._ret()，等于是代理 if (!result.isContinue()) { ret = result._ret(); } else { ret = zuper.call(); } } catch (Throwable t) { try { interceptor.handleMethodException(targetObject, method, allArguments, method.getParameterTypes(), t); } catch (Throwable t2) { LOGGER.error(t2, \u0026#34;class[{}] handle method[{}] exception failure\u0026#34;, obj.getClass(), method.getName()); } throw t; } finally { try { ret = interceptor.afterMethod(targetObject, method, allArguments, method.getParameterTypes(), ret); } catch (Throwable t) { LOGGER.error(t, \u0026#34;class[{}] after method[{}] intercept failure\u0026#34;, obj.getClass(), method.getName()); } } return ret; } InstanceMethodsAroundInterceptor 在InstanceMethodsAroundInterceptor的before和after方法上都打上断点，请求hello接口，其核心链路如下图所示。\nTomcatInvokerInterceptor是在插件tomcat-7.x-8.x-plugin-8.15.0.jar中TomcatInstrumentation类的getMethodsInterceptor指定，对org.apache.catalina.core.StandardHostValve#invoke进行加强\nGetBeanInterceptor是在插件apm-springmvc-annotation-5.x-plugin-8.15.0.jar中的HandlerMethodInstrumentation类getMethodsInterceptor指定，对org.springframework.web.method.HandlerMethod#getBean方法进行加强\nRestMappingMethodInterceptor是在插件apm-springmvc-annotation-5.x-plugin-8.15.0.jar中的ControllerInstrumentation和RestControllerInstrumentation类所继承的AbstractControllerInstrumentation的getMethodsInterceptor指定（这里如果是@RequestMapping注解会走到RequestMappingMethodInterceptor，如果是@GetMapping、@PostMapping等rest的注解，则是会走到RestMappingMethodInterceptor，但其实这两个Interceptor都是继承的AbstractMethodInterceptor）\nGetBeanInterceptor、RestMappingMethodInterceptor都定义在插件apm-springmvc-annotation-commons-8.15.0.jar中\nInterceptor源码分析 TomcatInvokerIntercetor TomcatInvokerIntercetor相对比较独立，像是在容器层面的监听和统计，和mvc流程不掺和；逻辑也比较简单，就是将请求的url、method、head和响应状态封装到span里，上报到oap，这里就不贴源码分析了；\nGetBeanInterceptor GetBeanInterceptor的作用就是将request和response放到了thredlocal里面，方便RestMappingMethodInterceptor获取和处理\n//GetBeanInterceptor public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class\u0026lt;?\u0026gt;[] argumentsTypes, Object ret) throws Throwable { if (ret instanceof EnhancedInstance) { ServletRequestAttributes requestAttributes = (ServletRequestAttributes)RequestContextHolder.getRequestAttributes(); if (requestAttributes != null) { ContextManager.getRuntimeContext().put(\u0026#34;SW_REQUEST\u0026#34;, requestAttributes.getRequest()); ContextManager.getRuntimeContext().put(\u0026#34;SW_RESPONSE\u0026#34;, requestAttributes.getResponse()); } } return ret; } RestMappingMethodInterceptor 在分析这段代码之前，建议先看以下官方文档对于span的介绍，简单总结就是\nSpan 表示分布式系统中完成工作的单个单元，即一个组件的一次操作，可以被包含。\nSkywalking 将span做了类型区分\nEntrySpan 用来在服务间交互的时候记录数据\nLocalSpan 用来在本地方法记录数据\nExitSpan 则表示endpoint的数据\npublic void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class\u0026lt;?\u0026gt;[] argumentsTypes, MethodInterceptResult result) throws Throwable { //SW_FORWARD_REQUEST_FLAG这个我没找到在哪里塞入 Boolean forwardRequestFlag = (Boolean)ContextManager.getRuntimeContext().get(\u0026#34;SW_FORWARD_REQUEST_FLAG\u0026#34;); if (forwardRequestFlag == null || !forwardRequestFlag) { //依托于getBean方法的afterMethod塞到threadlocal的request Object request = ContextManager.getRuntimeContext().get(\u0026#34;SW_REQUEST\u0026#34;); if (request != null) { //字面意思，用来记录调用方法的深度 StackDepth stackDepth = (StackDepth)ContextManager.getRuntimeContext().get(\u0026#34;SW_CONTROLLER_METHOD_STACK_DEPTH\u0026#34;); //这里是指进入controller之前，已经记录了一层，但我想象不到是哪种场景 if (stackDepth != null) { AbstractSpan span = ContextManager.createLocalSpan(this.buildOperationName(objInst, method)); span.setComponent(ComponentsDefine.SPRING_MVC_ANNOTATION); } else { ContextCarrier contextCarrier = new ContextCarrier(); CarrierItem next; String operationName; AbstractSpan span; //区分request是HttpServletRequest、还是jakarta包的HttpServletRequest、或者是ServerHttpRequest if (IN_SERVLET_CONTAINER \u0026amp;\u0026amp; IS_JAVAX \u0026amp;\u0026amp; HttpServletRequest.class.isAssignableFrom(request.getClass())) { HttpServletRequest httpServletRequest = (HttpServletRequest)request; next = contextCarrier.items(); //从请求的header找有没有contextCarrier对象属性的值 while(next.hasNext()) { next = next.next(); next.setHeadValue(httpServletRequest.getHeader(next.getHeadKey())); } //将请求url和方法提取并组合 operationName = this.buildOperationName(method, httpServletRequest.getMethod(), (EnhanceRequireObjectCache)objInst.getSkyWalkingDynamicField()); //创建EntrySpan，这里记录了开始时间，下面是记录URL、方法（Get、POST）、组件类型 span = ContextManager.createEntrySpan(operationName, contextCarrier); Tags.URL.set(span, httpServletRequest.getRequestURL().toString()); HTTP.METHOD.set(span, httpServletRequest.getMethod()); span.setComponent(ComponentsDefine.SPRING_MVC_ANNOTATION); SpanLayer.asHttp(span); //默认是false，如果为true，则要记录入参请求 if (SpringMVC.COLLECT_HTTP_PARAMS) { RequestUtil.collectHttpParam(httpServletRequest, span); } //指定要记录的header if (!CollectionUtil.isEmpty(Http.INCLUDE_HTTP_HEADERS)) { RequestUtil.collectHttpHeaders(httpServletRequest, span); } } else if (IN_SERVLET_CONTAINER \u0026amp;\u0026amp; IS_JAKARTA \u0026amp;\u0026amp; jakarta.servlet.http.HttpServletRequest.class.isAssignableFrom(request.getClass())) { jakarta.servlet.http.HttpServletRequest httpServletRequest = (jakarta.servlet.http.HttpServletRequest)request; //和上面一样 } else { if (!ServerHttpRequest.class.isAssignableFrom(request.getClass())) { throw new IllegalStateException(\u0026#34;this line should not be reached\u0026#34;); } ServerHttpRequest serverHttpRequest = (ServerHttpRequest)request; //和上面一样 } //初始化一个StackDepth，值为1 stackDepth = new StackDepth(); ContextManager.getRuntimeContext().put(\u0026#34;SW_CONTROLLER_METHOD_STACK_DEPTH\u0026#34;, stackDepth); } //每过一个before+1，每过一个after-1 stackDepth.increment(); } } } public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class\u0026lt;?\u0026gt;[] argumentsTypes, Object ret) throws Throwable { RuntimeContext runtimeContext = ContextManager.getRuntimeContext(); Boolean forwardRequestFlag = (Boolean)runtimeContext.get(\u0026#34;SW_FORWARD_REQUEST_FLAG\u0026#34;); if (forwardRequestFlag != null \u0026amp;\u0026amp; forwardRequestFlag) { return ret; } else { Object request = runtimeContext.get(\u0026#34;SW_REQUEST\u0026#34;); if (request != null) { try { //获取层深并减一 StackDepth stackDepth = (StackDepth)runtimeContext.get(\u0026#34;SW_CONTROLLER_METHOD_STACK_DEPTH\u0026#34;); if (stackDepth == null) { throw new IllegalMethodStackDepthException(); } stackDepth.decrement(); AbstractSpan span = ContextManager.activeSpan(); if (stackDepth.depth() == 0) { Object response = runtimeContext.get(\u0026#34;SW_RESPONSE\u0026#34;); if (response == null) { throw new ServletResponseNotFoundException(); } Integer statusCode = null; //记录请求response的code if (IS_SERVLET_GET_STATUS_METHOD_EXIST \u0026amp;\u0026amp; HttpServletResponse.class.isAssignableFrom(response.getClass())) { statusCode = ((HttpServletResponse)response).getStatus(); } else if (IS_JAKARTA_SERVLET_GET_STATUS_METHOD_EXIST \u0026amp;\u0026amp; jakarta.servlet.http.HttpServletResponse.class.isAssignableFrom(response.getClass())) { statusCode = ((jakarta.servlet.http.HttpServletResponse)response).getStatus(); } else if (ServerHttpResponse.class.isAssignableFrom(response.getClass())) { if (IS_SERVLET_GET_STATUS_METHOD_EXIST || IS_JAKARTA_SERVLET_GET_STATUS_METHOD_EXIST) { statusCode = ((ServerHttpResponse)response).getRawStatusCode(); } Object context = runtimeContext.get(\u0026#34;SW_REACTIVE_RESPONSE_ASYNC_SPAN\u0026#34;); if (context != null) { //响应是异步得专门看一下 ((AbstractSpan[])context)[0] = span.prepareForAsync(); } } if (statusCode != null) { Tags.HTTP_RESPONSE_STATUS_CODE.set(span, statusCode); if (statusCode \u0026gt;= 400) { span.errorOccurred(); } } runtimeContext.remove(\u0026#34;SW_REACTIVE_RESPONSE_ASYNC_SPAN\u0026#34;); runtimeContext.remove(\u0026#34;SW_REQUEST\u0026#34;); runtimeContext.remove(\u0026#34;SW_RESPONSE\u0026#34;); runtimeContext.remove(\u0026#34;SW_CONTROLLER_METHOD_STACK_DEPTH\u0026#34;); } //假如COLLECT_HTTP_PARAMS默认是false，那这里就会由ProfileStatus决定，而ProfileStatus由org.apache.skywalking.apm.agent.core.profile.ThreadProfiler#startProfilingIfNeed决定 if (!SpringMVC.COLLECT_HTTP_PARAMS \u0026amp;\u0026amp; span.isProfiling()) { if (IS_JAVAX \u0026amp;\u0026amp; HttpServletRequest.class.isAssignableFrom(request.getClass())) { RequestUtil.collectHttpParam((HttpServletRequest)request, span); } else if (IS_JAKARTA \u0026amp;\u0026amp; jakarta.servlet.http.HttpServletRequest.class.isAssignableFrom(request.getClass())) { RequestUtil.collectHttpParam((jakarta.servlet.http.HttpServletRequest)request, span); } else if (ServerHttpRequest.class.isAssignableFrom(request.getClass())) { RequestUtil.collectHttpParam((ServerHttpRequest)request, span); } } } finally { //在这里进行的上报 ContextManager.stopSpan(); } } return ret; } } 上报 到这里为止，可以发现其实就跟拦截器的思路是一样的，在执行前后做了一些记录操作。那么记录完之后，是如何上报到oap的呢?原理就在ContextManager.stopSpan()中\n收集（生产） public boolean stopSpan(AbstractSpan span) { AbstractSpan lastSpan = this.peek(); if (lastSpan == span) { if (lastSpan instanceof AbstractTracingSpan) { AbstractTracingSpan toFinishSpan = (AbstractTracingSpan)lastSpan; //这个finish是AbstractTracingSpan的finish， if (toFinishSpan.finish(this.segment)) { this.pop(); } } else { this.pop(); } //这个finish是TraceContent的finish this.finish(); return this.activeSpanStack.isEmpty(); } else { throw new IllegalStateException(\u0026#34;Stopping the unexpected span = \u0026#34; + span); } } org.apache.skywalking.apm.agent.core.context.ContextManager#stopSpan()-\u0026gt;\norg.apache.skywalking.apm.agent.core.context.trace.AbstractTracingSpan#finish，\n从 stopSpan跟进去，会先走到AbstractTracingSpan#finish这个方法，在这里将本次请求的span放到了TraceSegment.spans集合中，等待被收集和消费\npublic boolean finish(TraceSegment owner) { this.endTime = System.currentTimeMillis(); owner.archive(this); return true; } public void archive(AbstractTracingSpan finishedSpan) { this.spans.add(finishedSpan); } 然后会走到TraceContent的finish，org.apache.skywalking.apm.agent.core.context.TracingContext.ListenerManager#notifyFinish-\u0026gt;\u0026hellip;-\u0026gt;\n#org.apache.skywalking.apm.commons.datacarrier.DataCarrier#produce\nprivate void finish() { ... //下面是调用了两次notifyFinish，但是通知的内容不一样，这里我们主要关注第二个，因为通知的是TraceSegment boolean isFinishedInMainThread = this.activeSpanStack.isEmpty() \u0026amp;\u0026amp; this.running; if (isFinishedInMainThread) { TracingContext.TracingThreadListenerManager.notifyFinish(this); } if (isFinishedInMainThread \u0026amp;\u0026amp; (!this.isRunningInAsyncMode || this.asyncSpanCounter == 0)) { TraceSegment finishedSegment = this.segment.finish(this.isLimitMechanismWorking()); TracingContext.ListenerManager.notifyFinish(finishedSegment); this.running = false; } ... } //一层层跟下去 static void notifyFinish(TraceSegment finishedSegment) { Iterator var1 = LISTENERS.iterator(); while(var1.hasNext()) { TracingContextListener listener = (TracingContextListener)var1.next(); listener.afterFinished(finishedSegment); } } public void afterFinished(TraceSegment traceSegment) { if (!traceSegment.isIgnore()) { if (!this.carrier.produce(traceSegment) \u0026amp;\u0026amp; LOGGER.isDebugEnable()) { LOGGER.debug(\u0026#34;One trace segment has been abandoned, cause by buffer is full.\u0026#34;); } } } #org.apache.skywalking.apm.commons.datacarrier.DataCarrier#produce public boolean produce(T data) { return this.driver != null \u0026amp;\u0026amp; !this.driver.isRunning(this.channels) ? false : this.channels.save(data); } public void save(data){ while(条件){ this.bufferChannels[index].save(data) } ） 直到这里为止，我们可以发现数据被存到了DataCarrier.channels中，而且从执行的方法是produce可以猜到，对应的consume方法就是消费逻辑。\n消费 还是在DataCarrier中，通过下面的代码可以发现，实际一个ConsumeDriver有多个线程，每个线程对应一个channel，是以属性dataSource绑定到ConsumerThread上\npublic DataCarrier consume(Class\u0026lt;? extends IConsumer\u0026lt;T\u0026gt;\u0026gt; consumerClass, int num, long consumeCycle, Properties properties) { if (this.driver != null) { this.driver.close(this.channels); } //将channels放入ConsumeDriver this.driver = new ConsumeDriver(this.name, this.channels, consumerClass, num, consumeCycle, properties); this.driver.begin(this.channels); return this; } public void begin(Channels channels) { ... //将chennel和ConsumerThread做绑定 this.allocateBuffer2Thread(); ConsumerThread[] var2 = this.consumerThreads; int var3 = var2.length; for(int var4 = 0; var4 \u0026lt; var3; ++var4) { ConsumerThread consumerThread = var2[var4]; consumerThread.start(); } } private void allocateBuffer2Thread() { int channelSize = this.channels.getChannelSize(); for(int channelIndex = 0; channelIndex \u0026lt; channelSize; ++channelIndex) { int consumerIndex = channelIndex % this.consumerThreads.length; //将channel放到ConsumerThread的dataSource中，因为后面每个线程的主要工作就是从datasource获取要要发送的数据，然后发送 this.consumerThreads[consumerIndex].addDataSource(this.channels.getBuffer(channelIndex)); } } 所以ConsumerThread持有datasource，然后datasource又有了数据,线程在死循环获取datasource中数据就可以了\n#org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerThread#consume private boolean consume(List\u0026lt;T\u0026gt; consumeList) { Iterator var2 = this.dataSources.iterator(); while(var2.hasNext()) { ConsumerThread\u0026lt;T\u0026gt;.DataSource dataSource = (ConsumerThread.DataSource)var2.next(); //将datasource数据放入consumeList dataSource.obtain(consumeList); } ... this.consumer.consume(consumeList); ... } #org.apache.skywalking.apm.agent.core.remote.TraceSegmentServiceClient#consume public void consume(List\u0026lt;TraceSegment\u0026gt; data) { if (GRPCChannelStatus.CONNECTED.equals(this.status)) { final GRPCStreamServiceStatus status = new GRPCStreamServiceStatus(false); StreamObserver upstreamSegmentStreamObserver = ((TraceSegmentReportServiceStub)this.serviceStub.withDeadlineAfter((long)Collector.GRPC_UPSTREAM_TIMEOUT, TimeUnit.SECONDS)).collect(new StreamObserver\u0026lt;Commands\u0026gt;() { //这里的onNext是response的onNext，不是request，可以看一下collect的逻辑，所以下面直接调onNext并不是调到这个方法 public void onNext(Commands commands) { ((CommandService)ServiceManager.INSTANCE.findService(CommandService.class)).receiveCommand(commands); } ... }); ... while(var4.hasNext()) { TraceSegment segment = (TraceSegment)var4.next(); //构建传输对象 SegmentObject upstreamSegment = segment.transform(); //进行传输 upstreamSegmentStreamObserver.onNext(upstreamSegment); } ... } //走发送逻辑，由于GRPC我还没有研究过，所以暂不分析往下的源码 public void onNext(ReqT value) { Preconditions.checkState(!this.aborted, \u0026#34;Stream was terminated by error, no further calls are allowed\u0026#34;); Preconditions.checkState(!this.completed, \u0026#34;Stream is already completed, no further calls are allowed\u0026#34;); this.call.sendMessage(value); } 代码 Controller方法 @RestController @RequestMapping(\u0026#34;/first\u0026#34;) public class FirstRequestController { @GetMapping(\u0026#34;/hello\u0026#34;) public String hello() { System.out.println(\u0026#34;hello,mybatis\u0026#34;); System.out.println(testAgent()); System.out.println(noAgent());; return \u0026#34;mybatis\u0026#34;; } private String testAgent(){ return \u0026#34;testAgent\u0026#34;; } public String noAgent(){ return \u0026#34;noAgent\u0026#34;; } } 反编译FirstRequestController @RestController @RequestMapping(value={\u0026#34;/first\u0026#34;}) public class FirstRequestController implements EnhancedInstance { private volatile Object _$EnhancedClassField_ws; public static volatile /* synthetic */ InstMethodsInter delegate$fmp8mm0; public static volatile /* synthetic */ InstMethodsInter delegate$usgtuf1; public static volatile /* synthetic */ ConstructorInter delegate$ve3rcd0; public static volatile /* synthetic */ InstMethodsInter delegate$9q0b6r1; public static volatile /* synthetic */ InstMethodsInter delegate$mft2580; public static volatile /* synthetic */ ConstructorInter delegate$gcp4qa1; public static volatile /* synthetic */ InstMethodsInter delegate$4vl1o10; public static volatile /* synthetic */ InstMethodsInter delegate$vcjgr61; public static volatile /* synthetic */ ConstructorInter delegate$di6p0h0; public static volatile /* synthetic */ InstMethodsInter delegate$jfo0r51; public static volatile /* synthetic */ InstMethodsInter delegate$dg0j500; public static volatile /* synthetic */ ConstructorInter delegate$5c04f20; private static final /* synthetic */ Method cachedValue$aWq206nq$b4bilp1; public static volatile /* synthetic */ InstMethodsInter delegate$306a1i0; public static volatile /* synthetic */ InstMethodsInter delegate$3h5imi1; public static volatile /* synthetic */ ConstructorInter delegate$25tu2j0; public static volatile /* synthetic */ InstMethodsInter delegate$su4hhm0; public static volatile /* synthetic */ InstMethodsInter delegate$e5jt5f1; public static volatile /* synthetic */ ConstructorInter delegate$kc72041; public static volatile /* synthetic */ InstMethodsInter delegate$pf9hmj0; public static volatile /* synthetic */ InstMethodsInter delegate$kik32a0; public static volatile /* synthetic */ ConstructorInter delegate$os3qlu1; public static volatile /* synthetic */ InstMethodsInter delegate$0e263f0; public static volatile /* synthetic */ InstMethodsInter delegate$a5ji980; public static volatile /* synthetic */ ConstructorInter delegate$jc027h1; private static final /* synthetic */ Method cachedValue$niIMIXK0$b4bilp1; public FirstRequestController() { this(null); delegate$25tu2j0.intercept(this, new Object[0]); } private /* synthetic */ FirstRequestController(auxiliary.MVLCe3Gn mVLCe3Gn) { } @GetMapping(value={\u0026#34;/hello\u0026#34;}) public String hello() { return (String)delegate$306a1i0.intercept(this, new Object[0], (Callable\u0026lt;?\u0026gt;)new auxiliary.4sHLGVLS(this), cachedValue$niIMIXK0$b4bilp1); } private /* synthetic */ String hello$original$UjAdUjOr() { /*17*/ System.out.println(\u0026#34;hello,mybatis\u0026#34;); /*18*/ System.out.println(this.testAgent()); /*19*/ System.out.println(this.noAgent()); /*20*/ return \u0026#34;mybatis\u0026#34;; } private String testAgent() { /*23*/ return \u0026#34;testAgent\u0026#34;; } public String noAgent() { /*26*/ return \u0026#34;noAgent\u0026#34;; } static { ClassLoader.getSystemClassLoader().loadClass(\u0026#34;org.apache.skywalking.apm.dependencies.net.bytebuddy.dynamic.Nexus\u0026#34;).getMethod(\u0026#34;initialize\u0026#34;, Class.class, Integer.TYPE).invoke(null, FirstRequestController.class, 1021095365); cachedValue$niIMIXK0$b4bilp1 = FirstRequestController.class.getMethod(\u0026#34;hello\u0026#34;, new Class[0]); } final /* synthetic */ String hello$original$UjAdUjOr$accessor$niIMIXK0() { return this.hello$original$UjAdUjOr(); } } 反编译HandlerMethod public class HandlerMethod implements EnhancedInstance { private static final /* synthetic */ Method cachedValue$1RDdupwP$41avq00; public Object getBean() { return delegate$shr7st0.intercept(this, new Object[0], (Callable\u0026lt;?\u0026gt;) new auxiliary.ENGom7ym(this), cachedValue$1RDdupwP$41avq00); } /* * Enabled aggressive block sorting */ static { ClassLoader.getSystemClassLoader().loadClass(\u0026#34;org.apache.skywalking.apm.dependencies.net.bytebuddy.dynamic.Nexus\u0026#34;).getMethod(\u0026#34;initialize\u0026#34;, Class.class, Integer.TYPE).invoke(null, HandlerMethod.class, -1058650667); cachedValue$1RDdupwP$41avq00 = HandlerMethod.class.getMethod(\u0026#34;getBean\u0026#34;, new Class[0]); /* 66*/ logger = LogFactory.getLog(HandlerMethod.class); } } ","date":"2023-09-02T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/distributed/skywalking/skywalkingcontroller/","title":"分析Skywalking的controller加强原理"},{"content":"Skywalking 从架构上分为三个大模块，分别是Agent、Oap（Backend\u0026amp;Storage）、UI。这篇文档主要是介绍Agent部分。这部分核心依赖的是java的agent技术，对这个技术陌生的可以先看一下Agent 这篇文章。Skywalking在agent的基础上利用ByteBuddy类库对类和方法等进行加强，实现无入侵的监测。\nSkyWalkingAgent类 在官方的skywalking-agent包中，通过MANIFEST.MF的Premain-Class值，我们可以确定入口类是org.apache.skywalking.apm.agent.SkyWalkingAgent，而核心的方法就是里面的premain方法，大概的内容是以下四部分。\n读取并整合配置\n加载插件\n通过AgentBuilder注入到jvm\n启动上报相关的服务等\n读取并整合配置 //将各个途径的配置都处理汇总到CONFIG类里，CONFIG类里面全是静态字段，所以直接赋值也不需要实例化对象 SnifferConfigInitializer.initializeCoreConfig(agentArgs); public static void initializeCoreConfig(String agentOptions) { AGENT_SETTINGS = new Properties(); //loadConfig方法中会优先从指定的系统属性skywalking_config中取值（即 java -Dskywalking_config=xxx/custom.config) //如果没有设置，则默认加载SKYWALKING_AGENT_PATH/config/agent.config try (final InputStreamReader configFileStream = loadConfig()) { AGENT_SETTINGS.load(configFileStream); for (String key : AGENT_SETTINGS.stringPropertyNames()) { String value = (String) AGENT_SETTINGS.get(key); //替换占位符的变量，依次从System.getProperty(key)-\u0026gt;System.getenv(key)-\u0026gt;properties.getProperty(key)-\u0026gt;default取 AGENT_SETTINGS.put(key, PropertyPlaceholderHelper.INSTANCE.replacePlaceholders(value, AGENT_SETTINGS)); } } catch (Exception e) { LOGGER.error(e, \u0026#34;Failed to read the config file, skywalking is going to run in default config.\u0026#34;); } try { //替换通过java -Dskywalking.指定的变量值 //这里我觉得很奇怪，明明上面也是处理系统属性，这里为什么还要专门用skywalking前缀区分呢？ overrideConfigBySystemProp(); } catch (Exception e) { LOGGER.error(e, \u0026#34;Failed to read the system properties.\u0026#34;); } agentOptions = StringUtil.trim(agentOptions, \u0026#39;,\u0026#39;); if (!StringUtil.isEmpty(agentOptions)) { try { agentOptions = agentOptions.trim(); LOGGER.info(\u0026#34;Agent options is {}.\u0026#34;, agentOptions); //替换在 java -agent:/***.jar=key:value里的值 overrideConfigByAgentOptions(agentOptions); } catch (Exception e) { LOGGER.error(e, \u0026#34;Failed to parse the agent options, val is {}.\u0026#34;, agentOptions); } } //通过反射将AGENT_SETTINGS注入到Config的变量中 initializeConfig(Config.class); ... } 加载插件 //这一步实际上是加载了插件jar包里的增加类def里面描述的类，最终都传到了PluginFinder，存储为三种不同的对象 pluginFinder = new PluginFinder(new PluginBootstrap().loadPlugins()); public List\u0026lt;AbstractClassEnhancePluginDefine\u0026gt; loadPlugins() throws AgentPackageNotFoundException { //可以通过启动一次看日志，了解这里是先装载jar包再识别出def //注意，这里自定义了一个类加载器,并且加载了activations和plugins/plugins下的jar包 //Q\u0026amp;A 2023/8/27 // Q:为什么要自定义类加载器 // A:为了加载插件的那些jar包，继承自AppClassLodder AgentClassLoader.initDefaultLoader(); PluginResourcesResolver resolver = new PluginResourcesResolver(); //获取所有的skywalking-plugin.def，由于上面的jar包已经添加，所以实际就是那些jar包里的skywalking-plugin.def List\u0026lt;URL\u0026gt; resources = resolver.getResources(); if (resources == null || resources.size() == 0) { LOGGER.info(\u0026#34;no plugin files (skywalking-plugin.def) found, continue to start application.\u0026#34;); return new ArrayList\u0026lt;AbstractClassEnhancePluginDefine\u0026gt;(); } for (URL pluginUrl : resources) { try { //最终都加载到了List\u0026lt;PluginDefine\u0026gt; pluginClassList里 PluginCfg.INSTANCE.load(pluginUrl.openStream()); } catch (Throwable t) { LOGGER.error(t, \u0026#34;plugin file [{}] init failure.\u0026#34;, pluginUrl); } } List\u0026lt;PluginDefine\u0026gt; pluginClassList = PluginCfg.INSTANCE.getPluginClassList(); List\u0026lt;AbstractClassEnhancePluginDefine\u0026gt; plugins = new ArrayList\u0026lt;AbstractClassEnhancePluginDefine\u0026gt;(); for (PluginDefine pluginDefine : pluginClassList) { try { LOGGER.debug(\u0026#34;loading plugin class {}.\u0026#34;, pluginDefine.getDefineClass()); //Q\u0026amp;A 2023/8/22 // Q:为什么这里所有的类都能强转为AbstractClassEnhancePluginDefine // A:因为插件继承的顶层最终都是这个抽象类,见下面类图 AbstractClassEnhancePluginDefine plugin = (AbstractClassEnhancePluginDefine) Class.forName(pluginDefine.getDefineClass(), true, AgentClassLoader .getDefault()).newInstance(); plugins.add(plugin); } catch (Throwable t) { LOGGER.error(t, \u0026#34;load plugin [{}] failure.\u0026#34;, pluginDefine.getDefineClass()); } } //这个是通过SPI用所有的InstrumentationLoader来添加AbstractClassEnhancePluginDefine，不知道用在哪 plugins.addAll(DynamicPluginLoader.INSTANCE.load(AgentClassLoader.getDefault())); return plugins; } //这里面将插件分到了三个不同的集合中 public PluginFinder(List\u0026lt;AbstractClassEnhancePluginDefine\u0026gt; plugins) { for (AbstractClassEnhancePluginDefine plugin : plugins) { ClassMatch match = plugin.enhanceClass(); if (match == null) { continue; } //重写enhanceClass，以restTemplate为例，enhanceClass是NameMatch.byName(\u0026#34;org.springframework.web.client.RestTemplate\u0026#34;)，所以对应map的key就是\u0026#34;org.springframework.web.client.RestTemplate\u0026#34; if (match instanceof NameMatch) { NameMatch nameMatch = (NameMatch) match; LinkedList\u0026lt;AbstractClassEnhancePluginDefine\u0026gt; pluginDefines = nameMatchDefine.get(nameMatch.getClassName()); if (pluginDefines == null) { pluginDefines = new LinkedList\u0026lt;AbstractClassEnhancePluginDefine\u0026gt;(); nameMatchDefine.put(nameMatch.getClassName(), pluginDefines); } pluginDefines.add(plugin); } else { signatureMatchDefine.add(plugin); } if (plugin.isBootstrapInstrumentation()) { bootstrapClassMatchDefine.add(plugin); } } } AgentBuilder 这中间有一部分是JDK9的模块相关的内容，由于我还没有深入了解过JDK9相关的内容，加上\n//这一步实际上是加载了插件jar包里的增加类def里面描述的类，最终都传到了PluginFinder，存储为三种不同的对象 pluginFinder = new PluginFinder(new PluginBootstrap().loadPlugins()); public List\u0026lt;AbstractClassEnhancePluginDefine\u0026gt; loadPlugins() throws AgentPackageNotFoundException { //可以通过启动一次看日志，了解这里是先装载jar包再识别出def //注意，这里自定义了一个类加载器,并且加载了activations和plugins/plugins下的jar包 //Q\u0026amp;A 2023/8/27 // Q:为什么要自定义类加载器 // A:为了加载插件的那些jar包，继承自AppClassLodder AgentClassLoader.initDefaultLoader(); PluginResourcesResolver resolver = new PluginResourcesResolver(); //获取所有的skywalking-plugin.def，由于上面的jar包已经添加，所以实际就是那些jar包里的skywalking-plugin.def List\u0026lt;URL\u0026gt; resources = resolver.getResources(); if (resources == null || resources.size() == 0) { LOGGER.info(\u0026#34;no plugin files (skywalking-plugin.def) found, continue to start application.\u0026#34;); return new ArrayList\u0026lt;AbstractClassEnhancePluginDefine\u0026gt;(); } for (URL pluginUrl : resources) { try { //最终都加载到了List\u0026lt;PluginDefine\u0026gt; pluginClassList里 PluginCfg.INSTANCE.load(pluginUrl.openStream()); } catch (Throwable t) { LOGGER.error(t, \u0026#34;plugin file [{}] init failure.\u0026#34;, pluginUrl); } } List\u0026lt;PluginDefine\u0026gt; pluginClassList = PluginCfg.INSTANCE.getPluginClassList(); List\u0026lt;AbstractClassEnhancePluginDefine\u0026gt; plugins = new ArrayList\u0026lt;AbstractClassEnhancePluginDefine\u0026gt;(); for (PluginDefine pluginDefine : pluginClassList) { try { LOGGER.debug(\u0026#34;loading plugin class {}.\u0026#34;, pluginDefine.getDefineClass()); //Q\u0026amp;A 2023/8/22 // Q:为什么这里所有的类都能强转为AbstractClassEnhancePluginDefine // A:因为插件继承的顶层最终都是这个抽象类,见下面类图 AbstractClassEnhancePluginDefine plugin = (AbstractClassEnhancePluginDefine) Class.forName(pluginDefine.getDefineClass(), true, AgentClassLoader .getDefault()).newInstance(); plugins.add(plugin); } catch (Throwable t) { LOGGER.error(t, \u0026#34;load plugin [{}] failure.\u0026#34;, pluginDefine.getDefineClass()); } } //这个是通过SPI用所有的InstrumentationLoader来添加AbstractClassEnhancePluginDefine，不知道用在哪 plugins.addAll(DynamicPluginLoader.INSTANCE.load(AgentClassLoader.getDefault())); return plugins; } //这里面将插件分到了三个不同的集合中 public PluginFinder(List\u0026lt;AbstractClassEnhancePluginDefine\u0026gt; plugins) { for (AbstractClassEnhancePluginDefine plugin : plugins) { ClassMatch match = plugin.enhanceClass(); if (match == null) { continue; } //重写enhanceClass，以restTemplate为例，enhanceClass是NameMatch.byName(\u0026#34;org.springframework.web.client.RestTemplate\u0026#34;)，所以对应map的key就是\u0026#34;org.springframework.web.client.RestTemplate\u0026#34; if (match instanceof NameMatch) { NameMatch nameMatch = (NameMatch) match; LinkedList\u0026lt;AbstractClassEnhancePluginDefine\u0026gt; pluginDefines = nameMatchDefine.get(nameMatch.getClassName()); if (pluginDefines == null) { pluginDefines = new LinkedList\u0026lt;AbstractClassEnhancePluginDefine\u0026gt;(); nameMatchDefine.put(nameMatch.getClassName(), pluginDefines); } pluginDefines.add(plugin); } else { signatureMatchDefine.add(plugin); } if (plugin.isBootstrapInstrumentation()) { bootstrapClassMatchDefine.add(plugin); } } } 这里开始就要用到ByteBuddy了，先简单了解下AgentBuilder ，然后我们结合插件分析源码中的核心部分\n比较关键的其实就是type、transform和installOn三个方法，其他的ignore、with感兴趣的可以自己研究，不影响主流程的理解\ntype() type是命中要处理的类，对应的是插件里的enhanceClass，如果enhanceClass实现是指定的类名称，那么在之前已经加入到nameMatchDefine里了，如果不是则各自解析，比如Spring的插件就是通过注解来匹配\nprotected ClassMatch enhanceClass() { return ClassAnnotationMatch.byClassAnnotationMatch(this.getEnhanceAnnotations()); } protected String[] getEnhanceAnnotations() { return new String[]{\u0026#34;org.springframework.web.bind.annotation.RestController\u0026#34;}; } /** * 主要是通过插件里定义的NameMatch和IndirectMatch来匹配，IndirectMatch就是要更复杂，比如匹配的更多，前缀，后缀之类的，参考IndirectMatch的实现类 * @return */ public ElementMatcher\u0026lt;? super TypeDescription\u0026gt; buildMatch() { ElementMatcher.Junction judge = new AbstractJunction\u0026lt;NamedElement\u0026gt;() { @Override public boolean matches(NamedElement target) { return nameMatchDefine.containsKey(target.getActualName()); } }; judge = judge.and(not(isInterface())); for (AbstractClassEnhancePluginDefine define : signatureMatchDefine) { ClassMatch match = define.enhanceClass(); if (match instanceof IndirectMatch) { judge = judge.or(((IndirectMatch) match).buildJunction()); } } return new ProtectiveShieldMatcher(judge); transform() public DynamicType.Builder\u0026lt;?\u0026gt; define(TypeDescription typeDescription, DynamicType.Builder\u0026lt;?\u0026gt; builder, ... WitnessFinder finder = WitnessFinder.INSTANCE; //witness机制，希望加强某类之前，必须有些类已经加载，用于区分版本，让插件和应用的版本所对应 /** * find witness classes for enhance class */ String[] witnessClasses = witnessClasses(); if (witnessClasses != null) { for (String witnessClass : witnessClasses) { if (!finder.exist(witnessClass, classLoader)) { LOGGER.warn(\u0026#34;enhance class {} by plugin {} is not activated. Witness class {} does not exist.\u0026#34;, transformClassName, interceptorDefineClassName, witnessClass); return null; } } } List\u0026lt;WitnessMethod\u0026gt; witnessMethods = witnessMethods(); if (!CollectionUtil.isEmpty(witnessMethods)) { for (WitnessMethod witnessMethod : witnessMethods) { if (!finder.exist(witnessMethod, classLoader)) { LOGGER.warn(\u0026#34;enhance class {} by plugin {} is not activated. Witness method {} does not exist.\u0026#34;, transformClassName, interceptorDefineClassName, witnessMethod); return null; } } } /** * find origin class source code for interceptor */ DynamicType.Builder\u0026lt;?\u0026gt; newClassBuilder = this.enhance(typeDescription, builder, classLoader, context); ... } transform是增强命中的类，这里核心方法是org.apache.skywalking.apm.agent.SkyWalkingAgent.Transformer#transform-\u0026gt;\norg.apache.skywalking.apm.agent.core.plugin.AbstractClassEnhancePluginDefine#define\nWitness机制 这里需要提及一个机制，即Witness机制，他的作用是让引入的插件必须和当前应用组件的版本必须相对应。举例来说，spring-mvc有三个版本的插件，如下面代码所示，不同的版本校验的类并不相同。(但是我去查了spring3456每个版本的类，好像并不太能对应到spring的版本，所以我也不知道skywalking官方的这个mvc插件对应的哪个版本)\npublic abstract class AbstractSpring3Instrumentation extends ClassInstanceMethodsEnhancePluginDefine { public static final String WITHNESS_CLASSES = \u0026#34;org.springframework.web.servlet.view.xslt.AbstractXsltView\u0026#34;; public AbstractSpring3Instrumentation() { } protected final String[] witnessClasses() { return new String[]{\u0026#34;org.springframework.web.servlet.view.xslt.AbstractXsltView\u0026#34;}; } } public abstract class AbstractSpring4Instrumentation extends ClassInstanceMethodsEnhancePluginDefine { public static final String WITHNESS_CLASSES = \u0026#34;org.springframework.cache.interceptor.SimpleKey\u0026#34;; public AbstractSpring4Instrumentation() { } protected String[] witnessClasses() { return new String[]{\u0026#34;org.springframework.cache.interceptor.SimpleKey\u0026#34;, \u0026#34;org.springframework.cache.interceptor.DefaultKeyGenerator\u0026#34;}; } } public abstract class AbstractSpring5Instrumentation extends ClassInstanceMethodsEnhancePluginDefine { public static final String WITNESS_CLASSES = \u0026#34;org.springframework.beans.annotation.AnnotationBeanUtils\u0026#34;; public AbstractSpring5Instrumentation() { } protected final String[] witnessClasses() { return new String[]{\u0026#34;org.springframework.beans.annotation.AnnotationBeanUtils\u0026#34;}; } } 拦截器 enhance方法里面包含了两个部分，enhanceClass主要是加强类的静态方法，enhanceInstance则是加强类的构造方法和普通方法.\n这样给插件留出更细粒度的扩展，只需要插件实现InstanceMethodsInterceptPoint等接口就可以了\nprotected DynamicType.Builder\u0026lt;?\u0026gt; enhance(TypeDescription typeDescription, DynamicType.Builder\u0026lt;?\u0026gt; newClassBuilder, ClassLoader classLoader, EnhanceContext context) throws PluginException { //这里是实际和插件作用的地方 newClassBuilder = this.enhanceClass(typeDescription, newClassBuilder, classLoader); newClassBuilder = this.enhanceInstance(typeDescription, newClassBuilder, classLoader, context); return newClassBuilder; } protected DynamicType.Builder\u0026lt;?\u0026gt; enhanceInstance(TypeDescription typeDescription, DynamicType.Builder\u0026lt;?\u0026gt; newClassBuilder, ClassLoader classLoader, EnhanceContext context) throws PluginException { ... /** * Manipulate class source code.\u0026lt;br/\u0026gt; * * new class need:\u0026lt;br/\u0026gt; * 1.Add field, name {@link #CONTEXT_ATTR_NAME}. * 2.Add a field accessor for this field. * * And make sure the source codes manipulation only occurs once. * */ //生成一个新的类，该类继承EnhancedInstance接口，并且自定义了一个字段叫做_$EnhancedClassField_ws，同时生成了这个的set、get方法 //Q\u0026amp;A 2023/8/29 // Q: 为什么非要指定这样一个字段呢？ // A: 说是为了解决上下文问题，需要这样一个字段缓存，但是我不理解 https://github.com/apache/skywalking/issues/7146 if (!typeDescription.isAssignableTo(EnhancedInstance.class)) { if (!context.isObjectExtended()) { newClassBuilder = newClassBuilder.defineField( CONTEXT_ATTR_NAME, Object.class, ACC_PRIVATE | ACC_VOLATILE) .implement(EnhancedInstance.class) .intercept(FieldAccessor.ofField(CONTEXT_ATTR_NAME)); context.extendObjectCompleted(); } } //下面的增强构造和实例方法其实很类似 //核心点在于InstanceMethodsInterceptPoint， //通过getMethodsMatcher获取需要加强的方法 //通过getMethodsInterceptor获取需要插件定义的拦截器，然后将其构造到agentBuilder里 /** * 2. enhance constructors */ ... /** * 3. enhance instance methods */ ... newClassBuilder = newClassBuilder.method(junction) .intercept(MethodDelegation.withDefaultConfiguration() .to(new InstMethodsInter(interceptor, classLoader))); } return newClassBuilder; } 这里不对agentBuidle的intercept等具体分析，感兴趣的可以自己看\ninstallOn() 正常定义permain方法时，定义的transformer都是通过addTransformer添加到instrumentation的\npublic static void premain(String agentArgs, Instrumentation instrumentation) { System.out.println(\u0026#34;enhance by agent,params:\u0026#34;+agentArgs); instrumentation.addTransformer(new ClassFileTransformer() { @Override public byte[] transform(ClassLoader loader, String className, Class\u0026lt;?\u0026gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException { System.out.println(\u0026#34;premain load Class :\u0026#34; + className); return classfileBuffer; } }, true); } 而这里，我们用的是agentBuilder,在transform()部分我们已经知道定义了transformer,其transform方法是遍历插件定义然后加强类，因此我们可以猜测最终肯定也是将transformer添加到instrumentation，最简单的映证方法就是在sun.instrument.InstrumentationImpl#addTransformer(java.lang.instrument.ClassFileTransformer, boolean)打个断点，启动项目\ninstallon()-\u0026gt;org.apache.skywalking.apm.dependencies.net.bytebuddy.agent.builder.AgentBuilder.Default#doInstall()\nprivate ResettableClassFileTransformer doInstall(Instrumentation instrumentation, AgentBuilder.RawMatcher matcher, AgentBuilder.PatchMode.Handler handler) { if (!this.circularityLock.acquire()) { throw new IllegalStateException(\u0026#34;Could not acquire the circularity lock upon installation.\u0026#34;); } else { ResettableClassFileTransformer var13; try { AgentBuilder.RedefinitionStrategy.ResubmissionStrategy.Installation installation = this.redefinitionResubmissionStrategy.apply(instrumentation, this.poolStrategy, this.locationStrategy, this.descriptionStrategy, this.fallbackStrategy, this.listener, this.installationListener, this.circularityLock, new AgentBuilder.Default.Transformation.SimpleMatcher(this.ignoreMatcher, this.transformations), this.redefinitionStrategy, this.redefinitionBatchAllocator, this.redefinitionListener); ResettableClassFileTransformer classFileTransformer = this.transformerDecorator.decorate(this.makeRaw(installation.getListener(), installation.getInstallationListener(), installation.getResubmissionEnforcer())); installation.getInstallationListener().onBeforeInstall(instrumentation, classFileTransformer); try { this.warmupStrategy.apply(classFileTransformer, this.locationStrategy, this.redefinitionStrategy, this.circularityLock, installation.getInstallationListener()); handler.onBeforeRegistration(instrumentation); if (this.redefinitionStrategy.isRetransforming()) { DISPATCHER.addTransformer(instrumentation, classFileTransformer, true); } else { instrumentation.addTransformer(classFileTransformer); } 启动上报相关的服务\n暂未研究\n参考文档: Skywalking8.9.1源码解析\u0026lt;六\u0026gt;-Skywalking-agent版本识别机制\n","date":"2023-08-29T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/distributed/skywalking/skywalkingagent/","title":"SkywalkingAgent启动流程源码分析"},{"content":"紧急排查： 一个普通工作日的晚上8点，突然收到大量接口超时的报警，最高甚至有超100s，于是开始紧急排查。\n首先是看监控面板里的内存监控和cpu监控，说到这里不得不吐槽一句公司的内存监控没什么软用（当时并不会熟练使用arthas)，监控的是pod节点内存情况，也就是说一直展示的都是历史最高的，因为jvm申请内存后是不会返还给实例的，所以并不能看出来什么。倒是cpu确实彪的很高。\n直觉判断，肯定是内存上去了，频繁gc，导致的cpu飙高，那么是哪里的问题呢？\n下载内存dump文件，5个G，公司那小水管，每秒2兆，下载的贼慢，很绝望。\n而且观察发现，只有蓝组的一台机器是这样子的，其他的机器都没有问题，所以为了不影响用户使用，先把蓝组流量全部关了，慢慢查。\n通过命令jmap -histo 73066 | head -n 30查看，以前分析dump的时候，排名前几的都是char、Int等基本类型的对象居多，根本看不出什么问题，而这个虽然也是char 和int排名靠前，但是排在第5名的是一个普通的po类，去查这个类调用的地方，最终定位到是一个定时任务出现了问题，这也解释了为什么只影响了蓝组的一台实例，其他的没有受影响，加上这个任务并不是太重要，就手动先停了，今天先看看什么问题，第二天进行上线修补。\n定时任务的核心代码是为了维护一个列表，下面是个demo\n//这段代码逻辑大概是从某个接口查询一个列表，然后和数据库的进行比较 //最新列表比数据库多的要新增落库，少的要删掉，已经在的要更新 List\u0026lt;String\u0026gt; list = client.getEnableList(); List\u0026lt;Memory\u0026gt; memories = memoryMapper.selectList(new QueryWrapper\u0026lt;\u0026gt;()); ArrayList\u0026lt;Memory\u0026gt; addList = new ArrayList\u0026lt;\u0026gt;(); ArrayList\u0026lt;Memory\u0026gt; updateList = new ArrayList\u0026lt;\u0026gt;(); for (Memory memory : memories) { if (!list.contains(memory.getName())){ addList.add(memory); }else{ updateList.add(memory); } } for (Memory memory : updateList) { memoryMapper.insert(memory); } 观察上面这段逻辑，发现!list.contains的时候应该删除才对，而不是添加，应该是接口返回结果有，数据库没有才要添加，那仅仅如此为什么会导致异常呢？当时查了一下这个表的数据，有780万条数据，按照业务idgroupby了一下发现某个id就有780万重复数据，其他的数据都是1条。破案了，就是这条数据重复插入导致的，插入了780万次。\n但是仔细看现在的代码，是表里有，但是接口没有，才会进行插入。\n那表里这条数据为什么有呢？第一次是什么时候插入的呢？看了一下插入时间是几天前，也就是说几天前接口还返回了这条数据，但是今天突然不返回了，导致了这个问题\n而没有立即暴露出来的原因是，假设第一次查出来是1条数据，然后新增了一条；下一次查出来就是2条，然后会新增两条；数量低的时候内存不会有压力，加上定时任务是半小时执行一次，所以是每半小时翻一番，在翻到第23番的时候终于出现问题了；2-\u0026gt;4-\u0026gt;8-\u0026gt;16-\u0026gt;\u0026hellip;..-\u0026gt;2^23(8388608)，\n所以总结一下出问题的原因：\n诱因是今天返回的数据比之前少了一条，少的这条因为代码逻辑问题会重复插入（没有加唯一索引）\n复现： 还是这段代码，为了加快速度和方便测试，我们做了一下调整\n//mock接口返回数据就只有一个“first” List\u0026lt;String\u0026gt; first = Arrays.asList(\u0026#34;first\u0026#34;); List\u0026lt;Memory\u0026gt; memories = memoryMapper.selectList(new QueryWrapper\u0026lt;\u0026gt;()); System.out.println(\u0026#34;数据库List占用内存\u0026#34;+ObjectSizeCalculator.getObjectSize(memories)/1024/1024+\u0026#34;M\u0026#34;); ArrayList\u0026lt;Memory\u0026gt; addList = new ArrayList\u0026lt;\u0026gt;(); ArrayList\u0026lt;Memory\u0026gt; updateList = new ArrayList\u0026lt;\u0026gt;(); for (Memory memory : memories) { if (!first.contains(memory.getName())){ addList.add(memory); }else{ updateList.add(memory); } } //这里不再单个插入，而是批量插入，5万一次 Lists.partition(addList,50000).forEach(t-\u0026gt;{ System.out.println(\u0026#34;大List占用内存\u0026#34;+ObjectSizeCalculator.getObjectSize(addList)/1024/1024+\u0026#34;M\u0026#34;); memoryMapper.insertBatchSomeColumn(t); }); 数据库初始就两条数据，根据上面的代码，second这条会以2的幂级插入\n而且为了尽快达到上限，jvm参数得调整一下，最大堆200m，年轻代40m\n-Xms200m -Xmx200m -Xmn40m -XX:+PrintGCDetails -XX:+PrintGCDateStamps 好了，接下来使用jconsole监控这个进程，然后一次次的触发这段程序，进行观察 这是启动时，没有触发的状态\n在2^15次时，对象终于达到1M，然后是3M,6M,13M,27M,54M\n最终报了OOM，而这个时候数据库是1048577条数据，20次的时候是54M，而且由于两个list（memories和addList)，所以代码实际使用100M，在下一次执行就得申请200M了，总共就200M，于是OOM，我们简单估算一下线上当时会申请多少M？21-\u0026gt;100M,22-\u0026gt;200M,23-\u0026gt;400M，所以在第23次的时候就得申请两个400M，也就是800M了。\n2023-08-19 20:22:23.521 ERROR 57861 --- [nio-8080-exec-5] o.a.c.c.C.[.[.[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Handler dispatch failed; nested exception is java.lang.OutOfMemoryError: GC overhead limit exceeded] with root cause java.lang.OutOfMemoryError: GC overhead limit exceeded 参考文档： 面试官：一个线程OOM，进程里其他线程还能运行么？\n面试官问：平时碰到系统CPU飙高和频繁GC，你会怎么排查？\njava面试oom问题及答案_java面试中必问的oom问题_卜奕的博客-CSDN博客\n","date":"2023-08-19T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/problem/task_fullgc/","title":"记一次内存飙升、gc频繁、cpu飙高"},{"content":"小组群内leader甩出来一个截图，说是线程有些异常，一直在增长，从pool-1-thread一直到pool-285-thread，每个pool都只有三个线程：thread-1 thread-2 thread-3，第一反应感觉肯定和定时任务有关，这种稳定的有规律的一般都是和定时任务有关。\n定位线程是哪部分的代码\n如果线程池自定义名字了，直接在项目里搜就可以\n直接查询最新的线程的日志，比如这里就是查询pool-285-thread对应的日志，如果有日志的话，很大概率就能直接定位到是哪里的问题，很不幸，我们出问题的这部分当时没有打印日志\n通过jstack分析\n分析代码\ntask(){ ExecutorService executorService = Executors.newFixedThreadPool(6); executorService.execute(()-\u0026gt;{统计1}) executorService.execute(()-\u0026gt;{统计2}) executorService.execute(()-\u0026gt;{统计3}) } 线上出问题的代码大概是上面的逻辑，根据现象我们知道，一共开启了285个线程池，线程池每次有三个线程在工作。\n为什么会开启这么多线程池？\n由于Executors.newFixedThreadPool(6)是放在类里面，且没有手动shutdown，导致每次定时任务执行这个方法的时候都会开启一个线程池\n为什么线程池里的线程没有回收？\nnewFixedThreadPool最大线程和核心线程数量是一样的，即这里创建了6个核心线程，而核心线程的回收又得手动指定allowCoreThreadTimeOut为true才可以，所以并不会被回收\npublic static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;()); } 复现验证 public class Case { void fixPoolInc() { ExecutorService executorService = Executors.newFixedThreadPool(6); for (int i = 0; i \u0026lt; 3; i++) { executorService.execute(() -\u0026gt; { System.out.println(\u0026#34;ThreadName:\u0026#34; + Thread.currentThread().getName()); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } }); } } @SneakyThrows public static void main(String[] args) { Case aCase = new Case(); for (int i = 0; i \u0026lt; 10; i++) { Thread.sleep(5000); aCase.fixPoolInc(); } } } 开10个线程池，每个线程池启动3个线程，通过jconsole观察是否线程持续增长，并没有回收\n结论\n方法内部开启的线程池记得手动关闭，或者将方法内部的线程池提到外部\n最好还是通过ThreadPoolExecutor手动设置每个参数，这样对于业务更清晰，而不是偷懒使用ExecutorService\n线程池最好还是指定明细，这边方便排查异常\n参考文档： Java线程Dump分析_线程dump怎么分析_萨达哈鲁君的博客-CSDN博客\nidea + jconsole实现线程监控_idea查看线程运行情况_黑夜伴白行的博客-CSDN博客\n深入浅出线:程池的线程回收\u0026ndash;回收的是非核心线程吗?_非核心线程的是怎么回收的_小猪快跑22的博客-CSDN博客\n","date":"2023-08-18T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/problem/thread_exception/","title":"线程异常增长"},{"content":"普通的应用启动 新建一个Remote_JVM_Debug配置\n填入自己的服务器的ip和任意一个没有被占用的端口号（非当前应用启动用的端口号），然后重点是下面这段代码\n-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8100 在服务器启动对应应用，上面提到的代码必须在 java -jar xxx.jar 的-jar前面，而我的启动命令是下面这样，绿色为新插入的\nnohup java -Xms128m -Xmx128m -Xmn40m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./logs/jvm -Xloggc:./logs/jvm/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8100 -jar callback-1.0-SNAPSHOT.jar --spring.profiles.active=prod \u0026amp; 在确认服务器启动之后，在本地点debug启动按钮，如果打印了下面这个语句，就证明连接成功\n之后在你需要排查的地方打上断点，然后触发接口就可以了，就会发现就进入了熟悉的debug的模式里\ndocker启动 IDEA的配置不变，整体的区别就是docker在打包时要暴露出来调试的接口，启动命令-p 映射端口也要有两个\ndockerfile如下\nFROM openjdk:8 LABEL maintainer=\u0026#34;qisiii@example.com\u0026#34; WORKDIR /app #这里的路径不能使用父级的,即../ COPY callback-1.0-SNAPSHOT.jar /app/app.jar #这里是服务应用的端口 EXPOSE 8101 #这里是debug端口 EXPOSE 8100 ENV JAVA_OPTS=\u0026#39;\u0026#39; ENV JAVA_OPTS2=\u0026#39;--spring.profiles.active=prod\u0026#39; ENTRYPOINT [\u0026#34;sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;java ${JAVA_OPTS} -jar app.jar ${JAVA_OPTS2}\u0026#34;] docker run -e \u0026#34;JAVA_OPTS=-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8100\u0026#34; -d -p 8101:8101 -p 8100:8100 --name open-platform open-platform:1.0.0 k8s启动 idea本身的配置和通过docker启动一样，只需要修改k8s里相关的配置就可以了\n镜像依然使用docker那个镜像，我是在deployment对应的yml文件中添加的里面的环境变量\napiVersion: apps/v1 #kubectl api-versions 可以通过这条指令去看版本信息kind: Deployment # 指定资源类别metadata: #资源的一些元数据 name: open-platform #deloyment的名称 labels: app: open-platform #标签spec: replicas: 1 #创建pod的个数 selector: matchLabels: app: open-platform #满足标签为这个的时候相关的pod才能被调度到 template: metadata: labels: app: open-platform spec: imagePullSecrets: - name: aliyun containers: - name: open-platform image: registry.cn-hangzhou.aliyuncs.com/qisiii/open-platform:1.0.1 imagePullPolicy: IfNotPresent ports: - containerPort: 8101 env: - name: JAVA_OPTS value: \u0026#34;-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8100\u0026#34; 然后我在service里面暴露了端口号\n{ \u0026#34;kind\u0026#34;: \u0026#34;Service\u0026#34;, \u0026#34;apiVersion\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;open-platform-service\u0026#34; }, \u0026#34;spec\u0026#34;: { \u0026#34;type\u0026#34;:\u0026#34;NodePort\u0026#34;, \u0026#34;selector\u0026#34;: { \u0026#34;app\u0026#34;: \u0026#34;open-platform\u0026#34; }, \u0026#34;ports\u0026#34;: [ { \u0026#34;protocol\u0026#34;: \u0026#34;TCP\u0026#34;, \u0026#34;port\u0026#34;: 80, \u0026#34;targetPort\u0026#34;: 8101, \u0026#34;name\u0026#34;: \u0026#34;open-platform\u0026#34; }, { \u0026#34;protocol\u0026#34;: \u0026#34;TCP\u0026#34;, \u0026#34;port\u0026#34;: 8100, \u0026#34;targetPort\u0026#34;: 8100, \u0026#34;name\u0026#34;: \u0026#34;debug\u0026#34; } ] } } 并且在最后通过post-forward转发时同时转发了两个端口号\nkubectl port-forward --address 0.0.0.0 service/open-platform-service 8101:80 8100:8100 这个时候本地idea启动debug，打上断点，远程触发访问\n参考文档： https://zhuanlan.zhihu.com/p/128033093\nhttps://www.cnblogs.com/gaoyuechen/p/11811180.html\n","date":"2023-07-10T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/tool/remote_debug/","title":"IDEA进程远程Debug"},{"content":"MVCC机制遗留的问题 为什么在可重复读级别下，幻读没有产生？\n回想一下在事务隔离级别那篇文章中，可串行化是通过什么保证的？\n对操作的每一行记录加读锁、写锁和范围锁；任何其他事务都必须等待持有锁的事务释放锁之后才能进行操作；\n而可重复读级别相比之下唯一少的就是范围锁，所以无论你是否了解过具体原因，都应该去猜测推理，大概率是加了范围锁。而在这里，他有一个特殊的名字，叫做间隙锁。\n虽然我很想直接上间隙锁相关的内容，但是为了更加有体系化，最好还是完整梳理一下；\n本篇文章最好是有一点基础再看，因为本身就是自记录，没有打算写一篇完整的教学博客。\n读锁和写锁（共享锁和排它锁） Shared Lock 共享锁（S锁），也叫读锁；不和读锁冲突，但和写锁冲突；\n当事务A持有读锁的时候，事务B依然可以加读锁；但是除了事务A自己可以加写锁，其他事务都无法对这条记录加写锁。\nExclusive Lock 排他锁（X锁），也叫写锁；和谁都冲突；\n即当事务A持有记录的写锁时，其他事务读锁和写锁都加不了\nS X S 兼容 冲突 X 冲突 冲突 行和列代表不同事务\n表锁 表锁 上锁和解锁 lock tables 表名 [as alisa] 锁类型; unlock tables ; 表锁的命令就是上述两行，且表锁也分读写锁，表级读写的兼容冲突和读写锁一致。\n通过lock tables 命令加锁的session，在释放锁之前，能且只能执行lock tables 命令后面指定的表，命令类型和锁类型保持一致；比如 lock tables A read,那么后面就只能读A表，而不能执行读B表，或者写A表；如下面的例子一样；另外如果使用了别名，那么需要确保查询语句涉及的别名和lock table的别名完全一致；\nlock tables simple read; select * from simple; select * from batch_insert; //[HY000][1100] Table \u0026#39;batch_insert\u0026#39; was not locked with LOCK TABLES update simple set name=3 where id=2; Table \u0026#39;simple\u0026#39; was locked with a READ lock and can\u0026#39;t be updated Unlock tables 会显式的释放所有该session之前加的所有表；另一个作用是释放FLUSH TABLES WITH READ LOCK命令所加的全局读锁；\nAnother use for UNLOCK TABLES is to release the global read lock acquired with the FLUSH TABLES WITH READ LOCK statement, which enables you to lock all tables in all databases. See Section 13.7.8.3, “FLUSH Statement”.\nlock tables、start transcation命令可以隐式的释放之前持有的锁；\n查看锁情况 可通过下面的命令查看表是否上锁，name_locked为0表示上锁\nshow OPEN TABLES where In_use \u0026gt; 0; WRITE locks normally have higher priority than READ locks to ensure that updates are processed as soon as possible. This means that if one session obtains a READ lock and then another session requests a WRITE lock, subsequent READ lock requests wait until the session that requested the WRITE lock has obtained the lock and released it.\n对于读-写-读的情况，由于锁的优先级较高，如果申请写的session迟迟获取不到锁，会阻塞后续其他session申请读锁；具体分析看Case1；\n全局读锁 关于全局锁，我一共只在两篇文档中看到过；一个是《Mysql45讲》的06篇，一个mysql官方文档的lock-table文章和FLUSH Statement文章，所以了解的并不全，加上此时的我还不太关心数据库主从的问题，所以也没有深入研究。\nFLUSH TABLES WITH READ LOCK\nCloses all open tables and locks all tables for all databases with a global read lock.\n元数据锁 Statements acquire metadata locks one by one, not simultaneously, and perform deadlock detection in the process.\nDML statements normally acquire locks in the order in which tables are mentioned in the statement.\nDDL statements, LOCK TABLES, and other similar statements try to reduce the number of possible deadlocks between concurrent DDL statements by acquiring locks on explicitly named tables in name order.\n元数据锁是一个个获取的，DML和DDL通过不同的方式定义执行的顺序；官网提供了一个rename table的顺序例子，但那个例子挺迷的；\n//可以通过这个表查看元数据锁的情况 select * from performance_schema.metadata_locks; To ensure transaction serializability, the server must not permit one session to perform a data definition language (DDL) statement on a table that is used in an uncompleted explicitly or implicitly started transaction in another session. The server achieves this by acquiring metadata locks on tables used within a transaction and deferring release of those locks until the transaction ends. A metadata lock on a table prevents changes to the table\u0026rsquo;s structure. This locking approach has the implication that a table that is being used by a transaction within one session cannot be used in DDL statements by other sessions until the transaction ends.\n如果一个session或者一个事务持有某个表的元数据锁，那么另一个session或者事务就无法执行DDL操作；\nhttps://dev.mysql.com/doc/refman/8.0/en/metadata-locking.html\n读写阻塞问题 关于元数据锁，在《Mysql45讲》中有提到一个问题，后加的读锁会被前面的写锁所阻塞，很类似于表锁最后提到的优先级问题，有没有可能是一个原因呢？具体见case2\n行锁（Record Lock) A record lock is a lock on an index record.\n行锁是在索引上的一个锁。这句话非常重要！\n这里的索引可以是聚簇索引也可以是二级索引，如果表中没有索引或者查询的条件没有索引，又或者优化器认为索引没有作用，这个时候就会退化为“表锁”，但我总感觉像是锁定了所有行。\n另外，如果表中没有定义聚簇索引，会自动生成一个隐藏的索引。\n间隙锁（Gap Lock） A gap lock is a lock on a gap between index records, or a lock on the gap before the first or after the last index record.\n单靠行锁是无法解决幻读的问题的，所以innodb引入了间隙锁的概念，只在RR级别生效。间隙锁是一个范围锁，比如所以索引1和索引3之间就存在（1，3）这样一个间隙，当这个间隙被锁定的时候，就无法插入值为2的记录。\n不同的事务对于同一个间隙加锁是允许发生的，因为都是在保护这个间隙不被插入数据。\nGap locking is not needed for statements that lock rows using a unique index to search for a unique row.\n当查询条件是唯一索引，如果查询的值存在且是唯一的一行记录，那么是不需要加间隙锁的；因为间隙锁的出现就是为了防止幻读，对于加了唯一索引的表，同样的查询条件永远只能查出唯一的一条，既然已经保证了唯一，那么就没有间隙锁的必要了。\n那如果查询结果不存在？以及查询条件是范围查询？又或者是普通索引甚至没有索引呢？\n关于这些情况的排列组合，见case3\n临键锁(next-key Lock) A next-key lock is a combination of a record lock on the index record and a gap lock on the gap before the index record.\n临建锁=行锁+间隙锁，是innodb RR级别默认加的锁；由于锁定的是当前索引记录行和索引前的部分，所以一般总结为左开右闭；\n假如存在索引10,11,13,20，那么就会存在以下几个区间，最后一个范围是mysql会假定一个非常大的supremum，但由于实际并不存在这个值，所以是左开右开。\n(negative infinity, 10] (10, 11] (11, 13] (13, 20] (20, positive infinity) 意向锁 表意向锁 innodb支持多粒度锁，即允许行锁和表锁同时存在，并且在加锁的时候需要进行冲突检测；\n比如事务A已经持有了a表的一条记录索引的行锁，这个时候B事务想要给a表加表锁，就需要一行行查看是否存在行锁；为了优化这种情况，innodb引入了意向锁的概念。\n表意向锁是个表级锁，分为读意向锁（IS）和写意向锁（IX），它们添加的时机是在对行索引添加S锁和X锁之前；即如果想要对某一行加锁，就必须先取得这个表的意向锁。这样当另一个事务需要判断时，就不需要一行行进行检查，只需要查看这个表是否具有意向锁即可。\n意向锁的作用主要是用来阻塞表锁的。所以其互相之间是不存在互斥的，只和表锁存在冲突，即读写冲突，具体就像是下面表格这样；\nX IX S IS X Conflict Conflict Conflict Conflict IX Conflict Compatible Conflict Compatible S Conflict Conflict Compatible Compatible IS Conflict Compatible Compatible Compatible 插入意向锁 An insert intention lock is a type of gap lock set by INSERT operations prior to row insertion. This lock signals the intent to insert in such a way that multiple transactions inserting into the same index gap need not wait for each other if they are not inserting at the same position within the gap. Suppose that there are index records with values of 4 and 7. Separate transactions that attempt to insert values of 5 and 6, respectively, each lock the gap between 4 and 7 with insert intention locks prior to obtaining the exclusive lock on the inserted row, but do not block each other because the rows are nonconflicting.\n插入意向锁是间隙锁类型的一种意向锁，锁的是间隙；是在进行插入之前必须申请获得的锁，所以和间隙锁是冲突的；换句话说，如果你想插入一条语句，那么这个语句对应的间隙必须不存在锁，这样你才能加上插入意向锁，进而插入数据；\n而且，插入意向锁只要插入的不是同一行，那么就可以同时插入；\n自增锁（AUTO-INC Locks） An AUTO-INC lock is a special table-level lock taken by transactions inserting into tables with AUTO_INCREMENT columns.\n如官方文档所说，自增锁其实是只针对于自增的字段，算是一个表级锁，一般对我们来说就是自增主键；当有多个事务同时想要插入，由于自增的值必须保持连续，所以多个事务的插入必须串行；\nCase case1（表锁的读-写-读阻塞） 先看正常情况，表锁的读锁是可以加多个的，如下，通过两个查询命令也可以看到确实同时加上了，没有阻塞；\n//console1 lock tables simple read; //console2 lock tables simple read; select * from performance_schema.metadata_locks;\nshow OPEN TABLES where In_use \u0026gt; 0;\n但是在两次读中间插入一次写锁的获取，后面的读锁也会同时被阻塞\n//console1 lock tables simple read; //console2 lock tables simple write;//被console1阻塞 //console3 lock tables simple read;//被console2阻塞 实验证明确实如文档所说，但暂时没有分析原理；\ncase2（元数据锁读-写-读） mysql45讲中提到的一个问题，具体分析见mysql MDL读写锁阻塞，以及online ddl造成的“插队”现象_花落的速度的博客-CSDN博客\ncase3(next-key lock 和 primary key) 在分析之前，先贴一下45讲的总结,该总结版本是 5.x 系列 \u0026lt;=5.7.24，8.0 系列 \u0026lt;=8.0.13，而我测试的版本是8.0.33\n原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。\n原则 2：查找过程中访问到的对象才会加锁。\n优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。\n优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。\n一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。\n目前的数据\nCREATE TABLE `simple` ( `id` bigint NOT NULL AUTO_INCREMENT COMMENT \u0026#39;主键\u0026#39;, `name` varchar(256) COLLATE utf8mb4_bin DEFAULT NULL COMMENT \u0026#39;字符\u0026#39;, `seq` bigint NOT NULL COMMENT \u0026#39;消息序号\u0026#39;, `type` tinyint NOT NULL COMMENT \u0026#39;类型，tinyint值\u0026#39;, `version` int NOT NULL DEFAULT \u0026#39;1\u0026#39; COMMENT \u0026#39;版本值\u0026#39;, `msg` text COLLATE utf8mb4_bin COMMENT \u0026#39;消息\u0026#39;, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \u0026#39;创建时间\u0026#39;, `update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \u0026#39;修改时间\u0026#39;, `yn` tinyint NOT NULL DEFAULT \u0026#39;1\u0026#39; COMMENT \u0026#39;是否有效\u0026#39;, `uni` int NOT NULL COMMENT \u0026#39;唯一索引\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `unidx` (`uni`), KEY `seqidx` (`seq`) ) ENGINE=InnoDB AUTO_INCREMENT=301 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin COMMENT=\u0026#39;简单测试表\u0026#39; 单一查询且查询结果存在(id=15) 存在一个意向表锁和行级读锁，理论上锁住的应该是(5, 15]这部分，但是由于是主键索引（唯一），所以只会锁15这一行，没有必要锁前面的间隙；这是优化1的体现；\nLOCK_MODE为S,REC_NOT_GAP，我理解应该是说只有行锁，行锁类型是读锁；\nstart transaction ; select * from simple where id = 15 lock in share mode ; select * from performance_schema.data_locks; 单一查询且结果不存在(id=16） 将查询条件从15换成了16，理论上锁住的是（15,20]这部分，但是实验表明，20这行不会加行锁，所以最终表现为(15,20)；这是优化2的体现；\nLOCK_MODE为S,GAP，我理解应该是说只有间隙锁，即（15,20）；\nstart transaction ; select * from simple where id = 16 lock in share mode ; select * from performance_schema.data_locks; //console2 start transaction; insert into simple (id,name,type,seq) value (16,5,5,5);//会被阻塞 select * from simple where id=20 for update ;//发现这行可以执行成功 既然可以成功，那就证明id = 16 的查询并没有锁20这一行，不然不可能加的上写锁 那这里如果我把id为20的更新成id为16会怎样？\nupdate simple set id=16 where id=20;\n经实验16-19都不能更新，20以后可以更，比如update simple set id=21 where id=20就可以成功；所以间隙锁是不是也能防止更新；又或者说，其实是因为更新的本质是删除再插入，再插入的被阻塞了，这里感兴趣的可以研究一下；\n范围查询 id\u0026gt;5 按照理论，应该锁住的后5往后的所有范围，即(5,15],(15,20],(20,23],(23,super..];\n所以我推测LOCK_MODE只有一个S，代表加的是临键锁，类型是读锁，没有特殊表明缺少行锁或者间隙锁就是完整的临建锁，并且我在console2尝试插入id为6或者36的，都会被阻塞\n//console1 start transaction ; select * from simple where id\u0026gt;5 lock in share mode ; select * from performance_schema.data_locks; //console2 都会被阻塞 insert into simple (id,name,type,seq) value (6,5,5,5); insert into simple (id,name,type,seq) value (36,5,5,5); id\u0026gt;=5 和上面的唯一区别就是多了个等于5，那么5上是临键锁还是行锁呢？我觉得是行锁，因为优化1，而且这样和我们的认知也是比较符合的；\n实际看到确实是这样；\nstart transaction ; select * from simple where id\u0026gt;=5 lock in share mode ; select * from performance_schema.data_locks; id\u0026gt;5 and id\u0026lt;20 首先5\u0026lt;x\u0026lt;20，那么正常情况应该是(5,15]和(15,20]，然后20因为不等于会被优化（触发了优化2)，所以是(5,20)\nstart transaction ; select * from simple where id\u0026gt;5 and id\u0026lt;20 lock in share mode ; select * from performance_schema.data_locks; id\u0026gt;5 and id\u0026lt;=20 假如是5\u0026lt;x\u0026lt;=20，那就会是(5,20]；\n但是注意我们前面提到过一个bug，可是我们看到目前就是锁到20为止，并不是(5,23)，翻看评论区说在MySQL 8.0.18 已经修复,而我的版本是8.0.33，这里难道是修复了吗？先存疑，因为这里只能证明主键索引修复了，后面唯一索引那里还是乱的一批\nid\u0026gt;30 应该会直接锁(23,super\u0026hellip;)\ncase4(next-key lock和 unique key) 和case3唯一的区别就是将主键索引换成了唯一索引，猜测应该是一模一样的，因为文档里的特殊规则说的也都是唯一索引，而没有限制到主键上；\n单一查询且查询结果存在(uni=15) start transaction ; select * from simple where uni = 15 lock in share mode ; select * from performance_schema.data_locks; 理想很美好，现实很骨感；这是什么？？突然想到行锁和间隙锁都是锁在索引上的锁，由于我查询结果是所有字段，所以会发生回表查询；当命中到唯一索引的时候会锁一次，然后根据主键id再锁一次；\n但是现在我的uni和id字段值是一样的，所以为了区分，我将uni这一列都加了100，然后执行下面的句子\nstart transaction ; select * from simple where uni = 115 lock in share mode ; select * from performance_schema.data_locks; select id from simple where uni = 115 lock in share mode ; 可以看到primary那行应该是因为回表操作，而unidx那行应该则是对应唯一索引的查询，实际锁的范围和主键索引是一致的，只不过锁的内容我不理解，lock_data为115,15，为什么？\n而且如果我们查询的不是select *,而是select id ,锁的信息就不包含primary那行了；\n单一查询且结果不存在(uni=116） start transaction ; select * from simple where uni = 116 lock in share mode ; select * from performance_schema.data_locks; 由于查询不到，所以也不会回表查询，就不存在primary那行了\nuni\u0026gt;105 start transaction ; select id from simple where simple.uni\u0026gt;105 lock in share mode ; select * from performance_schema.data_locks; 我理解到每个索引节点的时候，都会执行一次select * from simple where id = x；所以会多出几行只有行锁primary的记录；\nuni\u0026gt;=105只是会在unidx和primary上各多一个锁，但范围和唯一索引依然一致，就不贴了\nuni\u0026gt;105 and uni\u0026lt;120 //console1 commit ; start transaction ; select * from simple where uni\u0026gt;105 and uni\u0026lt;120 lock in share mode ; select * from performance_schema.data_locks; //console2 select * from simple where uni=120 for update ;//被阻塞 这里和上面不一样的是，这里把120这行也锁上了，主键索引锁20是间隙锁，这里是临键锁；为什么这里会锁上呢？就很像是bug并没有修复，依然锁到了第一个不满足条件的，并且加了临键锁\nuni\u0026gt;105 and uni\u0026lt;=120 commit ; start transaction ; select * from simple where uni\u0026gt;105 and uni\u0026lt;=120 lock in share mode ; select * from performance_schema.data_locks; 这里更离谱，这里为什么把123都给锁上了？？感觉bug依然存在，多锁了一个区间\nuni\u0026gt;130和上面的id\u0026gt;30结果一样，就不贴了 总结：对于唯一索引来说，因为存在主键，那么会产生回表操作，回表操作会给主键再加一把锁；而那个bug依旧存在，只有主键索引的修复了，非主键唯一索引依然存在这个bug;\ncase5（索引加在哪） //console1 start transaction ; select id from simple where uni=105 lock in share mode ; select * from performance_schema.data_locks; //console2 start transaction ; update simple set name=\u0026#39;new\u0026#39; where id=5; 现在我们已经清楚，执行完console1之后，会给unidx加一个行锁，因为没有回表，所以主键上没有锁；那么console2能否成功执行呢？\n答案是，可以的；\n我个人理解，是因为锁是加在索引上的，而索引是列维度的，不是行维度的；console2执行语句只会去判断id这个索引上，有没有5这个锁；\n接下来我们反过来\n//console1 start transaction ; select * from simple where id=5 lock in share mode ; select * from performance_schema.data_locks; //console2 start transaction ; update simple set name=\u0026#39;new\u0026#39; where uni=105; 你试着一起敲一下就会发现，咦，console2怎么阻塞了呢？按上面所说的，不是不应该吗？\n实际上console1的执行锁的确实是id；\n但是你console2的执行，会回表啊，会尝试给id加写锁，但是id已经加了读锁了，所以自然不行了；\n所以，不要盲目的只看查询条件，要理解当前语句都会加什么锁，是否和已经加的锁冲突；\n最后，我们再来看一个附加题，下面两个语句加的锁是否一样呢？\nstart transaction ; select id from simple where uni=105 lock in share mode ; select * from performance_schema.data_locks; start transaction ; select id from simple where uni=105 for update ; select * from performance_schema.data_locks; 在我没有尝试之前，我理解都没有回表，那么就应该一个是唯一索引加读锁，一个是唯一索引加写锁；\n但是实际结果却是lock in share mode是对的，for update会认为你要更新语句，自动给主键加锁了\ncase6（next-key lock 和index） 吸取uni的教训，我给seq的值都加了200，现在这个表是这样的\nseq=215 start transaction ; select * from simple where seq=215 lock in share mode ; select * from performance_schema.data_locks; 除了意向锁，其他三个我们一个个看；\nseqidx(S)这行是普通索引执行时加的临键锁，由于不是唯一索引，所以不能优化（因为可能存在重复）\nprimary(S,REC_NOT_GAP)这是回表操作带来的\nseqidx(S,GAP)这行是因为不是唯一索引，所以在查询到匹配的值之后不会立马停止（因为后面可能还存在相同的值），所以必须要到不符合条件的值为止，而所有查询过的都会加索引，所以存在一个间隙锁。\nseq=216 start transaction ; select * from simple where seq=216 lock in share mode ; select * from performance_schema.data_locks; 我理解，应该是从205开始查，查到第一个不符合条件的值是215，加上中间没有回表，所以就这一个锁；理论应该是(215,220]，但由于优化2，所以退化为间隙锁；\nseq\u0026gt;215 and seq\u0026lt;220 start transaction ; select * from simple where seq\u0026gt;215 and seq \u0026lt;220 lock in share mode ; select * from performance_schema.data_locks; 从215开始匹配，第一个不符合条件的是220，所以只能是（215,220]\nseq\u0026gt;215 and seq \u0026lt;=220 start transaction ; select * from simple where seq\u0026gt;215 and seq \u0026lt;=220 lock in share mode ; select * from performance_schema.data_locks; 这里和上面区别就是不符合条件的会到223为止，另外中间因为匹配成功会回一次表\nseq\u0026gt;230和前面unidx\u0026gt;130和id\u0026gt;30都一样 case7(next-key和没有索引） alter table simple drop index seqidx; start transaction ; select * from simple where seq=215 lock in share mode ; select * from performance_schema.data_locks; 前面提到过，查询条件匹配不到索引或者只是索引的一部分，这个时候为了保证数据的准确性，会给整个表“加锁”，其实给表里所有的记录都加锁(这里我不知道描述的对不对，因为表锁！=所有记录加锁，虽然效果相似，但并不是一个东西）.\n同时因为这个表存在意向读锁，通过lock tables simple write 加写的表锁会冲突；\n疑问 对于事务和表锁一起用的情况，到底要使用set autocommit=0吗？why？\nThe correct way to use LOCK TABLES and UNLOCK TABLES with transactional tables, such as InnoDB tables, is to begin a transaction with SET autocommit = 0 (not START TRANSACTION) followed by LOCK TABLES, and to not call UNLOCK TABLES until you commit the transaction explicitly. For example, if you need to write to table t1 and read from table t2, you can do this: SET autocommit=0; LOCK TABLES t1 WRITE, t2 READ, ...; ... do something with tables t1 and t2 here ...COMMIT; UNLOCK TABLES; When you call LOCK TABLES, InnoDB internally takes its own table lock, and MySQL takes its own table lock. InnoDB releases its internal table lock at the next commit, but for MySQL to release its table lock, you have to call UNLOCK TABLES. You should not have autocommit = 1, because then InnoDB releases its internal table lock immediately after the call of LOCK TABLES, and deadlocks can very easily happen. InnoDB does not acquire the internal table lock at all if autocommit = 1, to help old applications avoid unnecessary deadlocks. 参考文档 https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html#innodb-shared-exclusive-locks\nhttps://dev.mysql.com/doc/refman/8.0/en/lock-tables.html\n06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？-极客时间\nmysql MDL读写锁阻塞，以及online ddl造成的“插队”现象_花落的速度的博客-CSDN博客\nMYSQL查看表是否被锁、以及解锁_mysql查看锁表_清石小猿的博客-CSDN博客\n","date":"2023-06-14T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/mysql/db_lock/","title":"锁"},{"content":"事务隔离级别遗留问题： 在读已提交的级别下，事务B可以读到事务A持有写锁的的记录，且读到的是未更新前的，为何写读没有冲突？\n可重复读级别，事务B可以更新事务A已经获取读锁的记录，且更新后，事务A依然可以获取读锁，为何读-写-读没有冲突？\n在可重复读级别，幻读没有产生？\n其中，前两个问题就是因为mvcc机制（读锁的一种优化机制），通过不加读锁，避免读写冲突，进而提高了性能。\n而第三个问题，一部分原因是由MVCC机制保证的，还有一部分则是由锁来保证的；\n两次查询都是当前读或快照读，不会出现幻读问题；\n第一次查询是快照读，第二次是当前读，会出现幻读问题；\n在学习了解MVCC机制中遇到的问题： 为什么更新操作必须使用当前读？\n只读事务突然更新的话，因为更新必须使用当前读，那是否需要重新生成事务id?\n只读事务分配的事务id是什么东西？如何参与运作？\nreadview的范围\n知道了mvcc底层是undolog和readview后，怎么理解“版本”这个概念\n在只读视图能查到其他事务已经删除并且提交的记录吗？\n为什么要有MVCC机制？ 在读已提交的级别下，由于是给读加锁来保证读已提交， 如果事务A持有写锁，为了保证读已提交，事务B必须等待事务A提交之后才可以读；其他的读事务也是这样的情况，效率太低\n在可重复读级别，为了保证可重复读，如果事务A持有读锁，为了第二次读到的一样，其他所有写事务必须等待读完才可以，同样效率低\n那么很自然的想到，无论读事务是先产生还是后产生，如果这个时候还存在写事务没有执行，或者需要执行；那么就应该让读事务读到目前最新的值，且写事务可以更新；只不过读事务在写事务提交更新后，依据隔离级别是否可见最新更新即可。这就是MVCC机制的核心能力，将读锁干掉。\nMVCC机制核心组件 MVCC机制由版本链、undolog、readview三大核心构成\n版本链 猜测很多人第一次看到MVCC的版本都是和我一样在各种各样的博客文章上，或者可能是在一些课程专栏或者《高性能mysql》这本书的mvcc部分看到的，那么在你的理解中，版本的底层是什么样子呢？\ninnodb引擎数据库中的每一条记录上，我们都可以认为上面有3个隐藏字段，分别是DB_ROW_ID(不在此次讨论范围),DB_TRX_ID和DB_ROLL_PTR,如下图一样\n在我的理解中，\nDB_TRX_ID就是插入或者更新时，当前事务的trx_id，由全局事务管理器分配的递增的一个id；\nDB_ROLL_PTR存储的undolog中当前记录上一个版本的指针，先姑且记住这是一个指针。\n当插入一条记录时\n在这条记录的DB_TRX_ID填入当前事务的id，由于没有历史版本，所以DB_ROLL_PTR为空\n当更新一条记录时\n由于这个时候存在历史版本，所以需要将老版本的数据写到undolog里，然后构建指针\n将DB_TRX_ID更新为当前事务的id,将DB_ROLL_PTR更新为刚才构建的指针，以及更新需要更新的字段。\n当删除一条记录时（这个不太确定，主观猜测）\n猜测是将老记录写到undolog，然后构建指针\n新记录DB_TRX_ID更新为当前事务的id,将DB_ROLL_PTR更新为刚才构建的指针，但是没有需要更新的字段。\nmysql不会立即删除，记录上有一个info_bits字段，会标记上删除标识(REC_INFO_DELETED_FLAG)，后续由purge线程（不了解，姑且认为是个scheduleTask吧)删除\n这样，当多次更新之后，新记录存储的永远都是最新操作的事务id，并通过指针指向了老版本，老版本还指向了更老的版本\u0026hellip;等等，最终构成了一个版本链\nReadview 理论： 在周志明老师的凤凰架构（或者极客时间的‘周志明的软件架构课’）中对mvcc简单介绍到\n隔离级别是可重复读：总是读取 CREATE_VERSION 小于或等于当前事务 ID 的记录，在这个前提下，如果数据仍有多个版本，则取最新（事务 ID 最大）的。\n隔离级别是读已提交：总是取最新的版本即可，即最近被 Commit 的那个版本的数据记录。\n在mysql官网中是这么描述的\nIf the transaction isolation level is REPEATABLE READ (the default level), all consistent reads within the same transaction read the snapshot established by the first such read in that transaction. You can get a fresher snapshot for your queries by committing the current transaction and after that issuing new queries.\nWith READ COMMITTED isolation level, each consistent read within a transaction sets and reads its own fresh snapshot.\n翻译：\n隔离级别是可重复读：在同一个事务中，一致性视图是在总是去第一次读取时生成的快照。\n隔离级别是读已提交：事务中的每次读取都取自己新生成的快照。\n相比之下，周老师形容的更贴近隔离级别的概念上，官方的描述则是底层的具体实现逻辑。\n两者结合一下就是\n可重复读：通过在每个事物只读取第一次select时生成的快照和undolog比较，根据一个可见性规则判断，是否可以读当前版本的记录，可以就返回，不行就继续比较再上一个版本，直到最老的版本；\n读已提交：除了每次读取都会使用最新的快照，后面的都和可重复读的逻辑一样。\n为什么我这里说的是可见性规则呢？\n是因为周老师描述里“总是读取 CREATE_VERSION 小于或等于当前事务 ID 的记录”\n很容易错误的理解为当前版本记录里的trx_id\u0026lt;=快照创建时的事务id(create_trx_id)就都可见，真正的判断逻辑并不只是一个create_trx_id就能搞定的。\n但这里先不展开讲，自己想一下为什么不行，下面的图可能会给你一点灵感，接下来我们先去读一下“可见性规则”的底层源码。\n可见性规则底层实现 ReadView类 storage/innobase/include/read0types.h:47 //ReadView类 class ReadView { ... private: /** trx id of creating transaction, set to TRX_ID_MAX for free views. */ //创建快照的时候，快照对应的事务id，只有含有写操作的才会分配真正的事务id trx_id_t m_creator_trx_id; /** Set of RW transactions that was active when this snapshot was taken */ //活跃的读写事务id列表，从trx_sys-\u0026gt;rw_trx_ids抄过来的 ids_t m_ids; /** The read should not see any transaction with trx id \u0026gt;= this value. In other words, this is the \u0026#34;high water mark\u0026#34;. */ //赋值是即将分配的下一个事务id，所以大于等于这个id的记录对当前事务来说都是不可见的 trx_id_t m_low_limit_id; /** The read should see all trx ids which are strictly smaller (\u0026lt;) than this value. In other words, this is the low water mark\u0026#34;. */ //m_ids不为空就是ids.get(0)，为空则是m_low_limit_id,所以小于这个事务id的就代表着快照建立的时候 //已经不是活跃事务了，即已经提交了，所以一定可以看到这些事务的改动记录 trx_id_t m_up_limit_id; .... } 初始化赋值的时候 //read0read.cc //row_search_mvcc -\u0026gt; trx_assign_read_view -\u0026gt; MVCC::view_open -\u0026gt; void ReadView::prepare(trx_id_t id) { ut_ad(trx_sys_mutex_own()); m_creator_trx_id = id; m_low_limit_no = trx_get_serialisation_min_trx_no(); m_low_limit_id = trx_sys_get_next_trx_id_or_no(); ut_a(m_low_limit_no \u0026lt;= m_low_limit_id); if (!trx_sys-\u0026gt;rw_trx_ids.empty()) { copy_trx_ids(trx_sys-\u0026gt;rw_trx_ids); } else { m_ids.clear(); } /* The first active transaction has the smallest id. */ m_up_limit_id = !m_ids.empty() ? m_ids.front() : m_low_limit_id; ut_a(m_up_limit_id \u0026lt;= m_low_limit_id); ut_d(m_view_low_limit_no = m_low_limit_no); m_closed = false; } 判断某个版本的记录是否可见？ //read0types.h bool changes_visible(trx_id_t id, const table_name_t \u0026amp;name) const { ut_ad(id \u0026gt; 0); //如果当前版本记录上的事务id（DB_TRX_ID）小于低水位或者等于当前事务， //那么要么就是自己更改的，要么就是历史上已经提交了的，所以可以读到 if (id \u0026lt; m_up_limit_id || id == m_creator_trx_id) { return (true); } check_trx_id_sanity(id, name); //如果当前版本记录上的事务id（DB_TRX_ID）大于高水位，那么就是在当前快照生成后生成的事务，一律看不到 if (id \u0026gt;= m_low_limit_id) { return (false); //这一步我没有理解， } else if (m_ids.empty()) { return (true); } const ids_t::value_type *p = m_ids.data(); //二分查找，如果活跃的事务里面没有，那么就返回true //这里我是这么理解的，[低水位,高水位]包含活水和死水，即活跃的事务和已经提交的事务 //假如存在事务1是活跃的，事物2是已提交的，事务3是活跃的，我们在事务4的时候开启快照，很明显我们只能读到事务2或者事务4的变更 //假如正在判断的是事务2，因为已经经过了上面的校验， //所以我们知道当前版本记录的事务m_low_limit_id（高水位）\u0026gt;id\u0026gt;=m_up_limit_id（低水位)，且不是当前事务; //所以就需要判断事务只要不是活跃的，那么就一定是已经提交的事务，那么就可读 return (!std::binary_search(p, p + m_ids.size(), id)); } 事务的trx_id 在我还没开始看mysql源码，只是跟着博客学习写用例测试的时候，我发现，开启事务进行了第一次查询之后，确实有生成事务id，但后面我更新了之后，原来的事务id变了；就像下面这个图一样，最开始只有查询的时候是比较长的这个id,但执行了一条update语句后，事务id变成了一个短的。\n这个时候我就产生了很多疑问？同一个事务里，事务id怎么还能变呢？变的话changes_visible里面的比较怎么算？搜索了一下之后了解到，只读事务是不会生成事务id的，是假的！于是我又疑惑，那这个假id怎么参与changes_visible呢？也就是这个时候，我才下定决心去看源码，也借此理解了高低水位的设计，并认识到自己之前的理解是错误的。\n先上结论\n只读事务不会分配真正的事务id，他的值是0；\n只读事务参与change_visable的时候，create_trx_id也确实是0，是通过m_up_limit_id（低水位）来判断是否可见的，只有在变成读写事务是，create_trx_id才会起效并应用；\n因为值是0，在通过下面sql查询的时候，那串id只是展示的时候特殊处理的\nselect * from information_schema.INNODB_TRX; //trx0trx.cc#trx_start_low //这里可以看到只有读写事务才真正分配了id else { trx-\u0026gt;id = 0;//开始是0 if (!trx_is_autocommit_non_locking(trx)) { /* If this is a read-only transaction that is writing to a temporary table then it needs a transaction id to write to the temporary table. */ if (read_write) { trx_sys_mutex_enter(); ut_ad(!srv_read_only_mode); trx-\u0026gt;state.store(TRX_STATE_ACTIVE, std::memory_order_relaxed); trx-\u0026gt;id = trx_sys_allocate_trx_id();//这里进行分配 trx_sys-\u0026gt;rw_trx_ids.push_back(trx-\u0026gt;id); trx_sys_mutex_exit(); trx_sys_rw_trx_add(trx); } else { trx-\u0026gt;state.store(TRX_STATE_ACTIVE, std::memory_order_relaxed); } } else { ut_ad(!read_write); trx-\u0026gt;state.store(TRX_STATE_ACTIVE, std::memory_order_relaxed); } } //trx0trx.ic //这里是在展示的时候对只读事务的id做了处理 @return transaction id */ static inline trx_id_t trx_get_id_for_print(const trx_t *trx) { /* DATA_TRX_ID_LEN is the storage size in bytes. */ static const trx_id_t max_trx_id = (1ULL \u0026lt;\u0026lt; (DATA_TRX_ID_LEN * CHAR_BIT)) - 1; ut_ad(trx-\u0026gt;id \u0026lt;= max_trx_id); /* on some 32bit architectures casting trx_t* (4 bytes) directly to trx_id_t (8 bytes unsigned) does sign extension and the resulting value has highest 32 bits set to 1, so the number is unnecessarily huge. Also there is no guarantee that we will obtain the same integer each time. Casting to uintptr_t first, and then extending to 64 bits keeps the highest bits clean. */ return (trx-\u0026gt;id != 0 ? trx-\u0026gt;id : trx_id_t{reinterpret_cast\u0026lt;uintptr_t\u0026gt;(trx)} | (max_trx_id + 1)); } 生成快照时机（不太确定） 可重复读：只生成一次，后面继续使用\nReadView *trx_assign_read_view(trx_t *trx) /*!\u0026lt; in/out: active transaction */ { ut_ad(trx_can_be_handled_by_current_thread_or_is_hp_victim(trx)); ut_ad(trx-\u0026gt;state.load(std::memory_order_relaxed) == TRX_STATE_ACTIVE); if (srv_read_only_mode) { ut_ad(trx-\u0026gt;read_view == nullptr); return (nullptr); } else if (!MVCC::is_view_active(trx-\u0026gt;read_view)) { trx_sys-\u0026gt;mvcc-\u0026gt;view_open(trx-\u0026gt;read_view, trx); } return (trx-\u0026gt;read_view); } 读已提交：好像是用完就关，所以每次再获取就得新开，但是这里的关有两个地方调，不太确定上层是不是sql执行完的方法\nha_innodb.cc#store_lock 和ha_innodb.cc#external_lock\nif (lock_type != TL_IGNORE \u0026amp;\u0026amp; trx-\u0026gt;n_mysql_tables_in_use == 0) { trx-\u0026gt;isolation_level = innobase_trx_map_isolation_level(thd_get_trx_isolation(thd)); if (trx-\u0026gt;isolation_level \u0026lt;= TRX_ISO_READ_COMMITTED \u0026amp;\u0026amp; MVCC::is_view_active(trx-\u0026gt;read_view)) { /* At low transaction isolation levels we let each consistent read set its own snapshot */ mutex_enter(\u0026amp;trx_sys-\u0026gt;mutex); trx_sys-\u0026gt;mvcc-\u0026gt;view_close(trx-\u0026gt;read_view, true); mutex_exit(\u0026amp;trx_sys-\u0026gt;mutex); } } 快照读和当前读 快照读：当前执行的sql如果不存在锁，那么默认读到的就是readview里的快照，这种情况称之为快照读；\n当前读：如果当前执行的sql存在锁，比如使用了lock in share mode,for update，或者是insert、update、delete操作，对于这种需要锁的sql，必须读取最新的视图，这种行为称之为当前读；\n我个人理解只有在RR级别才需要区分对待，RC级别都是当前读；而且我认为二者的区别就只有加锁和不加锁这一个点\n回答文章最开始的一些问题： 为什么更新操作必须使用当前读？ 更新操作后的如果不回滚那没有事，如果要回滚，应该回滚到最新一次的提交，所以undo log里必须是最新的视图\n只读事务突然更新的话，因为更新必须使用当前读，那是否需要重新生成事务id? 不算做重新，是只有在触发锁操作时会分配真正的事务id，只读事务分配的id其实就是0\n只读事务分配的事务id是什么东西？如何参与运作？ 没有作为判断条件，作为判断条件的是up_limit记录的是最小活跃id，小于他的才能读，正规的事务id分配的在readview结构里其实是creator_trxid，用来判断当前是否能被当前事务看见\nreadview的范围 有这个疑问还是因为最开始对change_visable掌握的不够清晰。\n之前想的场景是在事务A里，如果存在两条不同记录甚至不同表的查询，而事务B在第事务A两条查询中间的时候对第二条查询的记录做了更改并提交，那应该查到的是新的还是旧的。\n其实应该是旧的，因为就算是第二条查询，最新版本的改动的事务id会大于等于事务A的高水位，因此只能查询到更老的undolog里的记录\n知道了mvcc底层是undolog和readview后，怎么理解“版本”这个概念 创建版本肯定就是字段里那个隐藏字段，删除版本应该是回滚指针\n在只读视图能查到其他事务已经删除并且提交的记录吗？ 经测试是可以的\n怎么解决的幻读？ 在只读事务下，如上文所说的事务1读不到事务2的更新是因为事务2的版本号要大于当前快照的高水位，那对于新增的记录来说，其版本号也是同样的道理，因此事务1读不到比当前快照里的高水位高的，也就避免了幻读这种情况。\n但是在当前读下，由于必须读取最新的结果，所以版本号一定是当前事务可见的，那么这个时候mysql的表现是什么样子呢？又是为什么是这样子呢？通过下面的实例来认识一下\nsimple表的初始情况\n//console1 select * from simple; select * from simple where id \u0026lt;10 lock in share mode ; //console2 start transaction ; insert into simple (id,name,seq,type) value (6,3,3,1); 这个时候理论上事务2应该可以顺利插入id为6的记录，毕竟我们虽然加了读锁；但是记录都不存在必然也锁不住； 但是我们会发现insert这条语句被阻塞了，在等待一会之后会报下面的错 Lock wait timeout exceeded; try restarting transaction 既然锁等待了，就必然存在一个锁，不过锁的部分我还需要再研究研究。\n预计将在下一篇文章中介绍，敬请期待\u0026hellip;\n参考资料： MySQL 8.0 MVCC 源码解析 - 掘金\nhttps://dev.mysql.com/doc/refman/8.0/en/innodb-consistent-read.html\nMySQL事务ID的分配时机_mysql事务id什么时候分配_哲学长的博客-CSDN博客\nMYSQL innodb中的只读事物以及事物id的分配方式_ITPUB博客\nMysql如何实现隔离级别 - 可重复读和读提交 源码分析_mysql 可重复度源码_择维士的博客-CSDN博客\n","date":"2023-06-05T00:00:00Z","image":"https://qisiii.github.io/blog-img/mvcc.png","permalink":"https://qisiii.github.io/post/tech/mysql/mvcc/","title":"MVCC机制"},{"content":"标准隔离级别 读未提交、读已提交、可重复读、串行化\n串行化 对事务中所有读写的数据加上读锁、写锁、范围锁。所以冲突的事务必须同步执行。\n//console1 start transaction ; select * from transaction_test where `key`=1; update transaction_test set name=\u0026#39;newTest\u0026#39; where `key`=1; //console2 start transaction ; select * from transaction_test where `key`=1;（由于事务1没有释放写锁，所以这里的查询会阻塞 如果等待时间过长，会报如下的错误；如果事务1只是查询，那么事务2也可以查询） [40001][1205] Lock wait timeout exceeded; try restarting transaction //console1 commit ;(提交完之后如果事务2没有等待超时，那么会立即执行) //console2; commit ; 可重复读 核心是只对事务中所有读写的数据加上读锁、写锁，不加范围锁。本应该如此，但是有mvcc优化。\n相比于读已提交，由于对整个事务都加上了读锁，避免其他事务可以进行更新，进而保证同一个事务多次读到的数据都是没有被修改过的数据。\n----避免可重复读---- name初始值为init //console1 start transaction ; select * from transaction_test where `key`=1;（查询结果是init) //console2 start transaction ; update transaction_test set name=\u0026#39;test\u0026#39; where `key`=1; (理论上，由于事务1已经获取了读锁，事务2这里添加写锁应该是添加不上的,应该是阻塞中才对； 但是，实操发现，执行成功了，且在事务2中通过下面这个语句查询是test，这应该也是mvcc导致的 select * from transaction_test where `key`=1; //console1 select * from transaction_test where `key`=1; console1的第2次查询，查询结果和第一次一样，还是init 另外，事务2都获得写锁了，怎么能允许你事务1再去获得读锁，还是因为MVCC机制搞的鬼 commit ; //console2 commit ; 相比于串行化，由于没有加范围锁，会引发一种叫幻读的情况\n所谓幻读是指在同一个事务中，第一次查询id\u0026lt;10的假定有1条，第二次查询可能会有2条，原因是在两次查询的中间，存在别的事务插入或者删除了数据，由于事务A只加了读锁或者写锁，只能防止其他事务对已经加锁的这几条数据进行修改，但避免不了插入和删除，所以才会出现这个问题。\n----幻读---- 初始是1,name //console1 start transaction ; select * from transaction_test where `key`\u0026lt;10; //console2 start transaction ; insert into transaction_test ( `key`,`name`) value (3,\u0026#39;newddd\u0026#39;); select * from transaction_test where `key`\u0026lt;10; commit; //console1 select * from transaction_test where `key`\u0026lt;10; 理论上来讲，这个地方应该会查到三条，但是实操发现，在事务2添加并提交之后，事务1查到了依然是原来的样子 即不存在幻读现象，这是怎么回事？ MVCC的优化 commit ; select * from transaction_test where `key`\u0026lt;10;(提交之后再次查询就有新结果了） 读已提交 核心是对事务中需要更新的操作行加写锁，直到事务结束，但对查询的操作行加读锁，但在查询完之后立即释放，即不是在整个事务范围锁定。\n读已提交通过对查询操作加锁来避免读未提交，在事务B修改数据时因为其在事务结束之前一直持有写锁，事务A无法对数据加读锁，只能等待事务B提交事务才可以读取，这也是读已提交的名称的由来。\n虽然解决了读未提交的问题，但是由于只在查询的时候短暂加了读锁，引发了另一个不可重复读的问题；\n所谓不可重复读是指在同一个事务中，对于同样一条数据的两次查询结果不一样，那么这个和幻读有什么区别呢？幻读整个事务中都存在读锁或者写锁，其他事务无法修改，只能增删；但是不可重复读，则是指当前已经查到的结果被更新了。\n原因是假如同一个事务两次查询中间，别的事务进行了修改，由于事务A没有加整个事务范围的读锁，所以事务B是可以成功获取写锁的，进而修改数据，最终导致了不可重复读。\n---避免读未提交---- name初始值是init //console1 start transaction ; select * from transaction_test where `key`=1; update transaction_test set name=\u0026#39;test\u0026#39; where `key`=1; //console2 start transaction ; select * from transaction_test where `key`=1;（由于读不到未提交的，所以肯定获取不到修改后的test值，理论上只能等待事务1结束） 这个地方由于事务1已经添加了写锁，原则上事务2根本查询不了，应该阻塞，就像串行化那里一样 但是实际结果却是可以查到以前的值，即init；所以这里应该是mvcc的作用 在读已提交的级别下，mvcc机制总是取最新的版本即可，即最近被 Commit 的那个版本的数据记录。 这样保证了读到的都是已提交的事务 //console1 commit;//提交之后，事务2再次查询，发现已经可以获取到改动后的值了，即test ---不可重复读---- name初始值是init //console1 start transaction ; select * from transaction_test where `key`=1;(第一次查询是init) //console2 start transaction ; update transaction_test set name=\u0026#39;test\u0026#39; where `key`=1;(在事务2中更新并提交) commit ; //console1 select * from transaction_test where `key`=1;(第二次查询是test) commit ; 读未提交 核心是对事务中需要更新的操作行加写锁，直到事务结束，但对查询的操作行不加锁。\n引发的问题是脏读，其实就是读到了其他事务还没有提交的数据；那么为什么事务A可以读到事务B还没有提交的数据？\n分为两步理解:\n1.为什么存在可以读的新的数据?\n核心原因应该是write-ahead logging的设计。即上一章提到的允许在事务提交之前提前写入数据，理论上肯定是写到了内存中，并且记录到undolog里面，虽然还不太情况事务的提交真正干了什么操作，但目前来，在内存是可以读到已经修改好的数据。\n2.为什么可以读到已经加了写锁的数据\n原因是读未提交读取数据是不加读锁的，而写锁只能防止其他事物不能加读锁和写锁，而不能防止没有锁 也可以看一下这篇博客的解释\nshow variables like \u0026#39;transaction%\u0026#39;; set global transaction isolation level read uncommitted ;//设置完之后要重新登录 CREATE TABLE `transaction_test` ( `key` int(11), `name` varchar(10) DEFAULT NULL ) ENGINE=InnoDB; ---read uncommitted--- 读未提交 //console1 start transaction ; insert into transaction_test value (1,\u0026#39;test\u0026#39;); //console2 start transaction ; select * from transaction_test where `key`=1; (查询结果为1，test） //console1 commit ; //console2 commit; 两个事务都是写事务，晚开启的事务更新会阻塞 //console1 start transaction ; update transaction_test set name=\u0026#39;newTest\u0026#39; where `key`=1; //console2 start transaction ; update transaction_test set name=\u0026#39;Test\u0026#39; where `key`=1;（会阻塞，一直在执行中） //console1 commit ;（在事务1提交成功后，事务2的更新立马就成功了) //console2 commit; 参考资料： 12 | 本地事务如何实现隔离性？-极客时间\n03 | 事务隔离：为什么你改了我还看不见？-极客时间\n读未提交-为什么事务没提交就可以读到别人修改的数据 - 秦一居 - 博客园\n","date":"2023-05-30T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/mysql/transaction_isolation/","title":"事务隔离级别"},{"content":"\n本质是将接口和实现进行解耦，使得外部程序可以提供不同的实现；\n实现机制为ServiceLoader通过迭代器进行\npublic Iterator\u0026lt;S\u0026gt; iterator() { return new Iterator\u0026lt;S\u0026gt;() { //之所以有knownProviders是为了处理多次迭代的情况，首次迭代的时候就将其缓存到了providers， //如果要重新加载所有的实现类，需要调用reload Iterator\u0026lt;Map.Entry\u0026lt;String,S\u0026gt;\u0026gt; knownProviders = providers.entrySet().iterator(); //本质是lookupIterator的方法 public boolean hasNext() { if (knownProviders.hasNext()) return true; return lookupIterator.hasNext(); } public S next() { if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next(); } public void remove() { throw new UnsupportedOperationException(); } }; } 从图中可以看出核心方法是hasNextService和nextService，acc是Java安全机制之一——SecurityManager和AccessController，可以忽略不看。\nprivate boolean hasNextService() { if (nextName != null) { return true; } if (configs == null) { try { //PREFIX为META-INF/services/，service.getName是全限定名 String fullName = PREFIX + service.getName(); if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); } catch (IOException x) { fail(service, \u0026#34;Error locating configuration files\u0026#34;, x); } } while ((pending == null) || !pending.hasNext()) { if (!configs.hasMoreElements()) { return false; } //将文件按行读取，每一行是list的一个元素 pending = parse(service, configs.nextElement()); } nextName = pending.next(); return true; } private S nextService() { if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class\u0026lt;?\u0026gt; c = null; try { //搞到类 c = Class.forName(cn, false, loader); } catch (ClassNotFoundException x) { fail(service, \u0026#34;Provider \u0026#34; + cn + \u0026#34; not found\u0026#34;); } if (!service.isAssignableFrom(c)) { fail(service, \u0026#34;Provider \u0026#34; + cn + \u0026#34; not a subtype\u0026#34;); } try { //实例化，并强转为接口类型 S p = service.cast(c.newInstance()); //缓存方便以后使用 providers.put(cn, p); return p; } catch (Throwable x) { fail(service, \u0026#34;Provider \u0026#34; + cn + \u0026#34; could not be instantiated\u0026#34;, x); } throw new Error(); // This cannot happen } 缺点是：不能按需加载，需要将所有的实现都遍历完，实例化完。\n应用场景：比如spring参考SPI机制搞的spring.factories，dubbo的@SPI\n参考文档： 深入理解 Java 中 SPI 机制\nJava SPI概念、实现原理、优缺点、应用场景、使用步骤、实战SPI案例-CSDN博客\n","date":"2023-03-17T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/lang/java_spi/","title":"Java的SPI机制"},{"content":"hashmap源码分析 构造函数 initialCapacity 初始化大小，一般最好2次幂\npublic HashMap(int initialCapacity, float loadFactor) { //初始化值默认是16 if (initialCapacity \u0026lt; 0) throw new IllegalArgumentException(\u0026#34;Illegal initial capacity: \u0026#34; + initialCapacity); if (initialCapacity \u0026gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor \u0026lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\u0026#34;Illegal load factor: \u0026#34; + loadFactor); //The load factor for the hash table. 扩载因子，默认0.75f this.loadFactor = loadFactor; //The next size value at which to resize (capacity * load factor). this.threshold = tableSizeFor(initialCapacity); } //通过其他map初始化新的map public HashMap(Map\u0026lt;? extends K, ? extends V\u0026gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); } tableSizeFor /** * Returns a power of two size for the given target capacity. */ //生成一个大于等于 c 且为 2 的 N 次方的最小整数 static final int tableSizeFor(int cap) { //减一是为了已经是2的幂次方的统一应对 int n = cap - 1; //这一段的本质是将首位及其后面的数字都变为1，然后+1 n |= n \u0026gt;\u0026gt;\u0026gt; 1; n |= n \u0026gt;\u0026gt;\u0026gt; 2; n |= n \u0026gt;\u0026gt;\u0026gt; 4; n |= n \u0026gt;\u0026gt;\u0026gt; 8; n |= n \u0026gt;\u0026gt;\u0026gt; 16; return (n \u0026lt; 0) ? 1 : (n \u0026gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } put() public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } 先了解一下hash static final int hash(Object key) { int h; //高16为与低16为做异或 return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16); } //集合数组下标获取方式 if ((p = tab[i = (n - 1) \u0026amp; hash]) == null) tab[i] = newNode(hash, key, value, null); hash() 一般称之为扰动函数，可以看出hash表进行存储的时候，用的是key的hash值，理论上是32位值，但数组没那么大呀，默认也才16，所以通过数组下标获取方式的源码来看\n//所以是拿map的空间对hash掩码， tab[i = (n - 1) \u0026amp; hash] 我们可以将32位与n-1（其实刚好是掩码）做与操作，但是这样存储，会严重依赖于低位的信息，具体内容可以看HashMap中的hash函数 - 淡腾的枫 - 博客园，所以官方在与之前，先让高位和低位进行异或，增加了随机性\nputVal() 将链表转化为树\nTREEIFY_THRESHOLD=8\n//evict为false则表示处于创建中，查看调用方就只有clone，new Map(otherMap),readObject时是false final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { //数组加链表结构 Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) //调用resize初始化 n = (tab = resize()).length; //位置为空就直接塞进去，多线程的时候可能会导致值被覆盖 if ((p = tab[i = (n - 1) \u0026amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node\u0026lt;K,V\u0026gt; e; K k; //同key覆盖value if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) e = p; //如果是红黑树 else if (p instanceof TreeNode) e = ((TreeNode\u0026lt;K,V\u0026gt;)p).putTreeVal(this, tab, hash, key, value); else { //就只能是链表了 for (int binCount = 0; ; ++binCount) { //节点的next为null，表示接着往后面插入 if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); //长度达到指定值，转为树，但是在treeifyBin中如果数组长度达不到64，那么只是扩容，而不是转为树 if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } //和某个节点和hash值相同，key也相同，那就证明插过了，跳出循环，重新赋值，所以get的时候，不可能只是hash if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } //迭代器用的，记录结构修改次数，使用该值的迭代器，遍历时不能进行增删动作 ++modCount; if (++size \u0026gt; threshold) resize(); afterNodeInsertion(evict); return null; } //get节点 final Node\u0026lt;K,V\u0026gt; getNode(int hash, Object key) { Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; first, e; int n; K k; if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (first = tab[(n - 1) \u0026amp; hash]) != null) { if (first.hash == hash \u0026amp;\u0026amp; // always check first node ((k = first.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) return first; if ((e = first.next) != null) { if (first instanceof TreeNode) return ((TreeNode\u0026lt;K,V\u0026gt;)first).getTreeNode(hash, key); do { if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } putMapEntries() final void putMapEntries(Map\u0026lt;? extends K, ? extends V\u0026gt; m, boolean evict) { int s = m.size(); if (s \u0026gt; 0) { //为空的时候初始化 if (table == null) { // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft \u0026lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t \u0026gt; threshold) threshold = tableSizeFor(t); } //过小的话就需要扩容 else if (s \u0026gt; threshold) resize(); //依次插入 for (Map.Entry\u0026lt;? extends K, ? extends V\u0026gt; e : m.entrySet()) { K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); } } } resize() final Node\u0026lt;K,V\u0026gt;[] resize() { Node\u0026lt;K,V\u0026gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; //原有空间大于0，则扩大一倍 if (oldCap \u0026gt; 0) { if (oldCap \u0026gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap \u0026lt;\u0026lt; 1) \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; oldCap \u0026gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr \u0026lt;\u0026lt; 1; // double threshold } //剩下的都是初始化，指定为n，n!=0 else if (oldThr \u0026gt; 0) // initial capacity was placed in threshold newCap = oldThr; //n为0，默认初始化 else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } //修复大小 if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({\u0026#34;rawtypes\u0026#34;,\u0026#34;unchecked\u0026#34;}) Node\u0026lt;K,V\u0026gt;[] newTab = (Node\u0026lt;K,V\u0026gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { for (int j = 0; j \u0026lt; oldCap; ++j) { Node\u0026lt;K,V\u0026gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; //普通节点往数组扔，可能会移动，主要看首位是1还是0，0的话不动，1的话+newCap if (e.next == null) newTab[e.hash \u0026amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode\u0026lt;K,V\u0026gt;)e).split(this, newTab, j, oldCap); else { // preserve order //这是1.8版本优化之后的，1.7版本采用头插法，会在并发的时候导致链表成环，在get的时候就会死循环 //两个链表，一个链表用于存放还在原来桶的节点，一个链表用于放已经在扩容的桶的节点 Node\u0026lt;K,V\u0026gt; loHead = null, loTail = null; Node\u0026lt;K,V\u0026gt; hiHead = null, hiTail = null; Node\u0026lt;K,V\u0026gt; next; do { next = e.next; //将链表根据新旧桶区分，并先串起来 //参考文档 https://blog.csdn.net/Unknownfuture/article/details/105181447 //这里e.hash\u0026amp;oldCap就可以，是因为扩容前\u0026amp;的都是oldCap-1，比如oldCap为8，则\u0026amp;的为111，那么hash落入的必然是0-7，但是现在\u0026amp;的是1000，就变成了会落到0-7或者8-15中，简单的一个首位，就可以区分两个链表 if ((e.hash \u0026amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); //将两个链表的头放入桶中 if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } treeifyBin final void treeifyBin(Node\u0026lt;K,V\u0026gt;[] tab, int hash) { int n, index; Node\u0026lt;K,V\u0026gt; e; //node的总数过少，只会扩容，不会转树 if (tab == null || (n = tab.length) \u0026lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) \u0026amp; hash]) != null) { TreeNode\u0026lt;K,V\u0026gt; hd = null, tl = null;//根节点和尾结点 do { TreeNode\u0026lt;K,V\u0026gt; p = replacementTreeNode(e, null); if (tl == null) hd = p;//设置根节点 else { p.prev = tl;//互相指向 tl.next = p; } tl = p; } while ((e = e.next) != null); // 到目前为止 也只是把Node对象转换成了TreeNode对象，把单向链表转换成了双向链表 if ((tab[index] = hd) != null) hd.treeify(tab); } } LinkedHashMap Map 综述(二):彻头彻尾理解 LinkedHashMap_Rico\u0026rsquo;s Blogs-CSDN博客_linkedhashmap\n额外维护了一个双向链表，所以可以记录顺序\n//新建节点会调子类方法 Node\u0026lt;K,V\u0026gt; newNode(int hash, K key, V value, Node\u0026lt;K,V\u0026gt; e) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = new LinkedHashMap.Entry\u0026lt;K,V\u0026gt;(hash, key, value, e); linkNodeLast(p); return p; } //将当前节点加到尾结点后面 private void linkNodeLast(LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; last = tail; tail = p; if (last == null) head = p; else { p.before = last; last.after = p; } } //删除节点之后 void afterNodeRemoval(Node\u0026lt;K,V\u0026gt; e) { // unlink LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = (LinkedHashMap.Entry\u0026lt;K,V\u0026gt;)e, b = p.before, a = p.after; //删除节点后，连接前置和后驱节点 p.before = p.after = null; if (b == null) head = a; else b.after = a; if (a == null) tail = b; else a.before = b; } //在访问之后，比如是访问顺序的情况下，即accessOrder为true； void afterNodeAccess(Node\u0026lt;K,V\u0026gt; e) { // move node to last LinkedHashMap.Entry\u0026lt;K,V\u0026gt; last; if (accessOrder \u0026amp;\u0026amp; (last = tail) != e) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = (LinkedHashMap.Entry\u0026lt;K,V\u0026gt;)e, b = p.before, a = p.after; //关联e节点的前驱和后继 p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; //将e节点放到最后 if (last == null) head = p; else { p.before = last; last.after = p; } tail = p; ++modCount; } } void afterNodeInsertion(boolean evict) { // possibly remove eldest LinkedHashMap.Entry\u0026lt;K,V\u0026gt; first; //通过重写可以实现LRU算法 if (evict \u0026amp;\u0026amp; (first = head) != null \u0026amp;\u0026amp; removeEldestEntry(first)) { K key = first.key; removeNode(hash(key), key, null, false, true); } } ConcurrentHashMap volatile的数组只针对数组的引用具有volatile的语义，而不是它的元素\nputval() final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node\u0026lt;K,V\u0026gt;[] tab = table;;) { Node\u0026lt;K,V\u0026gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); //查看是否有值，没值的话通过CAS保证写入 else if ((f = tabAt(tab, i = (n - 1) \u0026amp; hash)) == null) { if (casTabAt(tab, i, null, new Node\u0026lt;K,V\u0026gt;(hash, key, value, null))) break; // no lock when adding to empty bin } //正在扩容，所以头结点的hash会为-1（MOVED），这个时候要去帮助扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { V oldVal = null; //cas也失败了，只能使用synchronized锁来 synchronized (f) { if (tabAt(tab, i) == f) { if (fh \u0026gt;= 0) { binCount = 1; for (Node\u0026lt;K,V\u0026gt; e = f;; ++binCount) { K ek; if (e.hash == hash \u0026amp;\u0026amp; ((ek = e.key) == key || (ek != null \u0026amp;\u0026amp; key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node\u0026lt;K,V\u0026gt; pred = e; if ((e = e.next) == null) { pred.next = new Node\u0026lt;K,V\u0026gt;(hash, key, value, null); break; } } } else if (f instanceof TreeBin) { Node\u0026lt;K,V\u0026gt; p; binCount = 2; if ((p = ((TreeBin\u0026lt;K,V\u0026gt;)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } } if (binCount != 0) { if (binCount \u0026gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } addCount(1L, binCount); return null; } addCount() //新增元素时，也就是在调用 putVal 方法后，为了通用，增加了个 check 入参，用于指定是否可能会出现扩容的情况 //check \u0026gt;= 0 即为可能出现扩容的情况，例如 putVal方法中的调用 private final void addCount(long x, int check){ ... ... if (check \u0026gt;= 0) { Node\u0026lt;K,V\u0026gt;[] tab, nt; int n, sc; //检查当前集合元素个数 s 是否达到扩容阈值 sizeCtl ，扩容时 sizeCtl 为负数，依旧成立，同时还得满足数组非空且数组长度不能大于允许的数组最大长度这两个条件才能继续 //这个 while 循环除了判断是否达到阈值从而进行扩容操作之外还有一个作用就是当一条线程完成自己的迁移任务后，如果集合还在扩容，则会继续循环，继续加入扩容大军，申请后面的迁移任务 while (s \u0026gt;= (long)(sc = sizeCtl) \u0026amp;\u0026amp; (tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026lt; MAXIMUM_CAPACITY) { int rs = resizeStamp(n); // sc \u0026lt; 0 说明集合正在扩容当中 if (sc \u0026lt; 0) { //判断扩容是否结束或者并发扩容线程数是否已达最大值，如果是的话直接结束while循环 if ((sc \u0026gt;\u0026gt;\u0026gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex \u0026lt;= 0) break; //扩容还未结束，并且允许扩容线程加入，此时加入扩容大军中 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); } //如果集合还未处于扩容状态中，则进入扩容方法，并首先初始化 nextTab 数组，也就是新数组 //(rs \u0026lt;\u0026lt; RESIZE_STAMP_SHIFT) + 2 为首个扩容线程所设置的特定值，后面扩容时会根据线程是否为这个值来确定是否为最后一个线程 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs \u0026lt;\u0026lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); } } helpTransfer（） final Node\u0026lt;K,V\u0026gt;[] helpTransfer(Node\u0026lt;K,V\u0026gt;[] tab, Node\u0026lt;K,V\u0026gt; f) { Node\u0026lt;K,V\u0026gt;[] nextTab; int sc; // 如果 table 不是空 且 node 节点是转移类型，数据检验 // 且 node 节点的 nextTable（新 table） 不是空，同样也是数据校验 // 尝试帮助扩容 if (tab != null \u0026amp;\u0026amp; (f instanceof ForwardingNode) \u0026amp;\u0026amp; (nextTab = ((ForwardingNode\u0026lt;K,V\u0026gt;)f).nextTable) != null) { int rs = resizeStamp(tab.length); // 如果 nextTab 没有被并发修改 且 tab 也没有被并发修改 // 且 sizeCtl \u0026lt; 0 （说明还在扩容） while (nextTab == nextTable \u0026amp;\u0026amp; table == tab \u0026amp;\u0026amp; (sc = sizeCtl) \u0026lt; 0) { if ((sc \u0026gt;\u0026gt;\u0026gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex \u0026lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) { transfer(tab, nextTab); break; } } return nextTab; } return table; } transfer() private final void transfer(Node\u0026lt;K,V\u0026gt;[] tab, Node\u0026lt;K,V\u0026gt;[] nextTab) { int n = tab.length, stride; //每个线程需要处理的桶的数量，不清楚这里为什么要除以8 if ((stride = (NCPU \u0026gt; 1) ? (n \u0026gt;\u0026gt;\u0026gt; 3) / NCPU : n) \u0026lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range if (nextTab == null) { // initiating try { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Node\u0026lt;K,V\u0026gt;[] nt = (Node\u0026lt;K,V\u0026gt;[])new Node\u0026lt;?,?\u0026gt;[n \u0026lt;\u0026lt; 1]; nextTab = nt; } catch (Throwable ex) { // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; } nextTable = nextTab; transferIndex = n; } int nextn = nextTab.length; //这里节点hash改为了MOVE ForwardingNode\u0026lt;K,V\u0026gt; fwd = new ForwardingNode\u0026lt;K,V\u0026gt;(nextTab); boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0;;) { Node\u0026lt;K,V\u0026gt; f; int fh; while (advance) { int nextIndex, nextBound; //当i没有走到bound时，表明当前都还是一批 if (--i \u0026gt;= bound || finishing) advance = false; //跳出循环，表明迁移完了，会用到下面i\u0026lt;0的条件 else if ((nextIndex = transferIndex) \u0026lt;= 0) { i = -1; advance = false; } //这里实际上是从n开始逆序分配，一次减少指定步长，然后在for循环中处理这一批 else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex \u0026gt; stride ? nextIndex - stride : 0))) { bound = nextBound; i = nextIndex - 1; advance = false; } } //i\u0026lt;0存在多种情况，比如单个线程单次干完了，再次分配的时候，发现TRANSFERINDEX还没到0，就又分到了一批，因此还得继续 //多个线程都分配了，当前线程尝试再次分配的时候，发现，i已经为-1了，这个时候，这个线程就可以撤了 if (i \u0026lt; 0 || i \u0026gt;= n || i + n \u0026gt;= nextn) { int sc; //如果全部结束，table要更新，阈值也要更新 if (finishing) { nextTable = null; table = nextTab; //1.5n=2n-0.5n，实际是0.75*2n sizeCtl = (n \u0026lt;\u0026lt; 1) - (n \u0026gt;\u0026gt;\u0026gt; 1); return; } //所以能到这里的，都是自己活干完的线程，来这里-1； if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) { if ((sc - 2) != resizeStamp(n) \u0026lt;\u0026lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit } } //这里是直接移动到新数组 else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); else if ((fh = f.hash) == MOVED) //已经被线程处理了 advance = true; // already processed else { //这里会锁节点，所以实际过程中，put和扩容会抢占，由于任意一方可能更改，如果是put则可能是新值，如果是扩容，则可能变为MOVE，因此拿到锁之后要先检查一遍是否和原来相等 synchronized (f) { if (tabAt(tab, i) == f) { Node\u0026lt;K,V\u0026gt; ln, hn; if (fh \u0026gt;= 0) { int runBit = fh \u0026amp; n; //lastRun的机制为最后一次变动的地方，这样没有变动的节点就可以直接拼在下面的ln或者hn中了 Node\u0026lt;K,V\u0026gt; lastRun = f; for (Node\u0026lt;K,V\u0026gt; p = f.next; p != null; p = p.next) { int b = p.hash \u0026amp; n; //只有和之前不一样，lastRun才会变动 if (b != runBit) { runBit = b; lastRun = p; } } if (runBit == 0) { ln = lastRun; hn = null; } else { hn = lastRun; ln = null; } //逆序构建两个链表，但是由于lastRun的存在，持有lastRun节点的链表，lastRun前面是逆序，后面是正序 for (Node\u0026lt;K,V\u0026gt; p = f; p != lastRun; p = p.next) { int ph = p.hash; K pk = p.key; V pv = p.val; //和hashmap同理 if ((ph \u0026amp; n) == 0) ln = new Node\u0026lt;K,V\u0026gt;(ph, pk, pv, ln); else hn = new Node\u0026lt;K,V\u0026gt;(ph, pk, pv, hn); } //将两个链表放到新数组的两个位置，同时标记旧数组当前节点为MOVE，虽然当前节点已经迁移成功了，但是要呼唤其他线程来帮忙 setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; } //暂不分析 else if (f instanceof TreeBin) { } } } } } } 为什么不需要锁？ 在1.8中ConcurrentHashMap的get操作全程不需要加锁，这也是它比其他并发集合比如hashtable、用Collections.synchronizedMap()包装的hashmap;安全效率高的原因之一\nget操作全程不需要加锁是因为Node的成员val是用volatile修饰的和数组用volatile修饰没有关系。\n数组用volatile修饰主要是保证在数组扩容的时候保证可见性。\nCopyOnWriteArrayList ArrayList是线程不安全的，看add方法就知道了，很有可能多个线程取到的size都是相同的，然后又同时更新了\npublic boolean add(E e) { ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; } CopyOnWrite字如其名，当存在写的时候，会先将数据复制一份出来，然后对复制的进行修改，然后将引用指过去。\n为啥这么设计呢？因为这样和读可以不冲突了，而写的时候都是通过加锁\npublic boolean add(E e) { final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; } finally { lock.unlock(); } } private E get(Object[] a, int index) { return (E) a[index]; } public E remove(int index) { final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; E oldValue = get(elements, index); int numMoved = len - index - 1; //是不是最后一个 if (numMoved == 0) setArray(Arrays.copyOf(elements, len - 1)); else { //如果不是，则先复制前半分，再复制后半份 Object[] newElements = new Object[len - 1]; System.arraycopy(elements, 0, newElements, 0, index); System.arraycopy(elements, index + 1, newElements, index, numMoved); setArray(newElements); } return oldValue; } finally { lock.unlock(); } } 参考资料 【搞定Java8新特性】之Java7/8 中的 HashMap 和 ConcurrentHashMap 全解析_Java学习-CSDN博客\n疫苗：Java HashMap的死循环 | 酷 壳 - CoolShell\n深入理解HashMap(三)resize方法解析_BodyCoding-CSDN博客_hashmap resize()\nHashMap的最大容量为什么是2的30次方(1左移30)?_与望-CSDN博客\nConcurrentHashMap1.8 - 扩容详解_concurrenthashmap1.8的扩容机制-CSDN博客\nConcurrentHashMap之transfer()扩容深入源码分析-CSDN博客\n","date":"2022-02-16T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/lang/javacollection/","title":"Java集合源码分析"},{"content":"Lock和Condition接口 Lock是java中显示使用锁的方案，相比于synchronized，要更加灵活；\nsynchronized在可重入的情况下，加锁和解锁是相反的顺序，但是Lock可以以任意的顺序解锁；\n而且synchronized必须限定在同一范围内使用，lock则可以在不同的范围；\n另外，synchronized仅限于对同一资源的独占的处理，而lock的实现机制则可以存在共享锁的存在，如ReentrantReadWriteLock。\n通常的使用如下面的代码一般，使用lock和unlock方法\nLock l = ...; l.lock(); try { // access the resource protected by this lock } finally { l.unlock(); } Condition则是一种线程间通信的方案，是对于Object的wait和notify的替代。Condition实例由Lock.newCondition产生，而且Condition的使用一般都在lock和unlock中间；\n相比于Object的wait和notify来说，condition可以更精确的控制某个线程的唤醒，只需要将condition.await置在需要挂起的线程，那么当任意线程执行condition.signal的时候，则可以精确唤醒该线程；\nLockSupport提供了两个方法park和unpark，等同于阻塞和唤醒，但是原理是park是消耗一个凭证，unpark是提供一个凭证；所以也可以先unpark，那么下次调用park就不会阻塞\nAQS AbstractQueuedSynchronizer其本质是两个队列。\n一个是同步队列，双向链表，用于存储等待获取锁的线程，状态和线程封装在NODE类中；\n一个是条件队列，单向链表，用于存储await的线程节点，通过nextWaiter连接链表；\nCLH CLH算法是一个自旋锁的算法，是对于普通的cas的优化。(Craig, Landin, and Hagersten)\n对于普通的cas来说，如果存在多个线程，那么每个线程都要在循环里尝试cas，这样会给cpu带来比较大的复合；另外有可能导致饥饿，即某个线程一直在等待，无法获取到锁。\nCLH持有一个尾结点，添加节点通过prev链接，节点有一个状态默认是true表示正在获取锁或者已经持有锁，线程通过判断前一个节点的状态什么时候变成false或者没有节点才可以获取锁\npublic class CLH { AtomicReference\u0026lt;Node\u0026gt; tail = new AtomicReference\u0026lt;\u0026gt;(); ThreadLocal\u0026lt;Node\u0026gt; cur = new ThreadLocal\u0026lt;\u0026gt;(); static class Node { Node prev; String name; volatile boolean state = true; public Node(String name) { this.name = name; } } void lock() { Node node = cur.get(); if (node == null) { node = new Node(Thread.currentThread().getName()); cur.set(node); boolean tailSet = false; while (tail.get() == null) { tailSet = tail.compareAndSet(null, node); } if (!tailSet) { node.prev = tail.getAndSet(node); // System.out.println(node.name+\u0026#34;前一个是\u0026#34;+node.prev.name); } else { // System.out.println(\u0026#34;首节点是\u0026#34;+node.name); } } do { // System.out.println(Thread.currentThread().getName() + \u0026#34;尝试获取锁\u0026#34;); } while (node.prev != null \u0026amp;\u0026amp; node.prev.state); System.out.println(Thread.currentThread().getName() + \u0026#34;获取到锁\u0026#34;); } void unlock() { System.out.println(Thread.currentThread().getName() + \u0026#34;释放锁\u0026#34;); Node node = cur.get(); node.state = false; cur.remove(); } public static void main(String[] args) { CLH clh = new CLH(); ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i \u0026lt; 10; i++) { executorService.submit(() -\u0026gt; { clh.lock(); try { Thread.sleep(1000); clh.unlock(); } catch (Exception e) { e.printStackTrace(); } }); } executorService.shutdown(); } } 同步队列 在了解同步队列运行机制前，先看一下NODE类\nstatic final class Node { //用于区分节点是共享还是独占 static final Node SHARED = new Node(); static final Node EXCLUSIVE = null; //waitStatus的四种状态，其中cancel表示节点取消（作废） static final int CANCELLED = 1; //signal用于唤醒下一个需要获取锁的线程（区别于CLH的设计） static final int SIGNAL = -1; //condition条件则是条件队里应用的，表示该节点目前是条件队里的一员 static final int CONDITION = -2; //PROPAGATE是在共享锁用到,当单个节点没有获取完锁，后续的节点可以继续获取锁 static final int PROPAGATE = -3; volatile int waitStatus; //用于处理取消的节点，将未取消的节点重新挂载在可用节点后 volatile Node prev; //用于唤醒机制，即head.next才是将要获取锁的 volatile Node next; //当前工作线程 volatile Thread thread; //用于标识当前节点在条件队列的位置 Node nextWaiter; 然后通过下图，我们了解一下aqs的机制\n没有任何线程获取锁，这个时候不存在节点，头即是尾\nThread1和Thread2通过尝试获取锁，假设Thread1获取锁成功，那么Thread2则会执行addWaiter方法，在这个方法中，初始化了head节点，通过将Thread2构造的节点作为head.next，并且作为tail；然后会执行acquireQueued方法，在这里会将Thread2.prev也就是head的waitStatus置为signal(-1)，然后会挂起当前线程；\nThread3和Thread4尝试获取锁，假设Thread4获取成功，那么Thread4会追加到Thread2，并临时作为tail；而Thread3由于在addWaiter方法中compareAndSetTail失败，所以会通过enq方法追加到Thread4后面，并作为Tail；同理，Thread2和Thread4的waitStatus都会被后一个节点设置为signal；\n这一步则是释放锁，当释放锁的时候，会判断如果head节点的waitStatus如果不等于0，然后就唤醒下一个可用的节点\u0026mdash;-Thread2，因为在acquireQueued方法开始继续执行，然后尝试获取锁，获取成功的话，就将自己设置为了head；\npublic final void acquire(int arg) { //tryAcquire是个钩子方法，由具体的实现类实现 if (!tryAcquire(arg) \u0026amp;\u0026amp; //addWaiter则是构建了一个node并且添加到队列尾部； //acquireQueued则是将当前工作线程阻塞在死循环里等待唤醒； acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; //队列有内容，则使用cas尝试追加到尾部 if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } //并发情况下cas只有一个能成功，所以需要enq来处理 enq(node); return node; } //enq负责两件事，一是初始化头，二是保证尾部追加 private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { //当前一个节点是head的时候，尝试获取锁 //两种情况，一是第一次进来的时候，有可能head刚好释放锁；另一种是从阻塞中唤醒； final Node p = node.predecessor(); if (p == head \u0026amp;\u0026amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } //shouldParkAfterFailedAcquire主要是设置node的前一个可用节点为signal if (shouldParkAfterFailedAcquire(p, node) \u0026amp;\u0026amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } public final boolean release(int arg) { //tryRelease也是钩子方法 if (tryRelease(arg)) { Node h = head; //只要head是signal，那么就要唤醒下一个可用节点 if (h != null \u0026amp;\u0026amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } 条件队列 条件队列是condition相关的队列，先来看一下aqs中的ConditionObject对象\npublic class ConditionObject implements Condition, java.io.Serializable { private static final long serialVersionUID = 1173984872572414699L; /** First node of condition queue. */ private transient Node firstWaiter; /** Last node of condition queue. */ private transient Node lastWaiter; } 可以看出ConditionObject只持有首尾，而串联起来Node的则是Node的nextWaiter字段，所以这是个单链表\n这是上面同步队列最后一步时的状态\nThread2调用await，会构建一个Thread2的condition节点（waitStatus为condition）作为firstWaiter，同时会释放Thread2已经持有的锁，唤醒Thread2.next（Thread4），因此同步队列里Thread4会变为头结点；\nThread4调用await，同Thread2一样，会新构建一个condition节点，然后→Thread2.nextWaiter指向Thread4，此时Thread4就是lastWaiter，同步队列也就只剩Thread3了\nThread2调用signal，将条件队列最靠前的可用的节点移出条件队列，重新追加到同步队列中去，将本来的tail节点状态置为signal\n//阻塞 public final void await() throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); //构建节点，追加到条件队列 Node node = addConditionWaiter(); //释放锁 int savedState = fullyRelease(node); int interruptMode = 0; //当确定不在同步队列的时候，阻塞线程；在该方法里isOnSyncQueue一定是，因为构建的节点status是condition while (!isOnSyncQueue(node)) { LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } //重新获取锁 if (acquireQueued(node, savedState) \u0026amp;\u0026amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); } private Node addConditionWaiter() { Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null \u0026amp;\u0026amp; t.waitStatus != Node.CONDITION) { unlinkCancelledWaiters(); t = lastWaiter; } //构建新节点，要么作为头，要么追加到尾 Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; } //唤醒 private void doSignal(Node first) { do { //指针循环往下指 if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; //移出条件队列 first.nextWaiter = null; } while (!transferForSignal(first) \u0026amp;\u0026amp; (first = firstWaiter) != null); } final boolean transferForSignal(Node node) { /* * If cannot change waitStatus, the node has been cancelled. */ if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; //重新加到同步队列里面 Node p = enq(node); int ws = p.waitStatus; //修改本来的tail节点的状态 //如果取消或者设置不对,立即唤醒 //但这里和同步队列唤醒机制不一样，因为线程是park在await中，而不是acquireQueue if (ws \u0026gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true; } private void doSignalAll(Node first) { lastWaiter = firstWaiter = null; //和dosignal的区别就是不作为条件，而是放在循环里了，所以是唤醒所有的条件及诶单 do { Node next = first.nextWaiter; first.nextWaiter = null; transferForSignal(first); first = next; } while (first != null); } 共享锁 主要是有个传递机制，其他没啥太大的区别，一旦有锁释放了，那么后面的就会改为传递\nprivate void doAcquireShared(int arg) { //追加节点到同步队列 final Node node = addWaiter(Node.SHARED); boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); //如果是head.next则尝试获取锁 if (p == head) { //这里锁的结果；r\u0026lt;0代表没有获取到；r=0代表获取了所有的锁； //r\u0026gt;0则代表获取完之后还有锁 int r = tryAcquireShared(arg); if (r \u0026gt;= 0) { //如果获取完之后还有锁，则继续让后面的节点获取锁 setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; } } //等同于独占锁，获取不到则设置signal，然后挂起 if (shouldParkAfterFailedAcquire(p, node) \u0026amp;\u0026amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } private void setHeadAndPropagate(Node node, int propagate) { Node h = head; // Record old head for check below setHead(node); ... //1.propagate \u0026gt; 0 意味着还有锁，则表示可以继续获取锁 //2.h==null和h==head==null是预防空指针，实际上不太可能存在 //3.h可能是新头或者旧头，但是如果waitStatus小于0，三种情况 //Cancel表示头结点取消了，那么肯定释放了锁，所以要继续获取锁 //Signal表示当前节点获取了锁（是最正常的状态），但是由于还有锁，所以可以继续往后 //PROPAGATE表示有其他线程调用了doReleaseShared，因为只有这里会将头结点设置为PROPAGATE，所以有地方调用表明释放了线程，也可以继续获取锁 if (propagate \u0026gt; 0 || h == null || h.waitStatus \u0026lt; 0 || (h = head) == null || h.waitStatus \u0026lt; 0) { Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); } } private void doReleaseShared() { for (;;) { Node h = head; //从头结点开始释放锁 if (h != null \u0026amp;\u0026amp; h != tail) { int ws = h.waitStatus; //如果头结点是signnal，那么就释放头结点的锁 if (ws == Node.SIGNAL) { if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); } //如果不是那证明别的线程可能释放了，就将后继节点改为可以获取锁，证明锁又空闲了 else if (ws == 0 \u0026amp;\u0026amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS } if (h == head) // loop if head changed break; } } ReentrantLock 本质是AQS，不过实现了公平锁和非公平锁，默认是非公平锁。\n//默认非公平 public ReentrantLock() { sync = new NonfairSync(); } lock方法不公平就体现在任何线程来了就先尝试获取锁，并且不检查是否需要排队 //NoFair final void lock() { acquire(1); } //Fair final void lock() { if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); } protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { //必须得是head.next才能尝试获取锁，所以保证了公平 if (!hasQueuedPredecessors() \u0026amp;\u0026amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc \u0026lt; 0) throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;); setState(nextc); return true; } return false; } final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc \u0026lt; 0) // overflow throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;); setState(nextc); return true; } return false; } ReentrantReadWriteLock 读写锁的设计是将int分为高低16位，高16为读锁，低16位为写锁。\n如果是\n00000000 0000010 00000000 00000010\n说明当前线程获得两次读锁，两次写锁\nstatic final int SHARED_SHIFT = 16; //65536,其实就是高位1 static final int SHARED_UNIT = (1 \u0026lt;\u0026lt; SHARED_SHIFT); //65535 0（16）1（16） static final int MAX_COUNT = (1 \u0026lt;\u0026lt; SHARED_SHIFT) - 1; static final int EXCLUSIVE_MASK = (1 \u0026lt;\u0026lt; SHARED_SHIFT) - 1; /** 无符号右移16位，即只要高16位 */ static int sharedCount(int c) { return c \u0026gt;\u0026gt;\u0026gt; SHARED_SHIFT; } /** 与上0000000000000000 1111111111111111，即只要低16位 */ static int exclusiveCount(int c) { return c \u0026amp; EXCLUSIVE_MASK; } 相比于ReentrantLock多了两个内部类\nReadLock和WriteLock\n//当前线程持有写锁，其他线程都不能持有写锁，但是当前线程还可以持有读锁\n//当前线程持有读锁，其他线程也可以获取读锁\n//写锁仍然是独占 public void lock() { sync.acquire(1); } //写锁的lock final boolean tryWriteLock() { Thread current = Thread.currentThread(); int c = getState(); if (c != 0) { int w = exclusiveCount(c); //如果c不为0，但是w为0，则表明当前存在读锁（即共享锁），存在读锁时，任何线程无法获取写锁 if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w == MAX_COUNT) throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;); } if (!compareAndSetState(c, c + 1)) return false; setExclusiveOwnerThread(current); return true; } //写锁的释放 //由于写锁是低16位，所以直接做减法就可以了 protected final boolean tryRelease(int releases) { if (!isHeldExclusively()) throw new IllegalMonitorStateException(); int nextc = getState() - releases; boolean free = exclusiveCount(nextc) == 0; if (free) setExclusiveOwnerThread(null); setState(nextc); return free; } //读锁是共享锁 public void lock() { sync.acquireShared(1); } //共享锁获取 protected final int tryAcquireShared(int unused) { Thread current = Thread.currentThread(); int c = getState(); //如果有独占锁，且不是当前线程，则不能获取共享锁； if (exclusiveCount(c) != 0 \u0026amp;\u0026amp; getExclusiveOwnerThread() != current) return -1; //获取目前的共享锁 int r = sharedCount(c); if (!readerShouldBlock() \u0026amp;\u0026amp; r \u0026lt; MAX_COUNT \u0026amp;\u0026amp; //原有的锁加上高位1 compareAndSetState(c, c + SHARED_UNIT)) { //下面的部分主要是记录哪些线程获取了几次锁 if (r == 0) { firstReader = current; firstReaderHoldCount = 1; } else if (firstReader == current) { firstReaderHoldCount++; } else { HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; } return 1; } return fullTryAcquireShared(current); } protected final boolean tryAcquire(int acquires) { /* * Walkthrough: * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c); if (c != 0) { // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) \u0026gt; MAX_COUNT) throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;); // Reentrant acquire setState(c + acquires); return true; } if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true; } //共享锁释放 protected final boolean tryReleaseShared(int unused) { Thread current = Thread.currentThread(); //减少线程持有的锁的数量 if (firstReader == current) { // assert firstReaderHoldCount \u0026gt; 0; if (firstReaderHoldCount == 1) firstReader = null; else firstReaderHoldCount--; } else { HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); int count = rh.count; if (count \u0026lt;= 1) { readHolds.remove(); if (count \u0026lt;= 0) throw unmatchedUnlockException(); } --rh.count; } //减少真正的锁的数量 for (;;) { int c = getState(); //现有锁减去高位1 int nextc = c - SHARED_UNIT; if (compareAndSetState(c, nextc)) // Releasing the read lock has no effect on readers, // but it may allow waiting writers to proceed if // both read and write locks are now free. return nextc == 0; } } 参考文档: AQS深入理解 shouldParkAfterFailedAcquire源码分析 状态为0或PROPAGATE的情况分析-CSDN博客\nAQS基础——多图详解CLH锁的原理与实现\nJava AQS 核心数据结构-CLH 锁\nAQS深入理解 setHeadAndPropagate源码分析 JDK8-CSDN博客\n","date":"2022-02-14T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/lang/javalock/","title":"JavaLock类源码分析"}]