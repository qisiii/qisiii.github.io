[{"content":"hugo官网|Stack官网\nURL： slug: 一个正常的网址格式是下面这样的，其中路径的最后一段就是slug。\n1 \u0026lt;协议\u0026gt;://\u0026lt;主机名\u0026gt;/\u0026lt;路径\u0026gt;/\u0026lt;文件slug\u0026gt;?\u0026lt;查询字符串\u0026gt;#\u0026lt;片段\u0026gt;` 据说简短清晰的slug有助于SEO，但哪怕没有这个功能，我们的文件名很多时候也是中文的，经过编码后可读性太差。因此，设置一个简短的slug是很有必要的。\n建议在模板文件archetypes/default.md直接新增slug字段，这样就不用每个文件手动添加了\n1 2 3 4 5 6 7 8 +++ title = \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; description = \u0026#34;\u0026#34; date = {{ .Date }} image = \u0026#34;\u0026#34; draft = true slug = \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; +++ permalinks: 如果只设置slug，stack主题配置默认路径是 域名/p/slug这样子，其实对于文件的组织管理和展示路径依然不是很明朗，因此，我这里是以文件夹层级的方式生成路径。\n在总配置中，修改或者新增\n1 2 permalinks: post: /:sections/:slug 这里的:sections是指多个路径，但是hugo默认处理顶级目录会自动识别为section外，其他目录需要手动添加_index.md文件才行。\n评论： hugo支持许多评论框架，具体可以看hugo-comments|Comments | Stack，我选择的是\nTwikoo 建议跟着快速上手 | Twikoo 文档去部署一遍，我这里选用的是Hugging Face免费部署的方案。\n部署主要有两部分：一部分是生成一个mogodb的密钥串，二部分则是在hugging face上新建空间和项目，最终获得envId\n然后修改站点配置文件\n1 2 3 4 5 6 7 8 comments: enabled: true provider: twikoo twikoo: envId: https://你的项目空间.hf.space region: path: lang: 小部件： Widgets | Stack\n1 2 3 4 5 6 7 8 9 10 11 12 widgets: homepage: - type: search - type: archives params: limit: 5 - type: categories params: limit: 10 - type: tag-cloud params: limit: 10 在stack的配置文件中，搜索工具、归档工具、分类和标签都是启用的。但是启用并不代表默认会出现，依然需要各种地方指定了值才能出现。\n分类\u0026amp;标签 在你的内容文件的front matter中，需要指定tag的值和categories的值，我这里的front matter是toml格式\n1 2 tag = [\u0026#39;hugo\u0026#39;,\u0026#39;stack\u0026#39;] categories = [\u0026#34;个人网站\u0026#34;] 归档： 需要在content/post目录下新建archives.md，内容如下，不需要任何正文内容\n1 2 3 4 5 6 +++ title = \u0026#39;Archives\u0026#39; layout = \u0026#34;archives\u0026#34; hidden = true comments = false +++ layout是指定为分类样式，hidden表示该文件不会被展示出来，comments表示评论区关闭.\n其次，需要在 项目/layouts/_default 或者 主题/layouts/_default下存在archives.html，由于stack主题下默认就有这个文件，所以正常来说添加了archives.md就可以使用归档功能了。\n搜索: 增加search.md 首先是同归档类似，需要在content/post目录下新建search.md，内容如下，不需要任何正文内容\n1 2 3 4 5 6 +++ title = \u0026#34;search\u0026#34; layout = \u0026#34;search\u0026#34; hidden = true comments = false +++ 增加搜索引擎的文件 静态网站的搜索本质上是将你的文档进行分词汇总到一个json文件，实际搜索的时候就是在搜索这个json文件。比较常用的是fuse.js,lunr.js或者主题自己封装的搜索能力。\nstack主题\n增加search.html和search.json\n需要在 项目/layouts/_default 或者 主题/layouts/_default 存在两个文件（对于stack来说），分别是search.html和search.json。\n在我clone的stack版本中，这两个文件在_default并不存在，但是在/layouts/page下面是有的，所以从cp layouts/page/* layouts/_default\n成功的话，会在public/post/search目录下生成index.html index.json两个文件，主要是index.json文件\nfuse\n我有看过两个文章是使用fuse的，但是我自己都没有实验成功，加上对hugo的模板还不熟，先不折腾了。\n给hugo添加搜索功能 | 搜百谷\nhttps://ttys3.dev/blog/hugo-fast-search\nDocsy主题\n可以参考官方文档Search | Docsy\n修改总配置hugo.yaml 1 2 3 4 5 6 7 outputs: home: - HTML - JSON page: - HTML - JSON 这里home和page两种kind都配置的原因是:\n假如你没有修改过总配置中的permalinks，那么你的博客的路径应该是 域名/p/文章名，这种情况下kind对应的是home类型\n但是假如你像我一下修改了permalinks，比如我改成了 post: /:sections/:slug，这个是为了让我的博客地址以路径+文件名来显示，但是由于有了层级关系，里面的博客文章的kind就变成了page，因此在配置的时候，将home和page两个都指定是最好的\n说实话，我其实还是不能理解这个kind的设计~\n参考文档: Hugo 归档页面制作 - Cory\n","date":"2024-08-10T16:32:55+08:00","image":"https://raw.githubusercontent.com/qisiii/imagehost/main/2024/08/11-00-35-18-image.png","permalink":"https://qisiii.github.io/post/site/hugo_stack_record/","title":"Hugo\u0026Stack主题的使用记录"},{"content":"调试前准备 对于大部分的开源项目，一般都可以从其启动shell脚本中分析出来java启动类。我这里clone源码后以tag 3.9.1为主创建了一个分支，方便注释，调试。\n在bin/zkServer.sh脚本中，其启动逻辑如下，如果是执行的./zkServer.sh start的话，最终执行的命令大概是\nnohup java [一堆参数] org.apache.zookeeper.server.quorum.QuorumPeerMain [输出日志],ZOOMAIN变量可以往上溯源，四个出现的地方最终都是QuorumPeerMain类。因此QuorumPeerMain类就是zookeeper的启动类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 case $1 in start) echo -n \u0026#34;Starting zookeeper ... \u0026#34; if [ -f \u0026#34;$ZOOPIDFILE\u0026#34; ]; then if kill -0 `cat \u0026#34;$ZOOPIDFILE\u0026#34;` \u0026gt; /dev/null 2\u0026gt;\u0026amp;1; then echo $command already running as process `cat \u0026#34;$ZOOPIDFILE\u0026#34;`. exit 1 fi fi nohup \u0026#34;$JAVA\u0026#34; $ZOO_DATADIR_AUTOCREATE \u0026#34;-Dzookeeper.log.dir=${ZOO_LOG_DIR}\u0026#34; \\ \u0026#34;-Dzookeeper.log.file=${ZOO_LOG_FILE}\u0026#34; \\ -XX:+HeapDumpOnOutOfMemoryError -XX:OnOutOfMemoryError=\u0026#39;kill -9 %p\u0026#39; \\ # $ZOOMAIN= org.apache.zookeeper.server.quorum.QuorumPeerMain -cp \u0026#34;$CLASSPATH\u0026#34; $JVMFLAGS $ZOOMAIN \u0026#34;$ZOOCFG\u0026#34; \u0026gt; \u0026#34;$_ZOO_DAEMON_OUT\u0026#34; 2\u0026gt;\u0026amp;1 \u0026lt; /dev/null \u0026amp; 知道启动类之后，就要进入debug模式进行调试，这里有两个点需要注意：\n设置启动参数\n由于shell脚本通过命令行模式执行的时候拼接了非常多的参数，虽然大部分参数都可以忽略，但是config参数确是必须的，即ZOOMAIN 后的 \u0026ldquo;ZOOCFG\u0026rdquo;。因此在通过idea等编辑器进行debug的时候，要设置program arguments为zk的配置文件(这里的zoo.cfg是复制的zoo_sample.cfg)\n启动时报类找不到，编译失败\n这是由于在pom文件中，有部分依赖的scope是provider类型，即zk项目本身不提供，由依赖方提供。我这里为了省事，将zookeeper-server的pom.xml里所有\u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt;都够注释掉了\n当涉及到客户端和服务端通信时，建议session过期时间设置的长一些，不然在debug的时候总是会session过期，连接关闭\n但是由于有最大限制，因此建议临时注释掉最大限制的逻辑\n源码分析 QuorumPeerMain QuorumPeerMain类的逻辑相对简单，需要注意的是集群和单机两种模式走的是不同的逻辑。下面我会先分析单机模式熟悉结构后，再去看集群模式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public static void main(String[] args) { QuorumPeerMain main = new QuorumPeerMain(); try { main.initializeAndRun(args); } protected void initializeAndRun(String[] args) throws ConfigException, IOException, AdminServerException { //args[0]一般是zk的配置文件zoo.cfg,即这里将配置文件转换为javaBean QuorumPeerConfig config = new QuorumPeerConfig(); if (args.length == 1) { config.parse(args[0]); } // Start and schedule the the purge task //通过定时执行PurgeTask来清楚data数据和datalog数据 DatadirCleanupManager purgeMgr = new DatadirCleanupManager( config.getDataDir(), config.getDataLogDir(), config.getSnapRetainCount(), config.getPurgeInterval()); purgeMgr.start(); // 集群和单机两种方式 if (args.length == 1 \u0026amp;\u0026amp; config.isDistributed()) { runFromConfig(config); } else { LOG.warn(\u0026#34;Either no config or no quorum defined in config, running in standalone mode\u0026#34;); // there is only server in the quorum -- run as standalone //单机模式 ZooKeeperServerMain.main(args); } } ZooKeeperServerMain 单机版的组件主要如上图所示。\nAdminServer: zk通过jetty简单实现了一个后端admin，可通过http://localhost:8080/commands去进行一些操作。\nMetricsProvider：用于记录、监控一些指标，本文不做分析\nJvmPauseMonitor: 来源于hadoop的一个监控，有个线程一直死循环，当判断系统暂停时间大于一定指标，打印一条信息\nJMX: java所提供的jmx\nQuorumPeerConfig: 读取的是zoo.cfg，服务于zk集群模式\nServerConfig: 读取的也是zoo.cfg，但是仅限于zk单机模式，且主要服务于通信组件\n启动入口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 final ZooKeeperServer zkServer = new ZooKeeperServer(jvmPauseMonitor, txnLog, config.tickTime, config.minSessionTimeout, config.maxSessionTimeout, config.listenBacklog, null, config.initialConfig); boolean needStartZKServer = true; if (config.getClientPortAddress() != null) { cnxnFactory = ServerCnxnFactory.createFactory();//默认是NIOServerCnxnFactory cnxnFactory.configure(config.getClientPortAddress(), config.getMaxClientCnxns(), config.getClientPortListenBacklog(), false); //启动入口 cnxnFactory.startup(zkServer); // zkServer has been started. So we don\u0026#39;t need to start it again in secureCnxnFactory. needStartZKServer = false; } public void startup(ZooKeeperServer zks, boolean startServer) throws IOException, InterruptedException { //启动socket相关的线程 start(); setZooKeeperServer(zks); if (startServer) { //启动zkDataBase zks.startdata(); //启动其他组件（限流、processor、session、jmx等） zks.startup(); } } 通信流程 ServerCnxnFactory 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public void start() { stopped = false; if (workerPool == null) { workerPool = new WorkerService(\u0026#34;NIOWorker\u0026#34;, numWorkerThreads, false); } for (SelectorThread thread : selectorThreads) { if (thread.getState() == Thread.State.NEW) { thread.start(); } } // ensure thread is started once and only once if (acceptThread.getState() == Thread.State.NEW) { acceptThread.start(); } if (expirerThread.getState() == Thread.State.NEW) { expirerThread.start(); } } ServerCnxnFactory主要负责socket相关的部分，从start方法可以看出，zk的serverSocket设计为了四种线程，acceptThread来监听accept事件，selectorThread监听读写io，workerPool负责处理IO，expirerThread负责处理过期的连接。\nAcceptThread AcceptThread只处理accept事件，且通过队列进行解耦。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 private boolean doAccept() { boolean accepted = false; SocketChannel sc = null; try { //获取到socketChannel sc = acceptSocket.accept(); accepted = true; //中间会校验一下是否达到最大连接 sc.configureBlocking(false); //建立连接后分配给selector线程，轮询分配 // Round-robin assign this connection to a selector thread if (!selectorIterator.hasNext()) { selectorIterator = selectorThreads.iterator(); } SelectorThread selectorThread = selectorIterator.next(); //将新accept的socket传递给selector if (!selectorThread.addAcceptedConnection(sc)) { throw new IOException(\u0026#34;Unable to add connection to selector queue\u0026#34; + (stopped ? \u0026#34; (shutdown in progress)\u0026#34; : \u0026#34;\u0026#34;)); } acceptErrorLogger.flush(); } return accepted; } } public boolean addAcceptedConnection(SocketChannel accepted) { //将socket放入acceptedQueue，在selectorThread进行处理 if (stopped || !acceptedQueue.offer(accepted)) { return false; } //唤醒阻塞在selectorThread上的select方法 wakeupSelector(); return true; } SelectorThread 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 public void run() { try { while (!stopped) { try { //处理读写IO事件 select(); //新accept的socket注册read事件 processAcceptedConnections(); //暂时没理解透下面这个方法 processInterestOpsUpdateRequests(); } }}} private void select() { try { //当收到accept事件或者由wakeupSelector()唤醒selector，下面的循环可能有事件，也可能没有事件，有事件优先处理，没有的话跳出select方法，去给新accept的socket注册read事件 selector.select(); Set\u0026lt;SelectionKey\u0026gt; selected = selector.selectedKeys(); ArrayList\u0026lt;SelectionKey\u0026gt; selectedList = new ArrayList\u0026lt;\u0026gt;(selected); Collections.shuffle(selectedList); Iterator\u0026lt;SelectionKey\u0026gt; selectedKeys = selectedList.iterator(); while (!stopped \u0026amp;\u0026amp; selectedKeys.hasNext()) { SelectionKey key = selectedKeys.next(); selected.remove(key); if (!key.isValid()) { cleanupSelectionKey(key); continue; } if (key.isReadable() || key.isWritable()) { //处理IO，其实是将key包装为request扔到workerpool handleIO(key); } else { LOG.warn(\u0026#34;Unexpected ops in select {}\u0026#34;, key.readyOps()); } } } private void processAcceptedConnections() { SocketChannel accepted; while (!stopped \u0026amp;\u0026amp; (accepted = acceptedQueue.poll()) != null) { SelectionKey key = null; try { //当前socket注册read事件 key = accepted.register(selector, SelectionKey.OP_READ); //根据socketChannel创建连接 NIOServerCnxn cnxn = createConnection(accepted, key, this); //这里key持有了cnxn，这样在处理io的时候才能获取到对应对象 key.attach(cnxn); addCnxn(cnxn); } catch (IOException e) { // register, createConnection cleanupSelectionKey(key); fastCloseSock(accepted); } } } expirerThread 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public void run() { try { while (!stopped) { long waitTime = cnxnExpiryQueue.getWaitTime(); if (waitTime \u0026gt; 0) { Thread.sleep(waitTime); continue; } //关闭过期的链接 for (NIOServerCnxn conn : cnxnExpiryQueue.poll()) { ServerMetrics.getMetrics().SESSIONLESS_CONNECTIONS_EXPIRED.add(1); conn.close(ServerCnxn.DisconnectReason.CONNECTION_EXPIRED); } } } catch (InterruptedException e) { LOG.info(\u0026#34;ConnnectionExpirerThread interrupted\u0026#34;); } } expirer线程的run逻辑是很简单的，就是从一个队列取出过期的连接，并进行关闭。程序会通过touchCnxn方法，来延长连接的过期时间。touchCnxn方法在创建连接，处理IO事件的前后都会调用。\n由于连接和session的过期机制都是一样的，所以这里先不分析cnxnExpiryQueue.poll和cnxnExpiryQueue.update方法，在下面讲到sessionTrack的时候进行分析\n1 2 3 public void touchCnxn(NIOServerCnxn cnxn) { cnxnExpiryQueue.update(cnxn, cnxn.getSessionTimeout()); } workPool worker线程的核心任务，是将socket中的数据读取并封装为request，然后交由processor去处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 void doIO(SelectionKey k) throws InterruptedException { try { //前4个字节用来记录长度 if (k.isReadable()) { //将消息长度写到incomingBuffer，返回值小于0表示没有读到消息长度 int rc = sock.read(incomingBuffer); if (rc \u0026lt; 0) { handleFailedRead(); } //正常来讲，消息长度占4个字节，所以此时limit==position if (incomingBuffer.remaining() == 0) { boolean isPayload; //这里没有特别理解，incomingBuffer什么情况下才会不等于呢？？ if (incomingBuffer == lenBuffer) { // start of next request //变成读模式，会在readLength读到incomingBuffer写入的数据（即长度） incomingBuffer.flip(); //incomingBuffer在这里会重新分配 isPayload = readLength(k); incomingBuffer.clear(); } else { // continuation isPayload = true; } if (isPayload) { // not the case for 4letterword //读取具体的数据 readPayload(); } else { // four letter words take care // need not do anything else return; } } } private boolean readLength(SelectionKey k) throws IOException { // Read the length, now get the buffer //获取到数据长度 int len = lenBuffer.getInt(); zkServer.checkRequestSizeWhenReceivingMessage(len); //重新分配长度 incomingBuffer = ByteBuffer.allocate(len); return true; } private void readPayload() throws IOException, InterruptedException, ClientCnxnLimitException { //刚分配了新的空间，所以这里一定不等于0，因此可以将socket剩余信息写到incomingBuffer if (incomingBuffer.remaining() != 0) { // have we read length bytes? int rc = sock.read(incomingBuffer); // sock is non-blocking, so ok if (rc \u0026lt; 0) { handleFailedRead(); } } //incomingBuffer已经写完数据了，所以下面就是flip后再读数据了 if (incomingBuffer.remaining() == 0) { // have we read length bytes? incomingBuffer.flip(); packetReceived(4 + incomingBuffer.remaining()); if (!initialized) { //只在这里面会将initialized设置为true，所以第一次建立连接一定会走进来 readConnectRequest(); } else { readRequest(); } lenBuffer.clear(); incomingBuffer = lenBuffer; } } 当建立连接后第一次处理io会走到readConnectRequest方法，这个方法封装的是ConnectRequest，由processConnectRequest进行处理\n1 2 3 BinaryInputArchive bia = BinaryInputArchive.getArchive(new ByteBufferInputStream(incomingBuffer)); ConnectRequest request = protocolManager.deserializeConnectRequest(bia); zkServer.processConnectRequest(this, request); 其他时候会走到readRequest，封装的是普通的RequestRecord，由processPacket进行处理\n1 2 3 4 RequestHeader h = new RequestHeader(); ByteBufferInputStream.byteBuffer2Record(incomingBuffer, h); RequestRecord request = RequestRecord.fromBytes(incomingBuffer.slice()); zkServer.processPacket(this, h, request); processConnectRequest最核心的工作就是创建了session，并封装了个createSession的request进行处理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 if (sessionId == 0) { long id = createSession(cnxn, passwd, sessionTimeout); long createSession(ServerCnxn cnxn, byte[] passwd, int timeout) { if (passwd == null) { // Possible since it\u0026#39;s just deserialized from a packet on the wire. passwd = new byte[0]; } long sessionId = sessionTracker.createSession(timeout); Random r = new Random(sessionId ^ superSecret); r.nextBytes(passwd); CreateSessionTxn txn = new CreateSessionTxn(timeout); cnxn.setSessionId(sessionId); Request si = new Request(cnxn, sessionId, 0, OpCode.createSession, RequestRecord.fromRecord(txn), null); submitRequest(si);//所以首次创建session最终还是会走到submitRequest return sessionId; } processPacket的工作则是进行认证校验和request转发\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public void processPacket(ServerCnxn cnxn, RequestHeader h, RequestRecord request) throws IOException { //除了校验之外则是正常的请求转发 if (h.getType() == OpCode.auth) { ... } else if (h.getType() == OpCode.sasl) { ... } else { if (!authHelper.enforceAuthentication(cnxn, h.getXid())) { // Authentication enforcement is failed // Already sent response to user about failure and closed the session, lets return return; } else { Request si = new Request(cnxn, cnxn.getSessionId(), h.getXid(), h.getType(), request, cnxn.getAuthInfo()); int length = request.limit(); if (isLargeRequest(length)) { // checkRequestSize will throw IOException if request is rejected checkRequestSizeWhenMessageReceived(length); si.setLargeRequestSize(length); } si.setOwner(ServerCnxn.me); //正常的请求则会从这里进去 submitRequest(si); } } } 至此，我们发现都会走到submitRequest方法，而这个方法的逻辑则是将request扔到节流器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public void submitRequest(Request si) { if (restoreLatch != null) { try { LOG.info(\u0026#34;Blocking request submission while restore is in progress\u0026#34;); restoreLatch.await(); } catch (final InterruptedException e) { LOG.warn(\u0026#34;Unexpected interruption\u0026#34;, e); } } enqueueRequest(si);//会将request扔到throttler的submittedRequests } public void enqueueRequest(Request si) { if (requestThrottler == null) { synchronized (this) { try { // Since all requests are passed to the request // processor it should wait for setting up the request // processor chain. The state will be updated to RUNNING // after the setup. while (state == State.INITIAL) { wait(1000); } } catch (InterruptedException e) { LOG.warn(\u0026#34;Unexpected interruption\u0026#34;, e); } if (requestThrottler == null) { throw new RuntimeException(\u0026#34;Not started\u0026#34;); } } } requestThrottler.submitRequest(si); } RequestThrottler throttler的创建和启动是在startupWithServerState方法中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 private void startupWithServerState(State state) { if (sessionTracker == null) { createSessionTracker(); } //用于管理每个链接的session startSessionTracker(); //以单链表的方式串起来processor setupRequestProcessors(); //节流器，所有的request都会先过一遍这个 startRequestThrottler(); } protected void startRequestThrottler() { requestThrottler = createRequestThrottler(); requestThrottler.start(); } 上面讲到所有的请求都执行了requestThrottler.submitRequest,这个操作实际是将请求放入了submittedRequests队列中，requestThrottler作为一个线程，循环取出队列中的请求并判断是否做限流。\n下面的代码主要有两个逻辑：\n一是当正在执行的请求数量达到上限时，要一直阻塞到数量小于maxRequests\n二是假如请求在队列里等待的时间大于throttled_op_wait_time，标记为已限流，后面的Processor处理时会抛异常。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 public void run() { try { while (true) { if (killed) { break; } //从队列取出一个请求 Request request = submittedRequests.take(); if (Request.requestOfDeath == request) { break; } if (request.mustDrop()) { continue; } // Throttling is disabled when maxRequests = 0 if (maxRequests \u0026gt; 0) { while (!killed) { //一直都没有处理，导致连接都关闭了，或者session超时了，丢掉请求 if (dropStaleRequests \u0026amp;\u0026amp; request.isStale()) { // Note: this will close the connection dropRequest(request); ServerMetrics.getMetrics().STALE_REQUESTS_DROPPED.add(1); request = null; break; } //没达到上限时跳出循环 if (zks.getInProcess() \u0026lt; maxRequests) { break; } //达到上限了的话，等待stallTime这么在重新进循环，避免过多执行循环 throttleSleep(stallTime); } } if (killed) { break; } // A dropped stale request will be null if (request != null) { if (request.isStale()) { ServerMetrics.getMetrics().STALE_REQUESTS.add(1); } final long elapsedTime = Time.currentElapsedTime() - request.requestThrottleQueueTime; ServerMetrics.getMetrics().REQUEST_THROTTLE_QUEUE_TIME.add(elapsedTime); //当在队列等待时间过长，大于限流等待时间时，会将请求标志位已限流；已限流的请求在finalRequestProcessor中会抛异常Code.THROTTLEDOP if (shouldThrottleOp(request, elapsedTime)) { request.setIsThrottled(true); ServerMetrics.getMetrics().THROTTLED_OPS.add(1); } //交由Processor去处理 zks.submitRequestNow(request); } } } 假如没有被限流的话，执行到zks.submitRequestNow(request);后就将request交给processor处理了\nRequestProcessor zookeeper中将Processor分为了三个Processor，其启动是在setupRequestProcessors方法中，以链表的形式串起了三个processor，以PrepRequestProcessor为head，FinalRequestProcessor为tail。\n1 2 3 4 5 6 7 8 9 10 11 12 protected void setupRequestProcessors() { RequestProcessor finalProcessor = new FinalRequestProcessor(this); RequestProcessor syncProcessor = new SyncRequestProcessor(this, finalProcessor); ((SyncRequestProcessor) syncProcessor).start(); firstProcessor = new PrepRequestProcessor(this, syncProcessor); ((PrepRequestProcessor) firstProcessor).start(); } public PrepRequestProcessor(ZooKeeperServer zks, RequestProcessor nextProcessor) { this.nextProcessor = nextProcessor; public SyncRequestProcessor(ZooKeeperServer zks, RequestProcessor nextProcessor) { this.zks = zks; this.nextProcessor = nextProcessor; PrepRequestProcessor PrepRequestProcessor的主要工作就是校验和创建事务。\n当调用processRequest时，也是通过队列解耦了一下，通过线程去异步执行，核心方法就是pRequestHelper\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public void processRequest(Request request) { request.prepQueueStartTime = Time.currentElapsedTime(); submittedRequests.add(request); ServerMetrics.getMetrics().PREP_PROCESSOR_QUEUED.add(1); } public void run() { LOG.info(String.format(\u0026#34;PrepRequestProcessor (sid:%d) started, reconfigEnabled=%s\u0026#34;, zks.getServerId(), zks.reconfigEnabled)); try { while (true) { Request request = submittedRequests.take(); ...不重要的逻辑 pRequest(request); } } protected void pRequest(Request request) throws RequestProcessorException { request.setHdr(null); request.setTxn(null); //正常情况下request的isThrottled应该是false，所以会执行pRequestHelper if (!request.isThrottled()) { //一些前置的校验，事务的创建等 pRequestHelper(request); } //获取事务ID， request.zxid = zks.getZxid(); long timeFinishedPrepare = Time.currentElapsedTime(); ServerMetrics.getMetrics().PREP_PROCESS_TIME.add(timeFinishedPrepare - request.prepStartTime); //由syncRequestProcessor执行 nextProcessor.processRequest(request); ServerMetrics.getMetrics().PROPOSAL_PROCESS_TIME.add(Time.currentElapsedTime() - timeFinishedPrepare); } pRequestHelper方法里根据不同的OpCode有各自的处理方法，但是总共依旧可以区分为两大类：需要创建事务和不需要创建事务\n不需要创建事务的如下，就只执行checkSession方法，就是校验一下session是否正常\n而需要创建事务的逻辑则也差不多，大多数都是封装为一个Request对象，然后执行pRequest2Txn方法\npRequest2Txn方法的主要逻辑则是校验request、校验Acl权限、校验路径、校验[quota](Zookeeper笔记之quota - CC11001100 - 博客园)、创建事务和创建事务摘要\n1 2 3 4 5 6 7 8 9 10 11 12 //校验request validateCreateRequest(path, createMode, request, ttl); //acl权限校验 zks.checkACL(request.cnxn, parentRecord.acl, ZooDefs.Perms.CREATE, request.authInfo, path, listACL); //校验路径名称合规 validatePath(path, request.sessionId); //校验节点数和字节数 zks.checkQuota(path, null, data, OpCode.create); //创建事务 request.setTxn(new CreateTxn(path, data, listACL, createMode.isEphemeral(), newCversion)); //事务摘要 setTxnDigest(request, nodeRecord.precalculatedDigest); SyncRequestProcessor SyncRequestProcessor主要有两个操作，一个是写事务，一个是生成快照。\n对于非事务操作，这个processor是没有意义的；只有事务操作，才会进行日志的持久化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 public void run() { try { // we do this in an attempt to ensure that not all of the servers // in the ensemble take a snapshot at the same time resetSnapshotStats(); lastFlushTime = Time.currentElapsedTime(); while (true) { ServerMetrics.getMetrics().SYNC_PROCESSOR_QUEUE_SIZE.add(queuedRequests.size()); long pollTime = Math.min(zks.getMaxWriteQueuePollTime(), getRemainingDelay()); //之所有先poll一次是为了当queuedRequests队列为null的时候，期望可以触发一下flush Request si = queuedRequests.poll(pollTime, TimeUnit.MILLISECONDS); if (si == null) { /* We timed out looking for more writes to batch, go ahead and flush immediately */ flush(); si = queuedRequests.take(); } if (si == REQUEST_OF_DEATH) { break; } long startProcessTime = Time.currentElapsedTime(); ServerMetrics.getMetrics().SYNC_PROCESSOR_QUEUE_TIME.add(startProcessTime - si.syncQueueStartTime); // 普通的查询都没有事务，所以都会返回false；append这里只是写到了流里，还需要在commit方法中调用flush才会落盘 if (!si.isThrottled() \u0026amp;\u0026amp; zks.getZKDatabase().append(si)) { if (shouldSnapshot()) { resetSnapshotStats(); // roll the log zks.getZKDatabase().rollLog(); // take a snapshot if (!snapThreadMutex.tryAcquire()) { LOG.warn(\u0026#34;Too busy to snap, skipping\u0026#34;); } else { new ZooKeeperThread(\u0026#34;Snapshot Thread\u0026#34;) { public void run() { try { zks.takeSnapshot(); } catch (Exception e) { LOG.warn(\u0026#34;Unexpected exception\u0026#34;, e); } finally { snapThreadMutex.release(); } } }.start(); } } } else if (toFlush.isEmpty()) { // optimization for read heavy workloads // iff this is a read or a throttled request(which doesn\u0026#39;t need to be written to the disk), // and there are no pending flushes (writes), then just pass this to the next processor //当没有需要flush的内容，直接调用下一个processor处理；但假如toFlush队列有内容，就只能排队处理了 if (nextProcessor != null) { nextProcessor.processRequest(si); if (nextProcessor instanceof Flushable) { ((Flushable) nextProcessor).flush(); } } continue; } //排队处理 toFlush.add(si); if (shouldFlush()) { flush(); } ServerMetrics.getMetrics().SYNC_PROCESS_TIME.add(Time.currentElapsedTime() - startProcessTime); } } catch (Throwable t) { handleException(this.getName(), t); } LOG.info(\u0026#34;SyncRequestProcessor exited!\u0026#34;); } 关于写事务的方法是append和flush\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 public synchronized boolean append(Request request) throws IOException { TxnHeader hdr = request.getHdr(); //普通的查询都没有事务，所以都会返回false if (hdr == null) { return false; } ... //当logStream == null时会新创建文件，首次创建或者文件达到上限新创建 if (logStream == null) { LOG.info(\u0026#34;Creating new log file: {}\u0026#34;, Util.makeLogName(hdr.getZxid())); logFileWrite = new File(logDir, Util.makeLogName(hdr.getZxid())); fos = new FileOutputStream(logFileWrite); logStream = new BufferedOutputStream(fos); oa = BinaryOutputArchive.getArchive(logStream); FileHeader fhdr = new FileHeader(TXNLOG_MAGIC, VERSION, dbId); long dataSize = oa.getDataSize(); fhdr.serialize(oa, \u0026#34;fileheader\u0026#34;); // Make sure that the magic number is written before padding. //新建文件的文件头要立刻flush logStream.flush(); filePosition += oa.getDataSize() - dataSize; filePadding.setCurrentSize(filePosition); //在commit的时候进行flush streamsToFlush.add(fos); } fileSize = filePadding.padFile(fos.getChannel(), filePosition); //request序列化 byte[] buf = request.getSerializeData(); if (buf == null || buf.length == 0) { throw new IOException(\u0026#34;Faulty serialization for header \u0026#34; + \u0026#34;and txn\u0026#34;); } long dataSize = oa.getDataSize(); Checksum crc = makeChecksumAlgorithm(); crc.update(buf, 0, buf.length); oa.writeLong(crc.getValue(), \u0026#34;txnEntryCRC\u0026#34;); //将request写到流里 Util.writeTxnBytes(oa, buf); unFlushedSize += oa.getDataSize() - dataSize; return true; } private void flush() throws IOException, RequestProcessorException { if (this.toFlush.isEmpty()) { return; } ServerMetrics.getMetrics().BATCH_SIZE.add(toFlush.size()); long flushStartTime = Time.currentElapsedTime(); //将事务日志从流里刷到盘里 zks.getZKDatabase().commit(); ServerMetrics.getMetrics().SYNC_PROCESSOR_FLUSH_TIME.add(Time.currentElapsedTime() - flushStartTime); if (this.nextProcessor == null) { this.toFlush.clear(); } else { while (!this.toFlush.isEmpty()) { final Request i = this.toFlush.remove(); long latency = Time.currentElapsedTime() - i.syncQueueStartTime; ServerMetrics.getMetrics().SYNC_PROCESSOR_QUEUE_AND_FLUSH_TIME.add(latency); //到finalRequestProcessor this.nextProcessor.processRequest(i); } if (this.nextProcessor instanceof Flushable) { ((Flushable) this.nextProcessor).flush(); } } lastFlushTime = Time.currentElapsedTime(); } public synchronized void commit() throws IOException { if (logStream != null) { logStream.flush(); filePosition += unFlushedSize; // If we have written more than we have previously preallocated, // we should override the fileSize by filePosition. if (filePosition \u0026gt; fileSize) { fileSize = filePosition; } unFlushedSize = 0; } for (FileOutputStream log : streamsToFlush) { //刷盘 log.flush(); ... } while (streamsToFlush.size() \u0026gt; 1) { streamsToFlush.poll().close(); } // 达到上限了创建新事务文件 if (txnLogSizeLimit \u0026gt; 0) { long logSize = getCurrentLogSize(); if (logSize \u0026gt; txnLogSizeLimit) { LOG.debug(\u0026#34;Log size limit reached: {}\u0026#34;, logSize); //创建新文件 rollLog(); } } } FinalRequestProcessor 到目前为止，如果是查询请求，那还没有进行查询操作；如果是事务请求，只是将事务落盘了，内存中还没有进行修改。加上返回对象的组装，这些都是在这个Processor进行处理的。下面分别以创建节点和查询数据两个为例\n创建节点（create）\n创建节点属于事务操作，所以在返回结果之间要同步修改内存中的值，核心方法是applyRequest，一直会执行到DataTree的processTxn\n1 2 3 4 5 6 7 public void processRequest(Request request) { LOG.debug(\u0026#34;Processing request:: {}\u0026#34;, request); ProcessTxnResult rc = null; if (!request.isThrottled()) { //处理事务或session rc = applyRequest(request); } 将其执行结果封装为response，并发送出去\n查询数据（getData）\n由于查询数据不是事务，所以在applyRequest中并没有啥操作，直接走到下面的switch，封装request，然后从zkDataBase获取节点，再获取数据封装为response并返回\nSessionTracker session是逻辑上客户端和服务端的一次长连接的通话，依托于物理的长连接connection。当第一次建立连接之后，zookeeper会为这个链接创建一个session并设置一个过期时间，只要没到过期时间，期间哪怕连接断开，只要可以重新连接，那依然算作一个session内。\nzookeeper利用session实现了如临时节点，即当session过期，当前session所建立的临时节点都会被删除。\nsessionTrack的创建也是在zookeeperServer.start的时候\n而session的过期处理和connect的过期处理逻辑基本一样，在这里以session讲解一下逻辑，上面的connect过期部分也就看的懂了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public void run() { try { while (running) { long waitTime = sessionExpiryQueue.getWaitTime(); if (waitTime \u0026gt; 0) { Thread.sleep(waitTime); continue; } //看似是poll，其实是取出expiryMap中已经过期的队列 for (SessionImpl s : sessionExpiryQueue.poll()) { ServerMetrics.getMetrics().STALE_SESSIONS_EXPIRED.add(1); setSessionClosing(s.sessionId); expirer.expire(s);//其实就是close操作 } } } } 过期逻辑核心是一个队列ExpiryQueue，核心方法是update和poll方法。\nExpiryQueue持有两个集合对象elemMap和expiryMap，\nelemMap的key为连接对象，在这里就是指session，在connect逻辑中就是指connect，value是其过期时间。\nexpiryMap的key是过期时间，value是当前过期时间下对应的连接的集合。结构大概如下图。\n此外，ExpiryQueue还记录了下一个要过期的时间nextExpirationTime，因此，对于poll方法，就是遍历expiryMap，找到nextExpirationTime\u0026lt;now\u0026lt;key的values，并关闭即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public Set\u0026lt;E\u0026gt; poll() { long now = Time.currentElapsedTime(); //当前最后一个要过期的时间 long expirationTime = nextExpirationTime.get(); //时间还没到，所以都不过期 if (now \u0026lt; expirationTime) { return Collections.emptySet(); } Set\u0026lt;E\u0026gt; set = null; //计算下一个周期并赋值 long newExpirationTime = expirationTime + expirationInterval; if (nextExpirationTime.compareAndSet(expirationTime, newExpirationTime)) { //取到上一个过期的周期的集合 set = expiryMap.remove(expirationTime); } if (set == null) { return Collections.emptySet(); } return set; } 而update方法也好理解，其实就是给session续期，假如续期之后其落到下个周期了，则要从上个周期对应的集合移除，添加到下个周期的集合\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 public Long update(E elem, int timeout) { //取到session的之前过期时间 Long prevExpiryTime = elemMap.get(elem); long now = Time.currentElapsedTime(); //续期 Long newExpiryTime = roundToNextInterval(now + timeout); //续期之后依然属于上个周期，则不需要改变expiryMap if (newExpiryTime.equals(prevExpiryTime)) { // No change, so nothing to update return null; } //续期之后不属于上个周期了，则要将当前sessoin加到下一个周期的集合，并从上一个集合删除 // First add the elem to the new expiry time bucket in expiryMap. Set\u0026lt;E\u0026gt; set = expiryMap.get(newExpiryTime); if (set == null) { // Construct a ConcurrentHashSet using a ConcurrentHashMap set = Collections.newSetFromMap(new ConcurrentHashMap\u0026lt;\u0026gt;()); // Put the new set in the map, but only if another thread // hasn\u0026#39;t beaten us to it Set\u0026lt;E\u0026gt; existingSet = expiryMap.putIfAbsent(newExpiryTime, set); if (existingSet != null) { set = existingSet; } } set.add(elem); // Map the elem to the new expiry time. If a different previous // mapping was present, clean up the previous expiry bucket. prevExpiryTime = elemMap.put(elem, newExpiryTime); if (prevExpiryTime != null \u0026amp;\u0026amp; !newExpiryTime.equals(prevExpiryTime)) { Set\u0026lt;E\u0026gt; prevSet = expiryMap.get(prevExpiryTime); if (prevSet != null) { prevSet.remove(elem); } } return newExpiryTime; } 而update方法的调用上层是touchSession，在Processor处理前会调用。\n参考文档： 【图解源码】Zookeeper3.7源码分析，包含服务启动流程源码、网络通信源码、RequestProcessor处理请求源码 - 掘金\n【图解源码】Zookeeper3.7源码剖析，Session的管理机制，Leader选举投票规则，集群数据同步流程 - 掘金\nZookeeper源码分析 | Coding Tree\nZookeeper笔记之quota - CC11001100 - 博客园\n","date":"2024-08-05T12:59:08+08:00","permalink":"https://qisiii.github.io/post/tech/distributed/zookeeper/zookeeperservermain/","title":"Zookeeper源码学习-单机部分通信组件"},{"content":"Jstack应用 jstack是java提供的工具，一般用于分析栈-线程相关的问题，常见的比如死锁问题，cpu过高问题。\njstack 命令使用方式如下：\njstack [-F][-l][-m] pid 或者jstack [-F][-l][-m] [server_id@]\u0026lt;remote server IP or hostname\n可以通过-h或者-help来了解每个参数具体的作用，pid指的是java项目所属的进程Id，一般通过jps命令或者top、ps等命令获取。\nJstack文件分析 参数分析 大部分的信息都如上图所示：\n\u0026ldquo;pool-1-thread-2\u0026rdquo; 表示线程的名字\n#12 猜测是线程的nativeId，和arthas的线程id列很像，但是arthas官网文档又强调不是nativeId\nprio表示java内定义的线程的优先级\nos_prio操作系统级别的优先级\ntid 猜测是一个地址，但具体不清楚\nnid 操作系统级别线程的线程id,可通过top -pid [java应用进程id] 获取\n下面的红色部分则是状态、调用链路、一些锁的操作信息，具体下面分开讲\n状态 Java中线程的状态有六种：NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED\n其中，NEW和TERMINATED是创建和销毁时的状态，在stack中没有见到过，基本上都是其他四种状态在流转。) RUNNABLE:表示当前可以被cpu调度执行或者已经在执行。\n为了更好的解释BLOCKED，这里要结合synchronized的底层原理Monitor来进行讲解： Monitor是java对象规定的一个区域，可以视作一个房间。\n当持有synchronized锁的时候，表示当前线程持有Monitor，释放锁表示释放Monitor。因此，同一时刻只有一个线程可以持有，这个信息被记录在对象头的markword部分中。\n左边的entrySet用于记录等待获取锁的线程（即最开始抢锁失败的线程），此时这些线程的状态就为BLOCKED，抢到锁的线程状态为RUNNABLE。\n当拥有锁的线程释放锁的时候，存在两种可能：\n一种是释放了并且再也不使用了，即线程工作完成了，此时线程就结束掉，状态变为TERMINATED。\n一种是释放了但是线程是核心线程，可能还会继续调用，此时线程状态会为WAITING或者TIMED_WAITING，此时这个线程就会被放入到右边的waitSet。当调用notify或者到指定时间之后，就会将线程重新添加到左边的entrySet中再次尝试获取锁。\n线程的操作 线程的操作是指在stack文件堆栈信息中，用于描述线程对锁、对象的一些操作，堆栈信息一般如下面这般，-locked就是线程的操作，分为几类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at com.qisi.simple.Jvisualvm.JStackExample.test1(JStackExample.java:18) - locked \u0026lt;0x000000076adddbb8\u0026gt; (a com.qisi.simple.Jvisualvm.JStackExample) at com.qisi.simple.Jvisualvm.JStackExample$$Lambda$1/777874839.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:750) java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for \u0026lt;0x000000076adddb80\u0026gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2044) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:750) locked [地址]：当前线程持有锁，即持有monitor\nwaiting on [地址] ：线程释放锁，等待通知，即在waitSet中\nwaiting to lock [地址]：线程获取锁失败，正在等待获取锁，即在entrySet中\nparking to wait for [地址]：这种的是属于非synchronized锁的信息，多用于Lock锁，对应park方法，具体参考multithreading - Java thread dump: Difference between \u0026quot;waiting to lock\u0026quot; and \u0026quot;parking to wait for\u0026quot;? - Stack Overflow\n例子： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 static Boolean flag = true; synchronized void producer(){ System.out.println(Thread.currentThread().getName()+\u0026#34;抢到了锁\u0026#34;); while (flag) { try { flag = false; Thread.sleep(5000); this.wait(); System.out.println(Thread.currentThread().getName()+\u0026#34;执行了test1\u0026#34;); } catch (InterruptedException e) { throw new RuntimeException(e); } } } synchronized void consumer(){ System.out.println(Thread.currentThread().getName()+\u0026#34;抢到了锁\u0026#34;); while (!flag) { flag = true; this.notify(); } try { Thread.sleep(5000); } catch (InterruptedException e) { throw new RuntimeException(e); } System.out.println(Thread.currentThread().getName()+\u0026#34;执行了test2\u0026#34;); } ExecutorService executorService = Executors.newFixedThreadPool(2); JStackExample example = new JStackExample(); for (int i = 0; i \u0026lt; 10; i++) { executorService.execute(example::producer); executorService.execute(example::consumer); }; 一个简单的生产者-消费者例子，生成两次堆栈，分别在producer sleep时和\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 2024-07-28 21:52:21 Full thread dump OpenJDK 64-Bit Server VM (25.392-b08 mixed mode): \u0026#34;Attach Listener\u0026#34; #14 daemon prio=9 os_prio=31 tid=0x0000000128811800 nid=0x5b03 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE \u0026#34;DestroyJavaVM\u0026#34; #13 prio=5 os_prio=31 tid=0x0000000159922000 nid=0x1503 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE \u0026#34;pool-1-thread-2\u0026#34; #12 prio=5 os_prio=31 tid=0x0000000159921000 nid=0x5a03 waiting for monitor entry [0x0000000172c56000] java.lang.Thread.State: BLOCKED (on object monitor) at com.qisi.simple.Jvisualvm.JStackExample.test2(JStackExample.java:27) - waiting to lock \u0026lt;0x000000076adddbb8\u0026gt; (a com.qisi.simple.Jvisualvm.JStackExample) at com.qisi.simple.Jvisualvm.JStackExample$$Lambda$2/930990596.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:750) \u0026#34;pool-1-thread-1\u0026#34; #11 prio=5 os_prio=31 tid=0x00000001598dc800 nid=0x5903 waiting on condition [0x0000000172a4a000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at com.qisi.simple.Jvisualvm.JStackExample.test1(JStackExample.java:18) - locked \u0026lt;0x000000076adddbb8\u0026gt; (a com.qisi.simple.Jvisualvm.JStackExample) at com.qisi.simple.Jvisualvm.JStackExample$$Lambda$1/777874839.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:750) 2024-07-28 21:52:26 Full thread dump OpenJDK 64-Bit Server VM (25.392-b08 mixed mode): \u0026#34;pool-1-thread-2\u0026#34; #12 prio=5 os_prio=31 tid=0x0000000159921000 nid=0x5a03 waiting on condition [0x0000000172c56000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at com.qisi.simple.Jvisualvm.JStackExample.test2(JStackExample.java:33) - locked \u0026lt;0x000000076adddbb8\u0026gt; (a com.qisi.simple.Jvisualvm.JStackExample) at com.qisi.simple.Jvisualvm.JStackExample$$Lambda$2/930990596.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:750) \u0026#34;pool-1-thread-1\u0026#34; #11 prio=5 os_prio=31 tid=0x00000001598dc800 nid=0x5903 in Object.wait() [0x0000000172a4a000] java.lang.Thread.State: BLOCKED (on object monitor) at java.lang.Object.wait(Native Method) - waiting on \u0026lt;0x000000076adddbb8\u0026gt; (a com.qisi.simple.Jvisualvm.JStackExample) at java.lang.Object.wait(Object.java:502) at com.qisi.simple.Jvisualvm.JStackExample.test1(JStackExample.java:19) - locked \u0026lt;0x000000076adddbb8\u0026gt; (a com.qisi.simple.Jvisualvm.JStackExample) at com.qisi.simple.Jvisualvm.JStackExample$$Lambda$1/777874839.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:750) 先看21:52:21时的信息，\n由于是thread1先执行producer，获取到锁，表现为-locked \u0026lt;0x000000076adddbb8\u0026gt;，当执行到sleep时，状态变为TIMED_WAITING\n当执行到wait时，thread1会释放锁，所以在2024-07-28 21:52:26，新增了一条- waiting on \u0026lt;0x000000076adddbb8\u0026gt;，同时状态变为了BLOCKED，表示在等待锁。此时thread2获取到锁,thread2新增- locked \u0026lt;0x000000076adddbb8\u0026gt;，状态为TIMED_WAITING\n当thread的sleep醒来执行了notify时，后面的堆栈信息虽然没有抓取到，但可以推测出来，thread1被唤醒，因此，thread1会再次获取到锁，从堆栈信息来看则是waiting on会变为lock，因为此时只有thread1需要锁，如果有多个线程都需要锁，有可能会变成waiting to lock\n死循环cpu打满问题 测试代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /** * @author : qisi * @date: 2024/7/28 * @description: cpu打满测试用例 */ public class CpuFullExample { public static void main(String[] args) { Runnable empty = new Runnable() { @Override public void run() { int count=0; while (count\u0026lt;1000){ count++; } System.out.println(count); } }; Runnable full = new Runnable() { @Override public void run() { int count=0; while(true){ count++; } } }; new Thread(empty).start(); new Thread(full).start(); } } 根据top -pid [应用Id]找到cpu最高的tid，将10进制tid转换为16进制\n根据jstack pid 生成tdump文件，根据转换出来的16进制，搜索对应的nid，此时的线程大概率是runnbale，不然怎么可能死循环，然后根据调用链路去找项目中对应的位置。\n死锁问题 测试代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 public class DeadLockExample { public Object resourceA = new Object(); public Object resourceB = new Object(); public static void main(String[] args) { DeadLockExample deadLockExample = new DeadLockExample(); Runnable runnableA = new Runnable() { @Override public void run() { synchronized(deadLockExample.resourceA) { System.out.printf( \u0026#34;[INFO]: %s get resourceA\u0026#34; + System.lineSeparator(), Thread.currentThread().getName() ); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.printf( \u0026#34;[INFO]: %s trying to get resourceB\u0026#34; + System.lineSeparator(), Thread.currentThread().getName() ); synchronized(deadLockExample.resourceB) { System.out.printf( \u0026#34;[INFO]: %s get resourceB\u0026#34; + System.lineSeparator(), Thread.currentThread().getName() ); } System.out.printf( \u0026#34;[INFO]: %s has done\u0026#34; + System.lineSeparator(), Thread.currentThread().getName() ); } } }; Runnable runnableB = new Runnable() { @Override public void run() { synchronized(deadLockExample.resourceB) { System.out.printf( \u0026#34;[INFO]: %s get resourceB\u0026#34; + System.lineSeparator(), Thread.currentThread().getName() ); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.printf( \u0026#34;[INFO]: %s trying to get resourceA\u0026#34; + System.lineSeparator(), Thread.currentThread().getName() ); synchronized(deadLockExample.resourceA) { System.out.printf( \u0026#34;[INFO]: %s get resourceA\u0026#34; + System.lineSeparator(), Thread.currentThread().getName() ); } System.out.printf( \u0026#34;[INFO]: %s has done\u0026#34; + System.lineSeparator(), Thread.currentThread().getName() ); } } }; new Thread(runnableA).start(); new Thread(runnableB).start(); } } 这段程序执行后，runnableA在持有resourceA后会再尝试获取resourceB锁，但此时resourceB锁已经被runnableB获取，释放的条件则是runnableB执行完，但是runnableB执行过程又在等待resourceA锁，这样就陷入了死锁。\n使用jps获取pid，使用jstack pid生成文件。文件内容大致就是下面这样，其中大部分都是如同第一段一般，只有在出现死锁的时候，才会出现第二段（Found one Java-level deadlock），并清楚的告诉是哪些线程陷入死锁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026#34;Thread-1\u0026#34; #14 prio=5 os_prio=31 tid=0x0000000125809000 nid=0x7a03 waiting for monitor entry [0x000000016efba000] java.lang.Thread.State: BLOCKED (on object monitor) at com.qisi.simple.Jvisualvm.DeadLockExample$2.run(DeadLockExample.java:59) - waiting to lock \u0026lt;0x000000076b5dee40\u0026gt; (a java.lang.Object) - locked \u0026lt;0x000000076b5dee50\u0026gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:750) ...... Found one Java-level deadlock: \u0026#34;Thread-1\u0026#34;: waiting to lock monitor 0x0000000124055770 (object 0x000000076b5dee40, a java.lang.Object), which is held by \u0026#34;Thread-0\u0026#34; \u0026#34;Thread-0\u0026#34;: waiting to lock monitor 0x0000000124058000 (object 0x000000076b5dee50, a java.lang.Object), which is held by \u0026#34;Thread-1\u0026#34; ...... Found 1 deadlock. 参考文档： https://zihengcat.github.io/2019/08/09/java-tutorial-for-language-adavanced-deadlock-example-and-solution/\n图解 Java 线程生命周期-腾讯云开发者社区-腾讯云\nJVM系列\u0026ndash;jstack工具详解 | 奚新灿的博客-Chronos\njstack 命令的使用和问题排查分析思路_jstack pid-CSDN博客\nMonitor对象全解析 - 张高峰的博客 | Peakiz Blog\n","date":"2024-07-28T17:14:47+08:00","permalink":"https://qisiii.github.io/post/tech/lang/jstack/","title":"Jstack使用"},{"content":"建站方式 选择建站方式，是使用动态建站（如WordPress、halo），还是使用静态建站（Jekyll、hexo、hugo）。\n前者更偏向于传统的CMS管理系统，有后台管理页面，可以在管理页面发布，修改文章。除了需要服务器之外，需要同时了解前端、后端、数据库相关的知识，当然现有的项目完全可以简单配置后就可以开箱使用。\n后者一般是使用各种开源项目，将文档转为静态资源（html），部署在服务器或者以GithubPages的方式供他人访问。而使用哪个开源项目进行建站，可以去Static Site Generators -Jamstack选择个人喜欢的项目，本文使用hugo项目进行搭建。\nhugo安装和使用 参考hugo中文官网，进行安装，我这里是mac os系统，所以直接使用 brew install hugo进行安装。\n使用命令hugo new site [路径]创建项目根目录，比如我这边路径是/Users/qisi/Research/hugo，则会在/Users/qisi/Research/hugo目录下创建以下文件夹\n其中，content文件夹用来存储你的文档，themes文件夹用来存储你想要的主题，hugo.toml是总的配置，其他的后面可以跟着官网慢慢熟悉。\n在主题网站安装想要的主题，我这里是使用的stack主题，可以通过两种方式安装\n通过git命令，在当前目录执行\n1 2 git init git submodule add --depth=1 https://github.com/CaiJimmy/hugo-theme-stack.git themes/hugo-theme-stack 手动安装则是自己新建文件夹，然后clone\n1 2 3 cd themes mkdir hugo-theme-stack git clone https://github.com/CaiJimmy/hugo-theme-stack.git 安装完成之后，将stack主题的配置复制一份到hugo根目录，并删除hugo.toml文件\ncp themes/hugo-theme-stack/exampleSite/hugo.yaml ./\n执行以下命令来新建文件，会自动在content/post目录下新建test.md\nhugo new post/test.md\n文件内容是,draft表示是草稿\n1 2 3 4 5 6 +++ title = \u0026#39;Test\u0026#39; date = 2024-07-29T14:25:00+08:00 draft = true +++ ## 这里是我手动添加的内容 通过hugo server --buildDrafts 启动后台，\u0026ndash;buildDrafts 表示会编译draft=true的文档，通过在浏览器访问http://localhost:1313打开网站，页面如图\nGithub Page 通过hugo server已经可以在本地电脑进行访问了，但如果想要通过互联网访问，则需要进行额外的设置。\n如果拥有自己的服务器，可以在服务器上启动hugo，然后使用nginx监听并转发到public目录；但如果没有服务器，则可以通过Github Page功能来托管自己的项目。\n首先需要创建一个项目，项目名称以github.io结尾，前缀一般用自己的用户名或者有标识的单词\n将hugo项目的public文件夹作为一个git项目，推送到刚新建的这个Repository中\n1 2 3 4 5 6 cd public git init git add . git commit -am 首次commit git remote add origin git@github.com:qisiii/qisiii.github.io.git git push --set-upstream origin master 在setting-pages下进行一些设置，如下图所示，保存后就可以通过[关键词].github.io来访问了\n如果想要更个性化的域名，则需要购买一个域名，添加一个cname类型的解析，同时在上图Custom domain的文本框中填入对应的域名，这样子就可以以自己的域名访问了。\nMarkdown工具 市面上的markdown工具还是蛮多的，各种开发用的ide，或者专门用于markdown的编辑器。我使用的是MarkText(GitHub - marktext/marktext: 📝A simple and elegant markdown editor, available for Linux, macOS and Windows.)，建议直接安装中文版markText。\nMarkText的图床功能存在bug：\nuploader为github时上传失败 原因是GithubApi要求content是base64格式的，所以需要额外做一下处理，参考pr\n无法上传剪贴板的图片 其中，无法上传剪贴板图片的bug是由于项目中fileSystem.js中path.join方法参数类型错误导致的；参考Fix Failure when uploading clipboard images with PicGo （#3360） by Jakentop · Pull Request #3366 · marktext/marktext · GitHub\n无法检测到picgo存在 无法检测到picgo我在本地启动没有复现，只有在打包之后才会出现这个问题，目前定位不到原因\n参考博客： 个人网站的建立过程（二）：使用Hugo框架搭建个人网站\n个人网站的建立过程（二）：使用Hugo框架搭建个人网站\n","date":"2024-07-23T00:00:00Z","permalink":"https://qisiii.github.io/post/site/personsite/","title":"搭建自己的博客"},{"content":"前言： 在看socket相关代码的时候，AbstractPlainSocketImpl中的一段代码吸引了我，其实之前见过很多次类似的代码，但一直不想去看，只知道肯定和权限什么的相关，这次既然又碰到了就研究一下，毕竟也不能对java基本代码一无所知。\n1 2 3 4 5 6 7 8 9 static { java.security.AccessController.doPrivileged( new java.security.PrivilegedAction\u0026lt;Void\u0026gt;() { public Void run() { System.loadLibrary(\u0026#34;net\u0026#34;); return null; } }); } 一些概念: 在jdk1.0的时代，applet依然是前端的一种可用的技术方案，比如可以嵌入在网页里运行。那个时候jdk的设计者们认为本地代码是安全的、远端代码是有风险的，而applet就是属于远端代码。因此，为了保证用户主机的安全和隐私，设计者参考了沙箱的思想，依托于当时jdk的体量很小，使用SecurityManager来分隔本地代码和远程代码，一个有权限，一个没有权限。\n当时还出现了签名相关的机制(本文不关心，所以没做了解），随着java发展，1.1的时候出现了JAVABEAN、JDBC、反射等新概念，于是有了更多的新权限。设计者发现完全授予本地代码所有权限变得不合理，在1.2的时候重构了SecurityManager，变成了现在这样以最小粒度控制权限。这个时候的SecurityManager有两个功能，一是防御远程代码、二是防御本地代码的漏洞。\n不知道是什么时候起，安全机制引入了域（ProtectDomain）的概念，也可以视作将一个大沙箱拆分为多个小沙箱。一个域对应一个沙箱，不同的代码（Codesource）被划分到不同域中，不同的域有着不同的权限（Permission），就像下图一样。同时可以给不同的域配置不同的权限，静态和动态均可，这个配置被称为策略(Policy)。 注意！\n在JDK20和JDK21的security-guide中都提到了，和SecurityManager与之相关的api已被弃用，并将在未来的版本中删除。SecurityManager没有替代者。有关讨论和备选方案，请参阅JEP 411: Deprecate the Security Manager for Removal。\nAccessController AccessController主要有两个功能，对应的核心方法也是两类\ncheckPermission(校验是否存在权限) 1 2 3 4 5 6 7 8 9 public static void checkPermission(Permission perm) throws AccessControlException { AccessControlContext stack = getStackAccessControlContext(); // if context is null, we had privileged system code on the stack. //...其他获取context方法 AccessControlContext acc = stack.optimize(); acc.checkPermission(perm); } 调用该方法时，一般会new一个期望的权限，然后作为入参传入checkPermission方法。\n1 2 FilePermission perm = new FilePermission(\u0026#34;C:\\\\Users\\\\Administrator\\\\Desktop\\\\liveController.txt\u0026#34;, \u0026#34;read\u0026#34;); AccessController.checkPermission(perm); 注意，校验权限的时候会校验调用链路径上所有类的权限；假如调用链是从i开始，一直调用到m，校验逻辑如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 for (int i = m; i \u0026gt; 0; i--) { if (caller i\u0026#39;s domain does not have the permission) throw AccessControlException else if (caller i is marked as privileged) { if (a context was specified in the call to doPrivileged) context.checkPermission(permission) if (limited permissions were specified in the call to doPrivileged) { for (each limited permission) { if (the limited permission implies the requested permission) return; } } else return; } } 代码执行的时候，每一次方法的调用都代表着一次入栈，而权限校验的时候则正好是从栈顶开始，依次判断每个栈帧是否具有权限，一直到栈底。 doPrivileged(临时授权) 1 public static native \u0026lt;T\u0026gt; T doPrivileged(PrivilegedAction\u0026lt;T\u0026gt; action); 这个方法的功能是将当前类所拥有的权限，能且仅能临时赋予其上游调用方。\n在这个场景下，必然存在多个域，且只有某些域拥有权限A，但是其他域并没有这个权限。在java语言中很容易出现这个情况，比如我们调用一些第三方jar包的方法，三方jar包还能调用别的三方jar包，这种场景很有可能只有最底层的方法所对应的域拥有权限。此时为了方法的成功，就可以使用该方法。\n使用的时候就是将代码逻辑放入AccessController.doPrivileged中即可，如下述代码一般。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 //项目B，会打成security-demo.jar public class PermissionDemo { /** * 使用特权访问机制 * @param file */ public void runWithOutPermission(String file){ AccessController.doPrivileged((PrivilegedAction\u0026lt;String\u0026gt;) () -\u0026gt; { //hutool的FileUtil String s = FileUtil.readString(file, \u0026#34;utf-8\u0026#34;); System.out.println(s); return s; }); } } //项目A，引入security-demo.jar public class Aperson { public static void main(String[] args) { new PermissionDemo().runWithOutPermission(\u0026#34;C:\\\\Users\\\\Administrator\\\\Desktop\\\\test.txt\u0026#34;); } } 这里需要注意的是，AccessController.doPrivileged所在的当前类也需要拥有权限。以这个例子为例，文件读写是在hutool的FileUtil中执行，hutool对应的是域C；PermissionDemo对应的是域B，且会将自身权限向上传递；而Aperson对应的是域A。这个例子中，想要Aperson执行成功，必须是域C和域B都拥有test.txt的read权限。\n对应的policy如下\n1 2 3 4 5 6 grant codeBase \u0026#34;file:/C:/Users/Administrator/.m2/repository/cn/hutool/hutool-all/5.7.11/-\u0026#34;{ permission java.io.FilePermission \u0026#34;C:\\\\Users\\\\Administrator\\\\Desktop\\\\*\u0026#34;, \u0026#34;read\u0026#34;; }; grant codeBase \u0026#34;file:/C:/Users/Administrator/.m2/repository/xxx/xxx/security-demo/-\u0026#34;{ permission java.io.FilePermission \u0026#34;C:\\\\Users\\\\Administrator\\\\Desktop\\\\*\u0026#34;, \u0026#34;read\u0026#34;; }; 从栈帧的角度来看的话，判断到doPrivilege对应的那层之后，校验就直接返回了，不校验下面层是否存在权限。 ProtectDomain protectDomain类由codeSource和permission构成 CodeSource 类的来源，一般为jar包路径或者classpath路径（target/classes）\n因为所有类在通过ClassLoader引入的，所以ClassLoader知道类的基本信息，在defineClass时，将CodeSource和Permission进行了绑定。同理，由于类必须通过ClassLoader加载，对于使用自定义ClassLoader加载的类，就只有那个类加载器知道对应的CodeSource和permission。因此，不同的类加载器本身就属于不同的域。\nPermission Java抽象出的顶层的类，核心方法是implies，该方法用来判断当前线程是否隐含指定权限，由各自的子类实现。子类实现过多，这里就不列举了。\nPermissionCollection本质是个list，里面是某一类权限的多个实例，比如文件夹A-读权限，文件夹B-写权限，文件夹C-读写权限。\nPermissions核心是一个map,key是Permissoin子类,value是PermissionCollection\nSecurityManager SecurityManage里有一堆check方法，调用的是AccessController.checkPermission方法，入参就是Permission各个子类的实例化。\n开启方式： 隐性：启动时添加-Djava.security.manager\n显性：System.setSecurityManager\n1 2 3 4 5 6 7 8 9 10 11 12 public class NoShowTest { static class CustomManager extends SecurityManager{ @Override public void checkRead(String file) { throw new AccessControlException(\u0026#34;无权限访问\u0026#34;); } } public static void main(String[] args) { System.setSecurityManager(new CustomManager()); System.getSecurityManager().checkRead(\u0026#34;C:\\\\Users\\\\Administrator\\\\Desktop\\\\liveController.txt\u0026#34;); } } Policy 启动时通过 -Djava.security.policy=xxxx\\custom.policy，如果没有指定，则默认使用jdk路径下\\jre\\lib\\security\\java.policy\n参考： Java安全:SecurityManager与AccessController - 掘金\nJava沙箱机制的实现——安全管理器、访问控制器 - 掘金\n第21章-再谈类的加载器\nhttps://openjdk.org/jeps/411\nhttps://docs.oracle.com/en/java/javase/20/security/java-security-overview1.html#GUID-BBEC2DC8-BA00-42B1-B52A-A49488FCF8FE\nAccessController.doPrivileged - 山河已无恙 - 博客园\n","date":"2023-11-08T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/lang/java_security/","title":"Java安全机制之一——SecurityManager和AccessController"},{"content":" 在定位公司问题的时候，需要了解一下skywalking的相关知识，而agent就提上了日程。\n官网文档\nAgent技术是Jdk在1.5版本之后，所提供的一个在jvm启动前后对部分java类代理加强的机制。由于是直接修改字节码，并不会对业务代码有注入，所以可以很好的应用于监控或者热部署等场景。\n正常所提到的Agent一般都是部署成jar包的样子，比如agent-1.0-SNAPSHOT.jar。\n在这个jar包中，要添加一个MANIFEST.MF文件，在文件中指定jar包的代理类，比如下面代码中的Premain-Class。\n在对应的代理类，要实现一个permain方法或者agentmain方法，这样jvm可以通过MANIFEST找到类，通过类再找到对应的方法，从而进行加强，所以加强逻辑是在permain方法或者agentmain方法内部实现的。\n1 2 3 4 5 6 7 8 9 Manifest-Version: 1.0 Built-By: qisi Premain-Class: com.qisi.agent.InterviewAgent Agent-Class: com.qisi.agent.InterviewAgent Can-Redefine-Classes: true Can-Retransform-Classes: true Class-Path: byte-buddy-1.10.22.jar Created-By: Apache Maven 3.8.1 Build-Jdk: 1.8.0_332 1 2 3 4 5 6 public class InterviewAgent { public static void premain(String agentArgs, Instrumentation instrumentation) { } public static void agentmain(String agentArgs, Instrumentation instrumentation) { } } 而如果在permain或者agentmain方法打上debug可以发现，执行时是通过sun.instrument.InstrumentationImpl#loadClassAndCallPremain和sun.instrument.InstrumentationImpl#loadClassAndCallAgentmain两个方法通过反射来执行到我们指定的类的。\nAgent技术有两种场景，一种是在jvm启动之前，通过-javaagent:path来指定jar包，像是skywalking就是采用的这种方式；另一种则是在jvm启动之后，通过attach指定的进程，对jvm中的类进行加强，arthas就是采用的这种方式。\n在具体介绍这两种方式之前，需要先讲一下Instrumentation相关类和接口\njava.lang.Instrumentation Instrumentation Instrumentation相关的类都在java.lang.Instrumentation包下，两个异常，两个接口，一个类。 两个异常在这里不做介绍，功能就像类名一样。核心的其实是Instrumentation接口，本文仅关注红框内的几个方法。这几个方法都是通过permain和agentmain获取到的instrumentation实例进行的操作。\n从时间发展来看，其中jdk1.5开始支持的是下面几个方法，也就是说在jdk5的时候，仅支持添加和移除类转换器，且添加的类转换器只能在加载和重定义的时候使用。就是说如果类没有加载，那么通过addTransformer方法注册的ClassFileTransformer就可以对这个类进行增强，否则一旦类已经加载完毕，则只能通过redefineClasses，完全替换类定义再次触发loadClass来增强\n1 2 3 4 addTransformer(ClassFileTransformer transformer) removeTransformer(ClassFileTransformer transformer) isRedefineClassesSupported();//依赖于MANIFEST中的Can-Redefine-Classes值 redefineClasses(ClassDefinition... definitions) 而从jdk1.6开始，增加了一个retransformClasses的概念。retransform和redefine的区别，前者是在原有类的基础上进行修改，后者则是完全重定义，不使用原有类做任何参考。 需要注意的事，只有在首次调用addTransformer时，将canRetransform设置为true的类，才可以被重新转换。\n1 2 3 4 addTransformer(ClassFileTransformer transformer, boolean canRetransform); isRetransformClassesSupported(); retransformClasses(Class\u0026lt;?\u0026gt;... classes)//依赖于MANIFEST中的Can-Retransform-Classes值 isModifiableClass(Class\u0026lt;?\u0026gt; theClass); ClassFileTransformer、ClassDefinition 这两个类其实都是Instrumentation接口方法的入参，其中用的比较多的应该是ClassFileTransformer。这个类只有一个transform，jvm类加载的时候都会调用一遍这个方法。如果需要加强，那么就利用给定的参数，进行字节码的改动，将改动后的字节码作为返回值返回；如果无需增强，则直接返回null即可。\n1 2 3 4 5 6 byte[] transform( ClassLoader loader, String className, Class\u0026lt;?\u0026gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) ClassDefinition也类似，不过是在对象里重新绑定class和byte的关系\n1 2 3 4 5 6 7 8 9 10 public final class ClassDefinition { /** * The class to redefine */ private final Class\u0026lt;?\u0026gt; mClass; /** * The replacement class file bytes */ private final byte[] mClassFile; 实践 MANIFEST.MF配置 在pom文件中添加下面的代码，根据需要修改参数值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-jar-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;archive\u0026gt; \u0026lt;addMavenDescriptor\u0026gt;false\u0026lt;/addMavenDescriptor\u0026gt; \u0026lt;manifest\u0026gt; \u0026lt;addClasspath\u0026gt;true\u0026lt;/addClasspath\u0026gt; \u0026lt;/manifest\u0026gt; \u0026lt;manifestEntries\u0026gt; \u0026lt;Premain-Class\u0026gt; com.qisi.agent.InterviewByteButtyAgent \u0026lt;/Premain-Class\u0026gt; \u0026lt;Agent-Class\u0026gt; com.qisi.agent.InterviewByteButtyAgent \u0026lt;/Agent-Class\u0026gt; \u0026lt;Can-Redefine-Classes\u0026gt; true \u0026lt;/Can-Redefine-Classes\u0026gt; \u0026lt;Can-Retransform-Classes\u0026gt; true \u0026lt;/Can-Retransform-Classes\u0026gt; \u0026lt;Built-By\u0026gt; qisi \u0026lt;/Built-By\u0026gt; \u0026lt;/manifestEntries\u0026gt; \u0026lt;/archive\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; -javaagent: 在这种方式下，起作用的是permain，也就是说-javaagent和permain方法是配套使用的。 核心就是添加一个自定义的ClassFileTransformer，可以另起一个类，也可以这样匿名类。 如果只是熟悉流程可以像下面一样，直接打印一些日志，不去修改类；\n1 2 3 4 5 6 7 8 9 10 11 12 public static void premain(String agentArgs, Instrumentation instrumentation) { System.out.println(\u0026#34;enhance by premain,params:\u0026#34;+agentArgs); instrumentation.addTransformer(new ClassFileTransformer() { @Override public byte[] transform(ClassLoader loader, String className, Class\u0026lt;?\u0026gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException { System.out.println(\u0026#34;premain load Class :\u0026#34; + className); return classfileBuffer; } }, true); } 如果要真实修改，需要引入asm javassist bytebuddy等修改字节码的框架。下面这部分就是使用了bytebuddy，作用是让任何类的testAgent方法，都返回固定值transformed\n1 2 3 4 5 6 7 8 9 10 public static void premain(String agentArgs, Instrumentation instrumentation) throws ClassNotFoundException { System.out.println(\u0026#34;enhance by permain InterviewByteButtyAgent,params:\u0026#34;+agentArgs); new AgentBuilder.Default().type(any()).transform(new AgentBuilder.Transformer() { @Override public DynamicType.Builder\u0026lt;?\u0026gt; transform(DynamicType.Builder\u0026lt;?\u0026gt; builder, TypeDescription typeDescription, ClassLoader classLoader, JavaModule module) { return builder.method(named(\u0026#34;testAgent\u0026#34;)) .intercept(FixedValue.value(\u0026#34;transformed\u0026#34;)); } }).installOn(instrumentation); } 编写完之后，就可以在任意项目添加一个存在testAgent方法的进行尝试了，比如 java -javaagent:/xxxx/path/agent-1.0-SNAPSHOT.jar=key1:value1,key2:value2 -jar AppDemo.jar\nattach agentmain 这种方式需要实现agentmain方法，和permian不太一样的地方是需要在addTransformer之后触发需要retransformClasses想要加强的类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public static void agentmain(String agentArgs, Instrumentation instrumentation) { System.out.println(\u0026#34;enhance by agentmain,params:\u0026#34;+agentArgs); instrumentation.addTransformer(new ClassFileTransformer() { @Override public byte[] transform(ClassLoader loader, String className, Class\u0026lt;?\u0026gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException { System.out.println(\u0026#34;agentmain load Class :\u0026#34; + className); return classfileBuffer; } }, true); try { instrumentation.retransformClasses(Class.forName(\u0026#34;com.qisi.mybatis.app.controller.FirstRequestController\u0026#34;)); } catch (UnmodifiableClassException e) { e.printStackTrace(); } catch (ClassNotFoundException e) { e.printStackTrace(); } } 同样，提供一个bytebuddy的例子，下面这个则是指定修改FirstRequestController的testAgent方法的返回值为transformed\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public static void agentmain(String agentArgs, Instrumentation instrumentation) throws ClassNotFoundException { System.out.println(\u0026#34;enhance by agentmain InterviewByteButtyAgent,params:\u0026#34;+agentArgs); //这里RedefinitionStrategy必须注意，默认的DISABLED是不支持retransform new AgentBuilder.Default().with(AgentBuilder.RedefinitionStrategy.RETRANSFORMATION).type(new AgentBuilder.RawMatcher() { @Override public boolean matches(TypeDescription typeDescription, ClassLoader classLoader, JavaModule module, Class\u0026lt;?\u0026gt; classBeingRedefined, ProtectionDomain protectionDomain) { return typeDescription.getName().contains(\u0026#34;FirstRequestController\u0026#34;); } }).transform(new AgentBuilder.Transformer() { @Override public DynamicType.Builder\u0026lt;?\u0026gt; transform(DynamicType.Builder\u0026lt;?\u0026gt; builder, TypeDescription typeDescription, ClassLoader classLoader, JavaModule module) { System.out.println(\u0026#34;enhance\u0026#34;+typeDescription.getName()); return builder.method(named(\u0026#34;testAgent\u0026#34;)) .intercept(FixedValue.value(\u0026#34;transformed\u0026#34;)); } //这里采用disableClassFormatChanges的方案，好像还可以使用advice }).disableClassFormatChanges().installOn(instrumentation); try { instrumentation.retransformClasses(Class.forName(\u0026#34;com.qisi.mybatis.app.controller.FirstRequestController\u0026#34;)); } catch (UnmodifiableClassException e) { e.printStackTrace(); } catch (ClassNotFoundException e) { e.printStackTrace(); } } VirtualMachine 不同于-javaagent命令，这里需要使用自jdk6开始提供的VirtualMachine类，在tool.jar包里 下面的方法是我参考arthas写的一个attach的流程，选择我们想要attach的进程，然后加载我们上面写好的jar包就好了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 public class AgentTest { public static void main(String[] args) throws IOException, AttachNotSupportedException { String pid = null; try { Process jps = Runtime.getRuntime().exec(\u0026#34;jps\u0026#34;); InputStream inputStream = jps.getInputStream(); BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream)); String line; while ((line = bufferedReader.readLine()) != null) { System.out.println(line); } System.out.println(\u0026#34;选择要attach的进程\u0026#34;); pid= new Scanner(System.in).nextLine(); System.out.println(\u0026#34;选择的pid是\u0026#34;+pid); } catch (IOException e) { e.printStackTrace(); } for (VirtualMachineDescriptor virtualMachineDescriptor : VirtualMachine.list()) { if (virtualMachineDescriptor.id().equals(pid)){ VirtualMachine attach = VirtualMachine.attach(virtualMachineDescriptor); try { attach.loadAgent(\u0026#34;/xxxxx/agent/target/agent-1.0-SNAPSHOT.jar\u0026#34;,\u0026#34;参数1，参数2\u0026#34;); } catch (AgentLoadException e) { e.printStackTrace(); } catch (AgentInitializationException e) { e.printStackTrace(); } finally { attach.detach(); } break; } } } } 参考文档： 探秘 Java 热部署二（Java agent premain）\nJAVA热更新1:Agent方式热更 | 花隐间-JAVA游戏技术解决方案\nByteBuddy入门教程\n","date":"2023-09-10T00:00:00Z","permalink":"https://qisiii.github.io/post/tech/lang/javaagent/","title":"JavaAgent技术"}]